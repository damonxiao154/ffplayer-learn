<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <link rel="canonical" href="https://blog.csdn.net/leixiaohua1020/article/details/45644367"/> 
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="referrer" content="always">
    <meta name="description" content="本文分析x264编码器主干部分的源代码。“主干部分”指的就是libx264中最核心的接口函数——x264_encoder_encode()，以及相关的几个接口函数x264_encoder_open()，x264_encoder_headers()，和x264_encoder_close()。这一部分源代码比较复杂，现在看了半天依然感觉很多地方不太清晰，暂且把已经理解的地方整理出来，以后再慢慢补充还不太清晰的地方。" />
    <meta name="keywords" content="x264,libx264" />
    <meta http-equiv="Cache-Control" content="no-siteapp" /><link rel="alternate" media="handheld" href="#" />
    <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848">
    <script src="https://csdnimg.cn/release/phoenix/vendor/tingyun/tingyun-rum-blog@js"></script>

    <link href="https://csdnimg.cn/public/favicon.ico" rel="SHORTCUT ICON">
    <title>x264源代码简单分析：编码器主干部分-1 - CSDN博客</title>
    
            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/detail-60a2c245da.min.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/themes/skin3-template/skin3-template-88717cedf2.min.css">

    <script type="text/javascript">
        var username = "leixiaohua1020";
        var blog_address = "https://blog.csdn.net/leixiaohua1020";
        var static_host = "https://csdnimg.cn/release/phoenix/";
        var currentUserName = ""; 
        var isShowAds = true;
        var isOwner = false;
        var loginUrl = "https://passport.csdn.net/account/login?from=https://blog.csdn.net/leixiaohua1020/article/details/45644367"
        var blogUrl = "https://blog.csdn.net/";
        var curSkin = "skin3-template";
    </script>
    <script type="text/javascript">
        // Traffic Stats of the entire Web site By baidu
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm@js?6bcd52f51e9b3dce32bec4a3997715ac";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
        // Traffic Stats of the entire Web site By baidu end
    </script>
    <script src="https://csdnimg.cn/public/common/libs/jquery/jquery-1.9.1.min@js" type="text/javascript"></script>
    <script src="https://csdnimg.cn/rabbit/exposure-click/main-1.0.6@js"></script>
    <!-- 新版上报 -->
    <script src="//g.csdnimg.cn/track/1.0.0/track@js" type="text/javascript"></script>
    <!-- 新版上报end -->
            <link rel="stylesheet" href="https://csdnimg.cn/public/sandalstrap/1.3/css/sandalstrap.min.css"> 
    <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>
</head>
<body>    
    <link rel="stylesheet" href="https://csdnimg.cn/public/common/toolbar/content_toolbar_css/content_toolbar.css">
    
    <script src="https://csdnimg.cn/public/sandalstrap/1.3/fonts/csdnc/csdnc@js"></script><link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/blog_code-c3a0c33d5c.css">
<link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/vendor/pagination/paging.css">
<script type="text/javascript" src="//static.mediav.com/js/mvf_news_feed@js"></script>

<header style="display: none;">
	<div class="container d-flex clearfix">
		<div class="title-box">
			<h2 class="title-blog">
				<a href="https://blog.csdn.net/leixiaohua1020">雷霄骅(leixiaohua1020)的专栏</a>
			</h2>
			<p class="description">一个广院工科生的视音频技术笔记</p>
		</div>
		<div class="opt-box d-flex justify-content-end">
			<a class="btn btn-sm" href="https://blog.csdn.net/leixiaohua1020/rss/list">
					<svg class="icon" aria-hidden="true">
						<use xlink:href="#csdnc-rss"></use>
					</svg>RSS订阅</a>
					</div>
	</div>
</header><script src="https://dup.baidustatic.com/js/ds@js"></script>
<div class="container clearfix pt0" id="mainBox">
    <main style="width: 100%;">
        <div class="blog-content-box">
	<div class="article-title-box">
			<span class="article-type type-1 float-left">原</span>		<h1 class="title-article">x264源代码简单分析：编码器主干部分-1</h1>
	</div>
	<div class="article-info-box">
		<div class="article-bar-top d-flex">
												<span class="time">2015年05月11日 17:10:51</span>
			<div class="float-right">
				<span class="read-count" style="display:none;">阅读数：12777</span>
											</div>
		</div>
	</div>
	<article>
		<div id="article_content" class="article_content_dummy clearfix csdn-tracking-statistics" data-pid="blog"  data-mod=popu_307  data-dsm = "post" >
                    <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/htmledit_views-0a60691e80.css" />
            <div class="htmledit_views">
                <p><span style="white-space:pre"></span></p><p>=====================================================</p><p>H.264源代码分析文章列表：</p><p>【编码 - x264】</p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45536607" rel="nofollow">x264源代码简单分析：概述</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45583217" rel="nofollow">x264源代码简单分析：x264命令行工具（x264.exe）</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45644367" rel="nofollow">x264源代码简单分析：编码器主干部分-1</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45719905" rel="nofollow">x264源代码简单分析：编码器主干部分-2</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45790195" rel="nofollow">x264源代码简单分析：x264_slice_write()</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45870269" rel="nofollow">x264源代码简单分析：滤波（Filter）部分</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45917757" rel="nofollow">x264源代码简单分析：宏块分析（Analysis）部分-帧内宏块（Intra）</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45936267" rel="nofollow">x264源代码简单分析：宏块分析（Analysis）部分-帧间宏块（Inter）</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45938927" rel="nofollow">x264源代码简单分析：宏块编码（Encode）部分</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45944811" rel="nofollow">x264源代码简单分析：熵编码（Entropy Encoding）部分</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45960409" rel="nofollow">FFmpeg与libx264接口源代码简单分析</a></p><p>【解码 - libavcodec H.264 解码器】</p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/44864509" rel="nofollow">FFmpeg的H.264解码器源代码简单分析：概述</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45001033" rel="nofollow">FFmpeg的H.264解码器源代码简单分析：解析器（Parser）部分</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45042755" rel="nofollow">FFmpeg的H.264解码器源代码简单分析：解码器主干部分</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45114453" rel="nofollow">FFmpeg的H.264解码器源代码简单分析：熵解码（EntropyDecoding）部分</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45143075" rel="nofollow">FFmpeg的H.264解码器源代码简单分析：宏块解码（Decode）部分-帧内宏块（Intra）</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45195291" rel="nofollow">FFmpeg的H.264解码器源代码简单分析：宏块解码（Decode）部分-帧间宏块（Inter）</a></p><p><a target=_blank href="http://blog.csdn.net/leixiaohua1020/article/details/45224579" rel="nofollow">FFmpeg的H.264解码器源代码简单分析：环路滤波（Loop Filter）部分</a></p><p>=====================================================</p><br /><p><span style="white-space:pre">	</span>本文分析x264编码器主干部分的源代码。“主干部分”指的就是libx264中最核心的接口函数——x264_encoder_encode()，以及相关的几个接口函数x264_encoder_open()，x264_encoder_headers()，和x264_encoder_close()。这一部分源代码比较复杂，现在看了半天依然感觉很多地方不太清晰，暂且把已经理解的地方整理出来，以后再慢慢补充还不太清晰的地方。由于主干部分内容比较多，因此打算分成两篇文章来记录：第一篇文章记录x264_encoder_open()，x264_encoder_headers()，和x264_encoder_close()这三个函数，第二篇文章记录x264_encoder_encode()函数。</p><br /><br /><h1>函数调用关系图</h1>X264编码器主干部分的源代码在整个x264中的位置如下图所示。<br /><div style="text-align: center;"><a target=_blank target="_blank" href="http://img.my.csdn.net/uploads/201505/06/1430897637_6272.jpg" rel="nofollow"><img src="https://img-blog.csdn.net/20150511151313927" alt="" /></a></div><div style="text-align: center;"><a target=_blank target="_blank" href="https://my.csdn.net/leixiaohua1020/album/detail/1807927" rel="nofollow">单击查看更清晰的图片</a></div><br /><p>X264编码器主干部分的函数调用关系如下图所示。</p><div style="text-align: center;"><a target=_blank target="_blank" href="http://img.my.csdn.net/uploads/201505/14/1431582266_9992.jpg" rel="nofollow"><img src="https://img-blog.csdn.net/20150514134431937" alt="" />&nbsp;</a></div><div style="text-align: center;"><a target=_blank target="_blank" href="https://my.csdn.net/leixiaohua1020/album/detail/1808305" rel="nofollow">单击查看更清晰的图片</a></div><br /><span style="white-space:pre">	</span>从图中可以看出，x264主干部分最复杂的函数就是x264_encoder_encode()，该函数完成了编码一帧YUV为H.264码流的工作。与之配合的还有打开编码器的函数x264_encoder_open()，关闭编码器的函数x264_encoder_close()，以及输出SPS/PPS/SEI这样的头信息的x264_encoder_headers()。<br /><br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_encoder_open()用于打开编码器，其中初始化了libx264编码所需要的各种变量。它调用了下面的函数：<blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_validate_parameters()：检查输入参数（例如输入图像的宽高是否为正数）。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_predict_16x16_init()：初始化Intra16x16帧内预测汇编函数。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_predict_4x4_init()：初始化Intra4x4帧内预测汇编函数。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_pixel_init()：初始化像素值计算相关的汇编函数（包括SAD、SATD、SSD等）。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_dct_init()：初始化DCT变换和DCT反变换相关的汇编函数。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_mc_init()：初始化运动补偿相关的汇编函数。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_quant_init()：初始化量化和反量化相关的汇编函数。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_deblock_init()：初始化去块效应滤波器相关的汇编函数。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_lookahead_init()：初始化Lookahead相关的变量。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_ratecontrol_new()：初始化码率控制相关的变量。</blockquote></blockquote><br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_encoder_headers()输出SPS/PPS/SEI这些H.264码流的头信息。它调用了下面的函数：<blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_sps_write()：输出SPS</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_pps_write()：输出PPS</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_sei_version_write()：输出SEI</blockquote></blockquote><br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_encoder_encode()编码一帧YUV为H.264码流。它调用了下面的函数：<br /></blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;"><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_frame_pop_unused()：获取1个x264_frame_t类型结构体fenc。如果frames.unused[]队列不为空，就调用x264_frame_pop()从unused[]队列取1个现成的；否则就调用x264_frame_new()创建一个新的。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_frame_copy_picture()：将输入的图像数据拷贝至fenc。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_lookahead_put_frame()：将fenc放入lookahead.next.list[]队列，等待确定帧类型。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_lookahead_get_frames()：通过lookahead分析帧类型。该函数调用了x264_slicetype_decide()，x264_slicetype_analyse()和x264_slicetype_frame_cost()等函数。经过一些列分析之后，最终确定了帧类型信息，并且将帧放入frames.current[]队列。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_frame_shift()：从frames.current[]队列取出1帧用于编码。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_reference_update()：更新参考帧列表。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_reference_reset()：如果为IDR帧，调用该函数清空参考帧列表。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_reference_hierarchy_reset()：如果是I（非IDR帧）、P帧、B帧（可做为参考帧），调用该函数。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_reference_build_list()：创建参考帧列表list0和list1。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_ratecontrol_start()：开启码率控制。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_slice_init()：创建 Slice Header。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_slices_write()：编码数据（最关键的步骤）。其中调用了x264_slice_write()完成了编码的工作（注意“x264_slices_write()”和“x264_slice_write()”名字差了一个“s”）。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_encoder_frame_end()：编码结束后做一些后续处理，例如记录一些统计信息。其中调用了x264_frame_push_unused()将fenc重新放回frames.unused[]队列，并且调用x264_ratecontrol_end()关闭码率控制。</blockquote></blockquote><br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_encoder_close()用于关闭解码器，同时输出一些统计信息。它调用了下面的函数：<br /></blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;"><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_lookahead_delete()：释放Lookahead相关的变量。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_ratecontrol_summary()：汇总码率控制信息。</blockquote><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;"><p>x264_ratecontrol_delete()：关闭码率控制。</p></blockquote></blockquote><p><br /></p><p>本文将会记录x264_encoder_open()，x264_encoder_headers()，和x264_encoder_close()这三个函数的源代码。下一篇文章记录x264_encoder_encode()函数。</p><br /><br /><h1>x264_encoder_open()</h1><p>x264_encoder_open()是一个libx264的API。该函数用于打开编码器，其中初始化了libx264编码所需要的各种变量。该函数的声明如下所示。</p><pre name="code" class="cpp">/* x264_encoder_open:
 *      create a new encoder handler, all parameters from x264_param_t are copied */
x264_t *x264_encoder_open( x264_param_t * );</pre>x264_encoder_open()的定义位于encoder\encoder.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_2_2086697" name="code" class="cpp">/****************************************************************************
 * x264_encoder_open:
* 注释和处理：雷霄骅
* http://blog.csdn.net/leixiaohua1020
* leixiaohua1020@126.com
 ****************************************************************************/
//打开编码器
x264_t *x264_encoder_open( x264_param_t *param )
{
    x264_t *h;
    char buf[1000], *p;
    int qp, i_slicetype_length;

    CHECKED_MALLOCZERO( h, sizeof(x264_t) );

    /* Create a copy of param */
    //将参数拷贝进来
    memcpy( &amp;h-&gt;param, param, sizeof(x264_param_t) );

    if( param-&gt;param_free )
        param-&gt;param_free( param );

    if( x264_threading_init() )
    {
        x264_log( h, X264_LOG_ERROR, &quot;unable to initialize threading\n&quot; );
        goto fail;
    }
    //检查输入参数
    if( x264_validate_parameters( h, 1 ) &lt; 0 )
        goto fail;

    if( h-&gt;param.psz_cqm_file )
        if( x264_cqm_parse_file( h, h-&gt;param.psz_cqm_file ) &lt; 0 )
            goto fail;

    if( h-&gt;param.rc.psz_stat_out )
        h-&gt;param.rc.psz_stat_out = strdup( h-&gt;param.rc.psz_stat_out );
    if( h-&gt;param.rc.psz_stat_in )
        h-&gt;param.rc.psz_stat_in = strdup( h-&gt;param.rc.psz_stat_in );

    x264_reduce_fraction( &amp;h-&gt;param.i_fps_num, &amp;h-&gt;param.i_fps_den );
    x264_reduce_fraction( &amp;h-&gt;param.i_timebase_num, &amp;h-&gt;param.i_timebase_den );

    /* Init x264_t */
    h-&gt;i_frame = -1;
    h-&gt;i_frame_num = 0;

    if( h-&gt;param.i_avcintra_class )
        h-&gt;i_idr_pic_id = 5;
    else
        h-&gt;i_idr_pic_id = 0;

    if( (uint64_t)h-&gt;param.i_timebase_den * 2 &gt; UINT32_MAX )
    {
        x264_log( h, X264_LOG_ERROR, &quot;Effective timebase denominator %u exceeds H.264 maximum\n&quot;, h-&gt;param.i_timebase_den );
        goto fail;
    }

    x264_set_aspect_ratio( h, &amp;h-&gt;param, 1 );
    //初始化SPS和PPS
    x264_sps_init( h-&gt;sps, h-&gt;param.i_sps_id, &amp;h-&gt;param );
    x264_pps_init( h-&gt;pps, h-&gt;param.i_sps_id, &amp;h-&gt;param, h-&gt;sps );
    //检查级Level-通过宏块个数等等
    x264_validate_levels( h, 1 );

    h-&gt;chroma_qp_table = i_chroma_qp_table + 12 + h-&gt;pps-&gt;i_chroma_qp_index_offset;

    if( x264_cqm_init( h ) &lt; 0 )
        goto fail;
    //各种赋值
    h-&gt;mb.i_mb_width = h-&gt;sps-&gt;i_mb_width;
    h-&gt;mb.i_mb_height = h-&gt;sps-&gt;i_mb_height;
    h-&gt;mb.i_mb_count = h-&gt;mb.i_mb_width * h-&gt;mb.i_mb_height;

    h-&gt;mb.chroma_h_shift = CHROMA_FORMAT == CHROMA_420 || CHROMA_FORMAT == CHROMA_422;
    h-&gt;mb.chroma_v_shift = CHROMA_FORMAT == CHROMA_420;

    /* Adaptive MBAFF and subme 0 are not supported as we require halving motion
     * vectors during prediction, resulting in hpel mvs.
     * The chosen solution is to make MBAFF non-adaptive in this case. */
    h-&gt;mb.b_adaptive_mbaff = PARAM_INTERLACED &amp;&amp; h-&gt;param.analyse.i_subpel_refine;

    /* Init frames. */
    if( h-&gt;param.i_bframe_adaptive == X264_B_ADAPT_TRELLIS &amp;&amp; !h-&gt;param.rc.b_stat_read )
        h-&gt;frames.i_delay = X264_MAX(h-&gt;param.i_bframe,3)*4;
    else
        h-&gt;frames.i_delay = h-&gt;param.i_bframe;
    if( h-&gt;param.rc.b_mb_tree || h-&gt;param.rc.i_vbv_buffer_size )
        h-&gt;frames.i_delay = X264_MAX( h-&gt;frames.i_delay, h-&gt;param.rc.i_lookahead );
    i_slicetype_length = h-&gt;frames.i_delay;
    h-&gt;frames.i_delay += h-&gt;i_thread_frames - 1;
    h-&gt;frames.i_delay += h-&gt;param.i_sync_lookahead;
    h-&gt;frames.i_delay += h-&gt;param.b_vfr_input;
    h-&gt;frames.i_bframe_delay = h-&gt;param.i_bframe ? (h-&gt;param.i_bframe_pyramid ? 2 : 1) : 0;

    h-&gt;frames.i_max_ref0 = h-&gt;param.i_frame_reference;
    h-&gt;frames.i_max_ref1 = X264_MIN( h-&gt;sps-&gt;vui.i_num_reorder_frames, h-&gt;param.i_frame_reference );
    h-&gt;frames.i_max_dpb  = h-&gt;sps-&gt;vui.i_max_dec_frame_buffering;
    h-&gt;frames.b_have_lowres = !h-&gt;param.rc.b_stat_read
        &amp;&amp; ( h-&gt;param.rc.i_rc_method == X264_RC_ABR
          || h-&gt;param.rc.i_rc_method == X264_RC_CRF
          || h-&gt;param.i_bframe_adaptive
          || h-&gt;param.i_scenecut_threshold
          || h-&gt;param.rc.b_mb_tree
          || h-&gt;param.analyse.i_weighted_pred );
    h-&gt;frames.b_have_lowres |= h-&gt;param.rc.b_stat_read &amp;&amp; h-&gt;param.rc.i_vbv_buffer_size &gt; 0;
    h-&gt;frames.b_have_sub8x8_esa = !!(h-&gt;param.analyse.inter &amp; X264_ANALYSE_PSUB8x8);

    h-&gt;frames.i_last_idr =
    h-&gt;frames.i_last_keyframe = - h-&gt;param.i_keyint_max;
    h-&gt;frames.i_input    = 0;
    h-&gt;frames.i_largest_pts = h-&gt;frames.i_second_largest_pts = -1;
    h-&gt;frames.i_poc_last_open_gop = -1;
    //CHECKED_MALLOCZERO(var, size)
    //调用malloc()分配内存,然后调用memset()置零
    CHECKED_MALLOCZERO( h-&gt;frames.unused[0], (h-&gt;frames.i_delay + 3) * sizeof(x264_frame_t *) );
    /* Allocate room for max refs plus a few extra just in case. */
    CHECKED_MALLOCZERO( h-&gt;frames.unused[1], (h-&gt;i_thread_frames + X264_REF_MAX + 4) * sizeof(x264_frame_t *) );
    CHECKED_MALLOCZERO( h-&gt;frames.current, (h-&gt;param.i_sync_lookahead + h-&gt;param.i_bframe
                        + h-&gt;i_thread_frames + 3) * sizeof(x264_frame_t *) );
    if( h-&gt;param.analyse.i_weighted_pred &gt; 0 )
        CHECKED_MALLOCZERO( h-&gt;frames.blank_unused, h-&gt;i_thread_frames * 4 * sizeof(x264_frame_t *) );
    h-&gt;i_ref[0] = h-&gt;i_ref[1] = 0;
    h-&gt;i_cpb_delay = h-&gt;i_coded_fields = h-&gt;i_disp_fields = 0;
    h-&gt;i_prev_duration = ((uint64_t)h-&gt;param.i_fps_den * h-&gt;sps-&gt;vui.i_time_scale) / ((uint64_t)h-&gt;param.i_fps_num * h-&gt;sps-&gt;vui.i_num_units_in_tick);
    h-&gt;i_disp_fields_last_frame = -1;
    //RDO初始化
    x264_rdo_init();

    /* init CPU functions */
    //初始化包含汇编优化的函数
    //帧内预测
    x264_predict_16x16_init( h-&gt;param.cpu, h-&gt;predict_16x16 );
    x264_predict_8x8c_init( h-&gt;param.cpu, h-&gt;predict_8x8c );
    x264_predict_8x16c_init( h-&gt;param.cpu, h-&gt;predict_8x16c );
    x264_predict_8x8_init( h-&gt;param.cpu, h-&gt;predict_8x8, &amp;h-&gt;predict_8x8_filter );
    x264_predict_4x4_init( h-&gt;param.cpu, h-&gt;predict_4x4 );
    //SAD等和像素计算有关的函数
    x264_pixel_init( h-&gt;param.cpu, &amp;h-&gt;pixf );
    //DCT
    x264_dct_init( h-&gt;param.cpu, &amp;h-&gt;dctf );
    //“之”字扫描
    x264_zigzag_init( h-&gt;param.cpu, &amp;h-&gt;zigzagf_progressive, &amp;h-&gt;zigzagf_interlaced );
    memcpy( &amp;h-&gt;zigzagf, PARAM_INTERLACED ? &amp;h-&gt;zigzagf_interlaced : &amp;h-&gt;zigzagf_progressive, sizeof(h-&gt;zigzagf) );
    //运动补偿
    x264_mc_init( h-&gt;param.cpu, &amp;h-&gt;mc, h-&gt;param.b_cpu_independent );
    //量化
    x264_quant_init( h, h-&gt;param.cpu, &amp;h-&gt;quantf );
    //去块效应滤波
    x264_deblock_init( h-&gt;param.cpu, &amp;h-&gt;loopf, PARAM_INTERLACED );
    x264_bitstream_init( h-&gt;param.cpu, &amp;h-&gt;bsf );
    //初始化CABAC或者是CAVLC
    if( h-&gt;param.b_cabac )
        x264_cabac_init( h );
    else
        x264_stack_align( x264_cavlc_init, h );

    //决定了像素比较的时候用SAD还是SATD
    mbcmp_init( h );
    chroma_dsp_init( h );
    //CPU属性
    p = buf + sprintf( buf, &quot;using cpu capabilities:&quot; );
    for( int i = 0; x264_cpu_names[i].flags; i++ )
    {
        if( !strcmp(x264_cpu_names[i].name, &quot;SSE&quot;)
            &amp;&amp; h-&gt;param.cpu &amp; (X264_CPU_SSE2) )
            continue;
        if( !strcmp(x264_cpu_names[i].name, &quot;SSE2&quot;)
            &amp;&amp; h-&gt;param.cpu &amp; (X264_CPU_SSE2_IS_FAST|X264_CPU_SSE2_IS_SLOW) )
            continue;
        if( !strcmp(x264_cpu_names[i].name, &quot;SSE3&quot;)
            &amp;&amp; (h-&gt;param.cpu &amp; X264_CPU_SSSE3 || !(h-&gt;param.cpu &amp; X264_CPU_CACHELINE_64)) )
            continue;
        if( !strcmp(x264_cpu_names[i].name, &quot;SSE4.1&quot;)
            &amp;&amp; (h-&gt;param.cpu &amp; X264_CPU_SSE42) )
            continue;
        if( !strcmp(x264_cpu_names[i].name, &quot;BMI1&quot;)
            &amp;&amp; (h-&gt;param.cpu &amp; X264_CPU_BMI2) )
            continue;
        if( (h-&gt;param.cpu &amp; x264_cpu_names[i].flags) == x264_cpu_names[i].flags
            &amp;&amp; (!i || x264_cpu_names[i].flags != x264_cpu_names[i-1].flags) )
            p += sprintf( p, &quot; %s&quot;, x264_cpu_names[i].name );
    }
    if( !h-&gt;param.cpu )
        p += sprintf( p, &quot; none!&quot; );
    x264_log( h, X264_LOG_INFO, &quot;%s\n&quot;, buf );

    float *logs = x264_analyse_prepare_costs( h );
    if( !logs )
        goto fail;
    for( qp = X264_MIN( h-&gt;param.rc.i_qp_min, QP_MAX_SPEC ); qp &lt;= h-&gt;param.rc.i_qp_max; qp++ )
        if( x264_analyse_init_costs( h, logs, qp ) )
            goto fail;
    if( x264_analyse_init_costs( h, logs, X264_LOOKAHEAD_QP ) )
        goto fail;
    x264_free( logs );

    static const uint16_t cost_mv_correct[7] = { 24, 47, 95, 189, 379, 757, 1515 };
    /* Checks for known miscompilation issues. */
    if( h-&gt;cost_mv[X264_LOOKAHEAD_QP][2013] != cost_mv_correct[BIT_DEPTH-8] )
    {
        x264_log( h, X264_LOG_ERROR, &quot;MV cost test failed: x264 has been miscompiled!\n&quot; );
        goto fail;
    }

    /* Must be volatile or else GCC will optimize it out. */
    volatile int temp = 392;
    if( x264_clz( temp ) != 23 )
    {
        x264_log( h, X264_LOG_ERROR, &quot;CLZ test failed: x264 has been miscompiled!\n&quot; );
#if ARCH_X86 || ARCH_X86_64
        x264_log( h, X264_LOG_ERROR, &quot;Are you attempting to run an SSE4a/LZCNT-targeted build on a CPU that\n&quot; );
        x264_log( h, X264_LOG_ERROR, &quot;doesn't support it?\n&quot; );
#endif
        goto fail;
    }

    h-&gt;out.i_nal = 0;
    h-&gt;out.i_bitstream = X264_MAX( 1000000, h-&gt;param.i_width * h-&gt;param.i_height * 4
        * ( h-&gt;param.rc.i_rc_method == X264_RC_ABR ? pow( 0.95, h-&gt;param.rc.i_qp_min )
          : pow( 0.95, h-&gt;param.rc.i_qp_constant ) * X264_MAX( 1, h-&gt;param.rc.f_ip_factor )));

    h-&gt;nal_buffer_size = h-&gt;out.i_bitstream * 3/2 + 4 + 64; /* +4 for startcode, +64 for nal_escape assembly padding */
    CHECKED_MALLOC( h-&gt;nal_buffer, h-&gt;nal_buffer_size );

    CHECKED_MALLOC( h-&gt;reconfig_h, sizeof(x264_t) );

    if( h-&gt;param.i_threads &gt; 1 &amp;&amp;
        x264_threadpool_init( &amp;h-&gt;threadpool, h-&gt;param.i_threads, (void*)x264_encoder_thread_init, h ) )
        goto fail;
    if( h-&gt;param.i_lookahead_threads &gt; 1 &amp;&amp;
        x264_threadpool_init( &amp;h-&gt;lookaheadpool, h-&gt;param.i_lookahead_threads, NULL, NULL ) )
        goto fail;

#if HAVE_OPENCL
    if( h-&gt;param.b_opencl )
    {
        h-&gt;opencl.ocl = x264_opencl_load_library();
        if( !h-&gt;opencl.ocl )
        {
            x264_log( h, X264_LOG_WARNING, &quot;failed to load OpenCL\n&quot; );
            h-&gt;param.b_opencl = 0;
        }
    }
#endif

    h-&gt;thread[0] = h;
    for( int i = 1; i &lt; h-&gt;param.i_threads + !!h-&gt;param.i_sync_lookahead; i++ )
        CHECKED_MALLOC( h-&gt;thread[i], sizeof(x264_t) );
    if( h-&gt;param.i_lookahead_threads &gt; 1 )
        for( int i = 0; i &lt; h-&gt;param.i_lookahead_threads; i++ )
        {
            CHECKED_MALLOC( h-&gt;lookahead_thread[i], sizeof(x264_t) );
            *h-&gt;lookahead_thread[i] = *h;
        }
    *h-&gt;reconfig_h = *h;

    for( int i = 0; i &lt; h-&gt;param.i_threads; i++ )
    {
        int init_nal_count = h-&gt;param.i_slice_count + 3;
        int allocate_threadlocal_data = !h-&gt;param.b_sliced_threads || !i;
        if( i &gt; 0 )
            *h-&gt;thread[i] = *h;

        if( x264_pthread_mutex_init( &amp;h-&gt;thread[i]-&gt;mutex, NULL ) )
            goto fail;
        if( x264_pthread_cond_init( &amp;h-&gt;thread[i]-&gt;cv, NULL ) )
            goto fail;

        if( allocate_threadlocal_data )
        {
            h-&gt;thread[i]-&gt;fdec = x264_frame_pop_unused( h, 1 );
            if( !h-&gt;thread[i]-&gt;fdec )
                goto fail;
        }
        else
            h-&gt;thread[i]-&gt;fdec = h-&gt;thread[0]-&gt;fdec;

        CHECKED_MALLOC( h-&gt;thread[i]-&gt;out.p_bitstream, h-&gt;out.i_bitstream );
        /* Start each thread with room for init_nal_count NAL units; it'll realloc later if needed. */
        CHECKED_MALLOC( h-&gt;thread[i]-&gt;out.nal, init_nal_count*sizeof(x264_nal_t) );
        h-&gt;thread[i]-&gt;out.i_nals_allocated = init_nal_count;

        if( allocate_threadlocal_data &amp;&amp; x264_macroblock_cache_allocate( h-&gt;thread[i] ) &lt; 0 )
            goto fail;
    }

#if HAVE_OPENCL
    if( h-&gt;param.b_opencl &amp;&amp; x264_opencl_lookahead_init( h ) &lt; 0 )
        h-&gt;param.b_opencl = 0;
#endif
    //初始化lookahead
    if( x264_lookahead_init( h, i_slicetype_length ) )
        goto fail;

    for( int i = 0; i &lt; h-&gt;param.i_threads; i++ )
        if( x264_macroblock_thread_allocate( h-&gt;thread[i], 0 ) &lt; 0 )
            goto fail;
    //创建码率控制
    if( x264_ratecontrol_new( h ) &lt; 0 )
        goto fail;

    if( h-&gt;param.i_nal_hrd )
    {
        x264_log( h, X264_LOG_DEBUG, &quot;HRD bitrate: %i bits/sec\n&quot;, h-&gt;sps-&gt;vui.hrd.i_bit_rate_unscaled );
        x264_log( h, X264_LOG_DEBUG, &quot;CPB size: %i bits\n&quot;, h-&gt;sps-&gt;vui.hrd.i_cpb_size_unscaled );
    }

    if( h-&gt;param.psz_dump_yuv )
    {
        /* create or truncate the reconstructed video file */
        FILE *f = x264_fopen( h-&gt;param.psz_dump_yuv, &quot;w&quot; );
        if( !f )
        {
            x264_log( h, X264_LOG_ERROR, &quot;dump_yuv: can't write to %s\n&quot;, h-&gt;param.psz_dump_yuv );
            goto fail;
        }
        else if( !x264_is_regular_file( f ) )
        {
            x264_log( h, X264_LOG_ERROR, &quot;dump_yuv: incompatible with non-regular file %s\n&quot;, h-&gt;param.psz_dump_yuv );
            goto fail;
        }
        fclose( f );
    }
    //这写法......
    const char *profile = h-&gt;sps-&gt;i_profile_idc == PROFILE_BASELINE ? &quot;Constrained Baseline&quot; :
                          h-&gt;sps-&gt;i_profile_idc == PROFILE_MAIN ? &quot;Main&quot; :
                          h-&gt;sps-&gt;i_profile_idc == PROFILE_HIGH ? &quot;High&quot; :
                          h-&gt;sps-&gt;i_profile_idc == PROFILE_HIGH10 ? (h-&gt;sps-&gt;b_constraint_set3 == 1 ? &quot;High 10 Intra&quot; : &quot;High 10&quot;) :
                          h-&gt;sps-&gt;i_profile_idc == PROFILE_HIGH422 ? (h-&gt;sps-&gt;b_constraint_set3 == 1 ? &quot;High 4:2:2 Intra&quot; : &quot;High 4:2:2&quot;) :
                          h-&gt;sps-&gt;b_constraint_set3 == 1 ? &quot;High 4:4:4 Intra&quot; : &quot;High 4:4:4 Predictive&quot;;
    char level[4];
    snprintf( level, sizeof(level), &quot;%d.%d&quot;, h-&gt;sps-&gt;i_level_idc/10, h-&gt;sps-&gt;i_level_idc%10 );
    if( h-&gt;sps-&gt;i_level_idc == 9 || ( h-&gt;sps-&gt;i_level_idc == 11 &amp;&amp; h-&gt;sps-&gt;b_constraint_set3 &amp;&amp;
        (h-&gt;sps-&gt;i_profile_idc == PROFILE_BASELINE || h-&gt;sps-&gt;i_profile_idc == PROFILE_MAIN) ) )
        strcpy( level, &quot;1b&quot; );
    //输出型和级
    if( h-&gt;sps-&gt;i_profile_idc &lt; PROFILE_HIGH10 )
    {
        x264_log( h, X264_LOG_INFO, &quot;profile %s, level %s\n&quot;,
            profile, level );
    }
    else
    {
        static const char * const subsampling[4] = { &quot;4:0:0&quot;, &quot;4:2:0&quot;, &quot;4:2:2&quot;, &quot;4:4:4&quot; };
        x264_log( h, X264_LOG_INFO, &quot;profile %s, level %s, %s %d-bit\n&quot;,
            profile, level, subsampling[CHROMA_FORMAT], BIT_DEPTH );
    }

    return h;
fail:
	//释放
    x264_free( h );
    return NULL;
}
</pre><br />由于源代码中已经做了比较详细的注释，在这里就不重复叙述了。下面根据函数调用的顺序，看一下x264_encoder_open()调用的下面几个函数：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">x264_sps_init()：根据输入参数生成H.264码流的SPS信息。<br />x264_pps_init()：根据输入参数生成H.264码流的PPS信息。<br />x264_predict_16x16_init()：初始化Intra16x16帧内预测汇编函数。<br />x264_predict_4x4_init()：初始化Intra4x4帧内预测汇编函数。<br />x264_pixel_init()：初始化像素值计算相关的汇编函数（包括SAD、SATD、SSD等）。<br />x264_dct_init()：初始化DCT变换和DCT反变换相关的汇编函数。<br />x264_mc_init()：初始化运动补偿相关的汇编函数。<br />x264_quant_init()：初始化量化和反量化相关的汇编函数。<br />x264_deblock_init()：初始化去块效应滤波器相关的汇编函数。<br />mbcmp_init()：决定像素比较的时候使用SAD还是SATD。</blockquote><br /><h2>x264_sps_init()</h2>x264_sps_init()根据输入参数生成H.264码流的SPS （Sequence Parameter Set，序列参数集）信息。该函数的定义位于encoder\set.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_3_106758" name="code" class="cpp">//初始化SPS
void x264_sps_init( x264_sps_t *sps, int i_id, x264_param_t *param )
{
    int csp = param-&gt;i_csp &amp; X264_CSP_MASK;

    sps-&gt;i_id = i_id;
    //以宏块为单位的宽度
    sps-&gt;i_mb_width = ( param-&gt;i_width + 15 ) / 16;
    //以宏块为单位的高度
    sps-&gt;i_mb_height= ( param-&gt;i_height + 15 ) / 16;
    //色度取样格式
    sps-&gt;i_chroma_format_idc = csp &gt;= X264_CSP_I444 ? CHROMA_444 :
                               csp &gt;= X264_CSP_I422 ? CHROMA_422 : CHROMA_420;

    sps-&gt;b_qpprime_y_zero_transform_bypass = param-&gt;rc.i_rc_method == X264_RC_CQP &amp;&amp; param-&gt;rc.i_qp_constant == 0;
    //型profile
    if( sps-&gt;b_qpprime_y_zero_transform_bypass || sps-&gt;i_chroma_format_idc == CHROMA_444 )
        sps-&gt;i_profile_idc  = PROFILE_HIGH444_PREDICTIVE;//YUV444的时候
    else if( sps-&gt;i_chroma_format_idc == CHROMA_422 )
        sps-&gt;i_profile_idc  = PROFILE_HIGH422;
    else if( BIT_DEPTH &gt; 8 )
        sps-&gt;i_profile_idc  = PROFILE_HIGH10;
    else if( param-&gt;analyse.b_transform_8x8 || param-&gt;i_cqm_preset != X264_CQM_FLAT )
        sps-&gt;i_profile_idc  = PROFILE_HIGH;//高型 High Profile 目前最常见
    else if( param-&gt;b_cabac || param-&gt;i_bframe &gt; 0 || param-&gt;b_interlaced || param-&gt;b_fake_interlaced || param-&gt;analyse.i_weighted_pred &gt; 0 )
        sps-&gt;i_profile_idc  = PROFILE_MAIN;//主型
    else
        sps-&gt;i_profile_idc  = PROFILE_BASELINE;//基本型

    sps-&gt;b_constraint_set0  = sps-&gt;i_profile_idc == PROFILE_BASELINE;
    /* x264 doesn't support the features that are in Baseline and not in Main,
     * namely arbitrary_slice_order and slice_groups. */
    sps-&gt;b_constraint_set1  = sps-&gt;i_profile_idc &lt;= PROFILE_MAIN;
    /* Never set constraint_set2, it is not necessary and not used in real world. */
    sps-&gt;b_constraint_set2  = 0;
    sps-&gt;b_constraint_set3  = 0;
    //级level
    sps-&gt;i_level_idc = param-&gt;i_level_idc;
    if( param-&gt;i_level_idc == 9 &amp;&amp; ( sps-&gt;i_profile_idc == PROFILE_BASELINE || sps-&gt;i_profile_idc == PROFILE_MAIN ) )
    {
        sps-&gt;b_constraint_set3 = 1; /* level 1b with Baseline or Main profile is signalled via constraint_set3 */
        sps-&gt;i_level_idc      = 11;
    }
    /* Intra profiles */
    if( param-&gt;i_keyint_max == 1 &amp;&amp; sps-&gt;i_profile_idc &gt; PROFILE_HIGH )
        sps-&gt;b_constraint_set3 = 1;

    sps-&gt;vui.i_num_reorder_frames = param-&gt;i_bframe_pyramid ? 2 : param-&gt;i_bframe ? 1 : 0;
    /* extra slot with pyramid so that we don't have to override the
     * order of forgetting old pictures */
    //参考帧数量
    sps-&gt;vui.i_max_dec_frame_buffering =
    sps-&gt;i_num_ref_frames = X264_MIN(X264_REF_MAX, X264_MAX4(param-&gt;i_frame_reference, 1 + sps-&gt;vui.i_num_reorder_frames,
                            param-&gt;i_bframe_pyramid ? 4 : 1, param-&gt;i_dpb_size));
    sps-&gt;i_num_ref_frames -= param-&gt;i_bframe_pyramid == X264_B_PYRAMID_STRICT;
    if( param-&gt;i_keyint_max == 1 )
    {
        sps-&gt;i_num_ref_frames = 0;
        sps-&gt;vui.i_max_dec_frame_buffering = 0;
    }

    /* number of refs + current frame */
    int max_frame_num = sps-&gt;vui.i_max_dec_frame_buffering * (!!param-&gt;i_bframe_pyramid+1) + 1;
    /* Intra refresh cannot write a recovery time greater than max frame num-1 */
    if( param-&gt;b_intra_refresh )
    {
        int time_to_recovery = X264_MIN( sps-&gt;i_mb_width - 1, param-&gt;i_keyint_max ) + param-&gt;i_bframe - 1;
        max_frame_num = X264_MAX( max_frame_num, time_to_recovery+1 );
    }

    sps-&gt;i_log2_max_frame_num = 4;
    while( (1 &lt;&lt; sps-&gt;i_log2_max_frame_num) &lt;= max_frame_num )
        sps-&gt;i_log2_max_frame_num++;
    //POC类型
    sps-&gt;i_poc_type = param-&gt;i_bframe || param-&gt;b_interlaced ? 0 : 2;
    if( sps-&gt;i_poc_type == 0 )
    {
        int max_delta_poc = (param-&gt;i_bframe + 2) * (!!param-&gt;i_bframe_pyramid + 1) * 2;
        sps-&gt;i_log2_max_poc_lsb = 4;
        while( (1 &lt;&lt; sps-&gt;i_log2_max_poc_lsb) &lt;= max_delta_poc * 2 )
            sps-&gt;i_log2_max_poc_lsb++;
    }

    sps-&gt;b_vui = 1;

    sps-&gt;b_gaps_in_frame_num_value_allowed = 0;
    sps-&gt;b_frame_mbs_only = !(param-&gt;b_interlaced || param-&gt;b_fake_interlaced);
    if( !sps-&gt;b_frame_mbs_only )
        sps-&gt;i_mb_height = ( sps-&gt;i_mb_height + 1 ) &amp; ~1;
    sps-&gt;b_mb_adaptive_frame_field = param-&gt;b_interlaced;
    sps-&gt;b_direct8x8_inference = 1;

    sps-&gt;crop.i_left   = param-&gt;crop_rect.i_left;
    sps-&gt;crop.i_top    = param-&gt;crop_rect.i_top;
    sps-&gt;crop.i_right  = param-&gt;crop_rect.i_right + sps-&gt;i_mb_width*16 - param-&gt;i_width;
    sps-&gt;crop.i_bottom = (param-&gt;crop_rect.i_bottom + sps-&gt;i_mb_height*16 - param-&gt;i_height) &gt;&gt; !sps-&gt;b_frame_mbs_only;
    sps-&gt;b_crop = sps-&gt;crop.i_left  || sps-&gt;crop.i_top ||
                  sps-&gt;crop.i_right || sps-&gt;crop.i_bottom;

    sps-&gt;vui.b_aspect_ratio_info_present = 0;
    if( param-&gt;vui.i_sar_width &gt; 0 &amp;&amp; param-&gt;vui.i_sar_height &gt; 0 )
    {
        sps-&gt;vui.b_aspect_ratio_info_present = 1;
        sps-&gt;vui.i_sar_width = param-&gt;vui.i_sar_width;
        sps-&gt;vui.i_sar_height= param-&gt;vui.i_sar_height;
    }

    sps-&gt;vui.b_overscan_info_present = param-&gt;vui.i_overscan &gt; 0 &amp;&amp; param-&gt;vui.i_overscan &lt;= 2;
    if( sps-&gt;vui.b_overscan_info_present )
        sps-&gt;vui.b_overscan_info = ( param-&gt;vui.i_overscan == 2 ? 1 : 0 );

    sps-&gt;vui.b_signal_type_present = 0;
    sps-&gt;vui.i_vidformat = ( param-&gt;vui.i_vidformat &gt;= 0 &amp;&amp; param-&gt;vui.i_vidformat &lt;= 5 ? param-&gt;vui.i_vidformat : 5 );
    sps-&gt;vui.b_fullrange = ( param-&gt;vui.b_fullrange &gt;= 0 &amp;&amp; param-&gt;vui.b_fullrange &lt;= 1 ? param-&gt;vui.b_fullrange :
                           ( csp &gt;= X264_CSP_BGR ? 1 : 0 ) );
    sps-&gt;vui.b_color_description_present = 0;

    sps-&gt;vui.i_colorprim = ( param-&gt;vui.i_colorprim &gt;= 0 &amp;&amp; param-&gt;vui.i_colorprim &lt;=  9 ? param-&gt;vui.i_colorprim : 2 );
    sps-&gt;vui.i_transfer  = ( param-&gt;vui.i_transfer  &gt;= 0 &amp;&amp; param-&gt;vui.i_transfer  &lt;= 15 ? param-&gt;vui.i_transfer  : 2 );
    sps-&gt;vui.i_colmatrix = ( param-&gt;vui.i_colmatrix &gt;= 0 &amp;&amp; param-&gt;vui.i_colmatrix &lt;= 10 ? param-&gt;vui.i_colmatrix :
                           ( csp &gt;= X264_CSP_BGR ? 0 : 2 ) );
    if( sps-&gt;vui.i_colorprim != 2 ||
        sps-&gt;vui.i_transfer  != 2 ||
        sps-&gt;vui.i_colmatrix != 2 )
    {
        sps-&gt;vui.b_color_description_present = 1;
    }

    if( sps-&gt;vui.i_vidformat != 5 ||
        sps-&gt;vui.b_fullrange ||
        sps-&gt;vui.b_color_description_present )
    {
        sps-&gt;vui.b_signal_type_present = 1;
    }

    /* FIXME: not sufficient for interlaced video */
    sps-&gt;vui.b_chroma_loc_info_present = param-&gt;vui.i_chroma_loc &gt; 0 &amp;&amp; param-&gt;vui.i_chroma_loc &lt;= 5 &amp;&amp;
                                         sps-&gt;i_chroma_format_idc == CHROMA_420;
    if( sps-&gt;vui.b_chroma_loc_info_present )
    {
        sps-&gt;vui.i_chroma_loc_top = param-&gt;vui.i_chroma_loc;
        sps-&gt;vui.i_chroma_loc_bottom = param-&gt;vui.i_chroma_loc;
    }

    sps-&gt;vui.b_timing_info_present = param-&gt;i_timebase_num &gt; 0 &amp;&amp; param-&gt;i_timebase_den &gt; 0;

    if( sps-&gt;vui.b_timing_info_present )
    {
        sps-&gt;vui.i_num_units_in_tick = param-&gt;i_timebase_num;
        sps-&gt;vui.i_time_scale = param-&gt;i_timebase_den * 2;
        sps-&gt;vui.b_fixed_frame_rate = !param-&gt;b_vfr_input;
    }

    sps-&gt;vui.b_vcl_hrd_parameters_present = 0; // we don't support VCL HRD
    sps-&gt;vui.b_nal_hrd_parameters_present = !!param-&gt;i_nal_hrd;
    sps-&gt;vui.b_pic_struct_present = param-&gt;b_pic_struct;

    // NOTE: HRD related parts of the SPS are initialised in x264_ratecontrol_init_reconfigurable

    sps-&gt;vui.b_bitstream_restriction = param-&gt;i_keyint_max &gt; 1;
    if( sps-&gt;vui.b_bitstream_restriction )
    {
        sps-&gt;vui.b_motion_vectors_over_pic_boundaries = 1;
        sps-&gt;vui.i_max_bytes_per_pic_denom = 0;
        sps-&gt;vui.i_max_bits_per_mb_denom = 0;
        sps-&gt;vui.i_log2_max_mv_length_horizontal =
        sps-&gt;vui.i_log2_max_mv_length_vertical = (int)log2f( X264_MAX( 1, param-&gt;analyse.i_mv_range*4-1 ) ) + 1;
    }
}
</pre><br />从源代码可以看出，x264_sps_init()根据输入参数集x264_param_t中的信息，初始化了SPS结构体中的成员变量。有关这些成员变量的具体信息，可以参考《H.264标准》。<br /><br /><h2>x264_pps_init()</h2>x264_pps_init()根据输入参数生成H.264码流的PPS（Picture Parameter Set，图像参数集）信息。该函数的定义位于encoder\set.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_4_2172217" name="code" class="cpp">//初始化PPS
void x264_pps_init( x264_pps_t *pps, int i_id, x264_param_t *param, x264_sps_t *sps )
{
    pps-&gt;i_id = i_id;
    //所属的SPS
    pps-&gt;i_sps_id = sps-&gt;i_id;
    //是否使用CABAC？
    pps-&gt;b_cabac = param-&gt;b_cabac;

    pps-&gt;b_pic_order = !param-&gt;i_avcintra_class &amp;&amp; param-&gt;b_interlaced;
    pps-&gt;i_num_slice_groups = 1;
    //目前参考帧队列的长度
    //注意是这个队列中当前实际的、已存在的参考帧数目，这从它的名字“active”中也可以看出来。
    pps-&gt;i_num_ref_idx_l0_default_active = param-&gt;i_frame_reference;
    pps-&gt;i_num_ref_idx_l1_default_active = 1;
    //加权预测
    pps-&gt;b_weighted_pred = param-&gt;analyse.i_weighted_pred &gt; 0;
    pps-&gt;b_weighted_bipred = param-&gt;analyse.b_weighted_bipred ? 2 : 0;
    //量化参数QP的初始值
    pps-&gt;i_pic_init_qp = param-&gt;rc.i_rc_method == X264_RC_ABR || param-&gt;b_stitchable ? 26 + QP_BD_OFFSET : SPEC_QP( param-&gt;rc.i_qp_constant );
    pps-&gt;i_pic_init_qs = 26 + QP_BD_OFFSET;

    pps-&gt;i_chroma_qp_index_offset = param-&gt;analyse.i_chroma_qp_offset;
    pps-&gt;b_deblocking_filter_control = 1;
    pps-&gt;b_constrained_intra_pred = param-&gt;b_constrained_intra;
    pps-&gt;b_redundant_pic_cnt = 0;

    pps-&gt;b_transform_8x8_mode = param-&gt;analyse.b_transform_8x8 ? 1 : 0;

    pps-&gt;i_cqm_preset = param-&gt;i_cqm_preset;

    switch( pps-&gt;i_cqm_preset )
    {
    case X264_CQM_FLAT:
        for( int i = 0; i &lt; 8; i++ )
            pps-&gt;scaling_list[i] = x264_cqm_flat16;
        break;
    case X264_CQM_JVT:
        for( int i = 0; i &lt; 8; i++ )
            pps-&gt;scaling_list[i] = x264_cqm_jvt[i];
        break;
    case X264_CQM_CUSTOM:
        /* match the transposed DCT &amp; zigzag */
        transpose( param-&gt;cqm_4iy, 4 );
        transpose( param-&gt;cqm_4py, 4 );
        transpose( param-&gt;cqm_4ic, 4 );
        transpose( param-&gt;cqm_4pc, 4 );
        transpose( param-&gt;cqm_8iy, 8 );
        transpose( param-&gt;cqm_8py, 8 );
        transpose( param-&gt;cqm_8ic, 8 );
        transpose( param-&gt;cqm_8pc, 8 );
        pps-&gt;scaling_list[CQM_4IY] = param-&gt;cqm_4iy;
        pps-&gt;scaling_list[CQM_4PY] = param-&gt;cqm_4py;
        pps-&gt;scaling_list[CQM_4IC] = param-&gt;cqm_4ic;
        pps-&gt;scaling_list[CQM_4PC] = param-&gt;cqm_4pc;
        pps-&gt;scaling_list[CQM_8IY+4] = param-&gt;cqm_8iy;
        pps-&gt;scaling_list[CQM_8PY+4] = param-&gt;cqm_8py;
        pps-&gt;scaling_list[CQM_8IC+4] = param-&gt;cqm_8ic;
        pps-&gt;scaling_list[CQM_8PC+4] = param-&gt;cqm_8pc;
        for( int i = 0; i &lt; 8; i++ )
            for( int j = 0; j &lt; (i &lt; 4 ? 16 : 64); j++ )
                if( pps-&gt;scaling_list[i][j] == 0 )
                    pps-&gt;scaling_list[i] = x264_cqm_jvt[i];
        break;
    }
}
</pre><br />从源代码可以看出，x264_pps_init()根据输入参数集x264_param_t中的信息，初始化了PPS结构体中的成员变量。有关这些成员变量的具体信息，可以参考《H.264标准》。<br /><br /><h2>x264_predict_16x16_init()</h2>x264_predict_16x16_init()用于初始化Intra16x16帧内预测汇编函数。该函数的定义位于x264\common\predict.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_5_7617983" name="code" class="cpp">//Intra16x16帧内预测汇编函数初始化
void x264_predict_16x16_init( int cpu, x264_predict_t pf[7] )
{
	//C语言版本
	//================================================
	//垂直 Vertical
    pf[I_PRED_16x16_V ]     = x264_predict_16x16_v_c;
    //水平 Horizontal
    pf[I_PRED_16x16_H ]     = x264_predict_16x16_h_c;
    //DC
    pf[I_PRED_16x16_DC]     = x264_predict_16x16_dc_c;
    //Plane
    pf[I_PRED_16x16_P ]     = x264_predict_16x16_p_c;
    //这几种是啥？
    pf[I_PRED_16x16_DC_LEFT]= x264_predict_16x16_dc_left_c;
    pf[I_PRED_16x16_DC_TOP ]= x264_predict_16x16_dc_top_c;
    pf[I_PRED_16x16_DC_128 ]= x264_predict_16x16_dc_128_c;
    //================================================
    //MMX版本
#if HAVE_MMX
    x264_predict_16x16_init_mmx( cpu, pf );
#endif
    //ALTIVEC版本
#if HAVE_ALTIVEC
    if( cpu&amp;X264_CPU_ALTIVEC )
        x264_predict_16x16_init_altivec( pf );
#endif
    //ARMV6版本
#if HAVE_ARMV6
    x264_predict_16x16_init_arm( cpu, pf );
#endif
    //AARCH64版本
#if ARCH_AARCH64
    x264_predict_16x16_init_aarch64( cpu, pf );
#endif
}
</pre><br />从源代码可看出，x264_predict_16x16_init()首先对帧内预测函数指针数组x264_predict_t[]中的元素赋值了C语言版本的函数x264_predict_16x16_v_c()，x264_predict_16x16_h_c()，x264_predict_16x16_dc_c()，x264_predict_16x16_p_c()；然后会判断系统平台的特性，如果平台支持的话，会调用x264_predict_16x16_init_mmx()，x264_predict_16x16_init_arm()等给x264_predict_t[]中的元素赋值经过汇编优化的函数。下文将会简单看几个其中的函数。<br /><br /><h3>相关知识简述</h3><p><span style="white-space:pre">	</span>简单记录一下帧内预测的方法。帧内预测根据宏块左边和上边的边界像素值推算宏块内部的像素值，帧内预测的效果如下图所示。其中左边的图为图像原始画面，右边的图为经过帧内预测后没有叠加残差的画面。</p><p style="text-align: center;"><img src="https://img-blog.csdn.net/20150511152447180?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></p><span style="white-space:pre">	</span>H.264中有两种帧内预测模式：16x16亮度帧内预测模式和4x4亮度帧内预测模式。其中16x16帧内预测模式一共有4种，如下图所示。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511152504371?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><span style="white-space:pre">	</span>这4种模式列表如下。<br /><table border="1" cellspacing="0" cellpadding="0" align="center" witdh="500"> <tbody><tr>  <td valign="top"><p>模式</p></td>  <td valign="top"><p>描述</p></td> </tr> <tr>  <td valign="top"><p>Vertical</p></td>  <td valign="top"><p>由上边像素推出相应像素值</p></td> </tr> <tr>  <td valign="top"><p>Horizontal</p></td>  <td valign="top"><p>由左边像素推出相应像素值</p></td> </tr> <tr>  <td valign="top"><p>DC</p></td>  <td valign="top"><p>由上边和左边像素平均值推出相应像素值</p></td> </tr> <tr>  <td valign="top"><p>Plane</p></td>  <td valign="top"><p>由上边和左边像素推出相应像素值</p></td> </tr></tbody></table><br /><span style="white-space:pre">	</span>4x4帧内预测模式一共有9种，如下图所示。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511152617361?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><span style="white-space:pre">	</span>有关Intra4x4的帧内预测模式的代码将在后文中进行记录。下面举例看一下Intra16x16的Vertical预测模式的实现函数x264_predict_16x16_v_c()。<br /><br /><h3>x264_predict_16x16_v_c()</h3>x264_predict_16x16_v_c()实现了Intra16x16的Vertical预测模式。该函数的定义位于common\predict.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_6_5887649" name="code" class="cpp">//16x16帧内预测
//垂直预测（Vertical）
void x264_predict_16x16_v_c( pixel *src )
{
	/*
	 * Vertical预测方式
	 *   |X1 X2 X3 X4
	 * --+-----------
	 *   |X1 X2 X3 X4
	 *   |X1 X2 X3 X4
	 *   |X1 X2 X3 X4
	 *   |X1 X2 X3 X4
	 *
	 */
	/*
	 * 【展开宏定义】
	 * uint32_t v0 = ((x264_union32_t*)(&amp;src[ 0-FDEC_STRIDE]))-&gt;i;
	 * uint32_t v1 = ((x264_union32_t*)(&amp;src[ 4-FDEC_STRIDE]))-&gt;i;
	 * uint32_t v2 = ((x264_union32_t*)(&amp;src[ 8-FDEC_STRIDE]))-&gt;i;
	 * uint32_t v3 = ((x264_union32_t*)(&amp;src[12-FDEC_STRIDE]))-&gt;i;
	 * 在这里，上述代码实际上相当于：
	 * uint32_t v0 = *((uint32_t*)(&amp;src[ 0-FDEC_STRIDE]));
	 * uint32_t v1 = *((uint32_t*)(&amp;src[ 4-FDEC_STRIDE]));
	 * uint32_t v2 = *((uint32_t*)(&amp;src[ 8-FDEC_STRIDE]));
	 * uint32_t v3 = *((uint32_t*)(&amp;src[12-FDEC_STRIDE]));
	 * 即分成4次，每次取出4个像素（一共16个像素），分别赋值给v0，v1，v2，v3
	 * 取出的值源自于16x16块上面的一行像素
	 *    0|          4          8          12         16
	 *    ||    v0    |    v1    |    v2    |    v3    |
	 * ---++==========+==========+==========+==========+
	 *    ||
	 *    ||
	 *    ||
	 *    ||
	 *    ||
	 *    ||
	 *
	 */
	//pixel4实际上是uint32_t（占用32bit），存储4个像素的值（每个像素占用8bit）

    pixel4 v0 = MPIXEL_X4( &amp;src[ 0-FDEC_STRIDE] );
    pixel4 v1 = MPIXEL_X4( &amp;src[ 4-FDEC_STRIDE] );
    pixel4 v2 = MPIXEL_X4( &amp;src[ 8-FDEC_STRIDE] );
    pixel4 v3 = MPIXEL_X4( &amp;src[12-FDEC_STRIDE] );

    //循环赋值16行
    for( int i = 0; i &lt; 16; i++ )
    {
    	//【展开宏定义】
    	//(((x264_union32_t*)(src+ 0))-&gt;i) = v0;
    	//(((x264_union32_t*)(src+ 4))-&gt;i) = v1;
    	//(((x264_union32_t*)(src+ 8))-&gt;i) = v2;
    	//(((x264_union32_t*)(src+12))-&gt;i) = v3;
    	//即分成4次，每次赋值4个像素
    	//
        MPIXEL_X4( src+ 0 ) = v0;
        MPIXEL_X4( src+ 4 ) = v1;
        MPIXEL_X4( src+ 8 ) = v2;
        MPIXEL_X4( src+12 ) = v3;
        //下一行
        //FDEC_STRIDE=32,是重建宏块缓存fdec_buf一行的数据量
        src += FDEC_STRIDE;
    }
}
</pre><br /><p>从源代码可以看出，x264_predict_16x16_v_c()首先取出了16x16图像块上面一行16个像素的值存储在v0，v1，v2，v3四个变量中（每个变量存储4个像素），然后循环16次将v0，v1，v2，v3赋值给16x16图像块的16行。</p>看完C语言版本Intra16x16的Vertical预测模式的实现函数之后，我们可以继续看一下该预测模式汇编语言版本的实现函数。从前面的初始化函数中已经可以看出，当系统支持X86汇编的时候，会调用x264_predict_16x16_init_mmx()初始化x86汇编优化过的函数；当系统支持ARM的时候，会调用x264_predict_16x16_init_arm()初始化ARM汇编优化过的函数。<br /><br /><h3>x264_predict_16x16_init_mmx()</h3>x264_predict_16x16_init_mmx()用于初始化经过x86汇编优化过的Intra16x16的帧内预测函数。该函数的定义位于common\x86\predict-c.c（在“x86”子文件夹下），如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_7_6283886" name="code" class="cpp">//Intra16x16帧内预测汇编函数-MMX版本
void x264_predict_16x16_init_mmx( int cpu, x264_predict_t pf[7] )
{
    if( !(cpu&amp;X264_CPU_MMX2) )
        return;
    pf[I_PRED_16x16_DC]      = x264_predict_16x16_dc_mmx2;
    pf[I_PRED_16x16_DC_TOP]  = x264_predict_16x16_dc_top_mmx2;
    pf[I_PRED_16x16_DC_LEFT] = x264_predict_16x16_dc_left_mmx2;
    pf[I_PRED_16x16_V]       = x264_predict_16x16_v_mmx2;
    pf[I_PRED_16x16_H]       = x264_predict_16x16_h_mmx2;
#if HIGH_BIT_DEPTH
    if( !(cpu&amp;X264_CPU_SSE) )
        return;
    pf[I_PRED_16x16_V]       = x264_predict_16x16_v_sse;
    if( !(cpu&amp;X264_CPU_SSE2) )
        return;
    pf[I_PRED_16x16_DC]      = x264_predict_16x16_dc_sse2;
    pf[I_PRED_16x16_DC_TOP]  = x264_predict_16x16_dc_top_sse2;
    pf[I_PRED_16x16_DC_LEFT] = x264_predict_16x16_dc_left_sse2;
    pf[I_PRED_16x16_H]       = x264_predict_16x16_h_sse2;
    pf[I_PRED_16x16_P]       = x264_predict_16x16_p_sse2;
    if( !(cpu&amp;X264_CPU_AVX) )
        return;
    pf[I_PRED_16x16_V]       = x264_predict_16x16_v_avx;
    if( !(cpu&amp;X264_CPU_AVX2) )
        return;
    pf[I_PRED_16x16_H]       = x264_predict_16x16_h_avx2;
#else
#if !ARCH_X86_64
    pf[I_PRED_16x16_P]       = x264_predict_16x16_p_mmx2;
#endif
    if( !(cpu&amp;X264_CPU_SSE) )
        return;
    pf[I_PRED_16x16_V]       = x264_predict_16x16_v_sse;
    if( !(cpu&amp;X264_CPU_SSE2) )
        return;
    pf[I_PRED_16x16_DC]      = x264_predict_16x16_dc_sse2;
    if( cpu&amp;X264_CPU_SSE2_IS_SLOW )
        return;
    pf[I_PRED_16x16_DC_TOP]  = x264_predict_16x16_dc_top_sse2;
    pf[I_PRED_16x16_DC_LEFT] = x264_predict_16x16_dc_left_sse2;
    pf[I_PRED_16x16_P]       = x264_predict_16x16_p_sse2;
    if( !(cpu&amp;X264_CPU_SSSE3) )
        return;
    if( !(cpu&amp;X264_CPU_SLOW_PSHUFB) )
        pf[I_PRED_16x16_H]       = x264_predict_16x16_h_ssse3;
#if HAVE_X86_INLINE_ASM
    pf[I_PRED_16x16_P]       = x264_predict_16x16_p_ssse3;
#endif
    if( !(cpu&amp;X264_CPU_AVX) )
        return;
    pf[I_PRED_16x16_P]       = x264_predict_16x16_p_avx;
#endif // HIGH_BIT_DEPTH

    if( cpu&amp;X264_CPU_AVX2 )
    {
        pf[I_PRED_16x16_P]       = x264_predict_16x16_p_avx2;
        pf[I_PRED_16x16_DC]      = x264_predict_16x16_dc_avx2;
        pf[I_PRED_16x16_DC_TOP]  = x264_predict_16x16_dc_top_avx2;
        pf[I_PRED_16x16_DC_LEFT] = x264_predict_16x16_dc_left_avx2;
    }
}
</pre><br />可以看出，针对Intra16x16的Vertical帧内预测模式，x264_predict_16x16_init_mmx()会根据系统的特型初始化2个函数：如果系统仅支持MMX指令集，就会初始化x264_predict_16x16_v_mmx2()；如果系统还支持SSE指令集，就会初始化x264_predict_16x16_v_sse()。下面看一下这2个函数的代码。<br /><br /><h3>x264_predict_16x16_v_mmx2()</h3><h3>x264_predict_16x16_v_sse()</h3>在x264中，x264_predict_16x16_v_mmx2()和x264_predict_16x16_v_sse()这两个函数的定义是写到一起的。它们的定义位于common\x86\predict-a.asm，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_8_6713142" name="code" class="plain">;-----------------------------------------------------------------------------
; void predict_16x16_v( pixel *src )
; Intra16x16帧内预测Vertical模式
;-----------------------------------------------------------------------------
;SIZEOF_PIXEL取值为1
;FDEC_STRIDEB为重建宏块缓存fdec_buf一行像素的大小，取值为32
;
;平台相关的信息位于x86inc.asm
;INIT_MMX中
;  mmsize为8
;  mova为movq
;INIT_XMM中：
;  mmsize为16
;  mova为movdqa
;
;STORE16的定义在前面，用于循环16行存储数据

%macro PREDICT_16x16_V 0
cglobal predict_16x16_v, 1,2
%assign %%i 0
%rep 16*SIZEOF_PIXEL/mmsize                         ;rep循环执行，拷贝16x16块上方的1行像素数据至m0,m1...
                                                    ;mmssize为指令1次处理比特数
    mova m %+ %%i, [r0-FDEC_STRIDEB+%%i*mmsize]     ;移入m0,m1...
%assign %%i %%i+1
%endrep
%if 16*SIZEOF_PIXEL/mmsize == 4                     ;1行需要处理4次
    STORE16 m0, m1, m2, m3                          ;循环存储16行，每次存储4个寄存器
%elif 16*SIZEOF_PIXEL/mmsize == 2                   ;1行需要处理2次
    STORE16 m0, m1                                  ;循环存储16行，每次存储2个寄存器
%else                                               ;1行需要处理1次
    STORE16 m0                                      ;循环存储16行，每次存储1个寄存器
%endif
    RET
%endmacro

INIT_MMX mmx2
PREDICT_16x16_V
INIT_XMM sse
PREDICT_16x16_V
</pre><br />从汇编代码可以看出，x264_predict_16x16_v_mmx2()和x264_predict_16x16_v_sse()的逻辑是一模一样的。它们之间的不同主要在于一条指令处理的数据量：MMX指令的MOVA对应的是MOVQ，一次处理8Byte（8个像素）；SSE指令的MOVA对应的是MOVDQA，一次处理16Byte（16个像素，正好是16x16块中的一行像素）。<br />作为对比，我们可以看一下ARM平台下汇编优化过的Intra16x16的帧内预测函数。这些汇编函数的初始化函数是x264_predict_16x16_init_arm()。<br /><br /><h3>x264_predict_16x16_init_arm()</h3>x264_predict_16x16_init_arm()用于初始化ARM平台下汇编优化过的Intra16x16的帧内预测函数。该函数的定义位于common\arm\predict-c.c（“arm”文件夹下），如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_9_8288233" name="code" class="cpp">void x264_predict_16x16_init_arm( int cpu, x264_predict_t pf[7] )
{
    if (!(cpu&amp;X264_CPU_NEON))
        return;

#if !HIGH_BIT_DEPTH
    pf[I_PRED_16x16_DC ]    = x264_predict_16x16_dc_neon;
    pf[I_PRED_16x16_DC_TOP] = x264_predict_16x16_dc_top_neon;
    pf[I_PRED_16x16_DC_LEFT]= x264_predict_16x16_dc_left_neon;
    pf[I_PRED_16x16_H ]     = x264_predict_16x16_h_neon;
    pf[I_PRED_16x16_V ]     = x264_predict_16x16_v_neon;
    pf[I_PRED_16x16_P ]     = x264_predict_16x16_p_neon;
#endif // !HIGH_BIT_DEPTH
}
</pre><br />从源代码可以看出，针对Vertical预测模式，x264_predict_16x16_init_arm()初始化了经过NEON指令集优化的函数x264_predict_16x16_v_neon()。<br /><br /><h3>x264_predict_16x16_v_neon()</h3>x264_predict_16x16_v_neon()的定义位于common\arm\predict-a.S，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_10_3144573" name="code" class="plain">/*
 * Intra16x16帧内预测Vertical模式-NEON
 *
 */
 /* FDEC_STRIDE=32Bytes，为重建宏块一行像素的大小 */
 /* R0存储16x16像素块地址 */
function x264_predict_16x16_v_neon
    sub         r0, r0, #FDEC_STRIDE     /* r0=r0-FDEC_STRIDE */
    mov         ip, #FDEC_STRIDE         /* ip=32 */
                                         /* VLD向量加载: 内存-&gt;NEON寄存器 */
                                         /* d0,d1为64bit双字寄存器，共16Byte，在这里存储16x16块上方一行像素 */
    vld1.64     {d0-d1}, [r0,:128], ip   /* 将R0指向的数据从内存加载到d0和d1寄存器（64bit） */
                                         /* r0=r0+ip */
.rept 16                                 /* 循环16次，一次处理1行 */
                                         /* VST向量存储: NEON寄存器-&gt;内存 */
    vst1.64     {d0-d1}, [r0,:128], ip   /* 将d0和d1寄存器中的数据传递给R0指向的内存 */
                                         /* r0=r0+ip */
.endr
    bx          lr                       /* 子程序返回 */
endfunc
</pre><br />可以看出，x264_predict_16x16_v_neon()使用vld1.64指令载入16x16块上方的一行像素，然后在一个16次的循环中，使用vst1.64指令将该行像素值赋值给16x16块的每一行。<br />至此有关Intra16x16的Vertical帧内预测方式的源代码就分析完了。后文为了简便，都只讨论C语言版本汇编函数。<br /><br /><h2>x264_predict_4x4_init()</h2>x264_predict_4x4_init()用于初始化Intra4x4帧内预测汇编函数。该函数的定义位于common\predict.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_11_1588962" name="code" class="cpp">//Intra4x4帧内预测汇编函数初始化
void x264_predict_4x4_init( int cpu, x264_predict_t pf[12] )
{
	//9种Intra4x4预测方式
    pf[I_PRED_4x4_V]      = x264_predict_4x4_v_c;
    pf[I_PRED_4x4_H]      = x264_predict_4x4_h_c;
    pf[I_PRED_4x4_DC]     = x264_predict_4x4_dc_c;
    pf[I_PRED_4x4_DDL]    = x264_predict_4x4_ddl_c;
    pf[I_PRED_4x4_DDR]    = x264_predict_4x4_ddr_c;
    pf[I_PRED_4x4_VR]     = x264_predict_4x4_vr_c;
    pf[I_PRED_4x4_HD]     = x264_predict_4x4_hd_c;
    pf[I_PRED_4x4_VL]     = x264_predict_4x4_vl_c;
    pf[I_PRED_4x4_HU]     = x264_predict_4x4_hu_c;
    //这些是？
    pf[I_PRED_4x4_DC_LEFT]= x264_predict_4x4_dc_left_c;
    pf[I_PRED_4x4_DC_TOP] = x264_predict_4x4_dc_top_c;
    pf[I_PRED_4x4_DC_128] = x264_predict_4x4_dc_128_c;

#if HAVE_MMX
    x264_predict_4x4_init_mmx( cpu, pf );
#endif

#if HAVE_ARMV6
    x264_predict_4x4_init_arm( cpu, pf );
#endif

#if ARCH_AARCH64
    x264_predict_4x4_init_aarch64( cpu, pf );
#endif
}
</pre><br />从源代码可看出，x264_predict_4x4_init()首先对帧内预测函数指针数组x264_predict_t[]中的元素赋值了C语言版本的函数x264_predict_4x4_v_c()，x264_predict_4x4_h_c()，x264_predict_4x4_dc_c()，x264_predict_4x4_p_c()等一系列函数（Intra4x4有9种，后面那几种是怎么回事？）；然后会判断系统平台的特性，如果平台支持的话，会调用x264_predict_4x4_init_mmx()，x264_predict_4x4_init_arm()等给x264_predict_t[]中的元素赋值经过汇编优化的函数。作为例子，下文看一个Intra4x4的Vertical帧内预测模式的C语言函数。<br /><br /><h3>相关知识简述</h3><span style="white-space:pre">	</span>Intra4x4的帧内预测模式一共有9种。如下图所示。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511152617361?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div>可以看出，Intra4x4帧内预测模式中前4种和Intra16x16是一样的。后面多增加了几种预测箭头不是45度角的方式——前面的箭头位于“口”中，而后面的箭头位于“日”中。<br /><br /><h3>x264_predict_4x4_v_c()</h3>x264_predict_4x4_v_c()实现了Intra4x4的Vertical帧内预测方式。该函数的定义位于common\predict.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_12_99391" name="code" class="cpp">void x264_predict_4x4_v_c( pixel *src )
{
    /*
     * Vertical预测方式
     *   |X1 X2 X3 X4
     * --+-----------
     *   |X1 X2 X3 X4
     *   |X1 X2 X3 X4
     *   |X1 X2 X3 X4
     *   |X1 X2 X3 X4
     *
     */

	/*
	 * 宏展开后的结果如下所示
	 * 注：重建宏块缓存fdec_buf一行的数据量为32Byte
	 *
	 * (((x264_union32_t*)(&amp;src[(0)+(0)*32]))-&gt;i) =
	 * (((x264_union32_t*)(&amp;src[(0)+(1)*32]))-&gt;i) =
	 * (((x264_union32_t*)(&amp;src[(0)+(2)*32]))-&gt;i) =
	 * (((x264_union32_t*)(&amp;src[(0)+(3)*32]))-&gt;i) = (((x264_union32_t*)(&amp;src[(0)+(-1)*32]))-&gt;i);
	 */
    PREDICT_4x4_DC(SRC_X4(0,-1));
}
</pre><br />x264_predict_4x4_v_c()函数的函数体极其简单，只有一个宏定义“PREDICT_4x4_DC(SRC_X4(0,-1));”。如果把该宏展开后，可以看出它取了4x4块上面一行4个像素的值，然后分别赋值给4x4块的4行像素。<br /><br /><h3>x264_pixel_init()</h3>x264_pixel_init()初始化像素值计算相关的汇编函数（包括SAD、SATD、SSD等）。该函数的定义位于common\pixel.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_13_844292" name="code" class="cpp">/****************************************************************************
 * x264_pixel_init:
 ****************************************************************************/
//SAD等和像素计算有关的函数
void x264_pixel_init( int cpu, x264_pixel_function_t *pixf )
{
    memset( pixf, 0, sizeof(*pixf) );

    //初始化2个函数-16x16,16x8
#define INIT2_NAME( name1, name2, cpu ) \
    pixf-&gt;name1[PIXEL_16x16] = x264_pixel_##name2##_16x16##cpu;\
    pixf-&gt;name1[PIXEL_16x8]  = x264_pixel_##name2##_16x8##cpu;
    //初始化4个函数-(16x16,16x8),8x16,8x8
#define INIT4_NAME( name1, name2, cpu ) \
    INIT2_NAME( name1, name2, cpu ) \
    pixf-&gt;name1[PIXEL_8x16]  = x264_pixel_##name2##_8x16##cpu;\
    pixf-&gt;name1[PIXEL_8x8]   = x264_pixel_##name2##_8x8##cpu;
    //初始化5个函数-(16x16,16x8,8x16,8x8),8x4
#define INIT5_NAME( name1, name2, cpu ) \
    INIT4_NAME( name1, name2, cpu ) \
    pixf-&gt;name1[PIXEL_8x4]   = x264_pixel_##name2##_8x4##cpu;
    //初始化6个函数-(16x16,16x8,8x16,8x8,8x4),4x8
#define INIT6_NAME( name1, name2, cpu ) \
    INIT5_NAME( name1, name2, cpu ) \
    pixf-&gt;name1[PIXEL_4x8]   = x264_pixel_##name2##_4x8##cpu;
    //初始化7个函数-(16x16,16x8,8x16,8x8,8x4,4x8),4x4
#define INIT7_NAME( name1, name2, cpu ) \
    INIT6_NAME( name1, name2, cpu ) \
    pixf-&gt;name1[PIXEL_4x4]   = x264_pixel_##name2##_4x4##cpu;
#define INIT8_NAME( name1, name2, cpu ) \
    INIT7_NAME( name1, name2, cpu ) \
    pixf-&gt;name1[PIXEL_4x16]  = x264_pixel_##name2##_4x16##cpu;

    //重新起个名字
#define INIT2( name, cpu ) INIT2_NAME( name, name, cpu )
#define INIT4( name, cpu ) INIT4_NAME( name, name, cpu )
#define INIT5( name, cpu ) INIT5_NAME( name, name, cpu )
#define INIT6( name, cpu ) INIT6_NAME( name, name, cpu )
#define INIT7( name, cpu ) INIT7_NAME( name, name, cpu )
#define INIT8( name, cpu ) INIT8_NAME( name, name, cpu )

#define INIT_ADS( cpu ) \
    pixf-&gt;ads[PIXEL_16x16] = x264_pixel_ads4##cpu;\
    pixf-&gt;ads[PIXEL_16x8] = x264_pixel_ads2##cpu;\
    pixf-&gt;ads[PIXEL_8x8] = x264_pixel_ads1##cpu;
    //8个sad函数
    INIT8( sad, );
    INIT8_NAME( sad_aligned, sad, );
    //7个sad函数-一次性计算3次
    INIT7( sad_x3, );
    //7个sad函数-一次性计算4次
    INIT7( sad_x4, );
    //8个ssd函数
    //ssd可以用来计算PSNR
    INIT8( ssd, );
    //8个satd函数
    //satd计算的是经过Hadamard变换后的值
    INIT8( satd, );
    //8个satd函数-一次性计算3次
    INIT7( satd_x3, );
    //8个satd函数-一次性计算4次
    INIT7( satd_x4, );
    INIT4( hadamard_ac, );
    INIT_ADS( );

    pixf-&gt;sa8d[PIXEL_16x16] = x264_pixel_sa8d_16x16;
    pixf-&gt;sa8d[PIXEL_8x8]   = x264_pixel_sa8d_8x8;
    pixf-&gt;var[PIXEL_16x16] = x264_pixel_var_16x16;
    pixf-&gt;var[PIXEL_8x16]  = x264_pixel_var_8x16;
    pixf-&gt;var[PIXEL_8x8]   = x264_pixel_var_8x8;
    pixf-&gt;var2[PIXEL_8x16]  = x264_pixel_var2_8x16;
    pixf-&gt;var2[PIXEL_8x8]   = x264_pixel_var2_8x8;
    //计算UV的
    pixf-&gt;ssd_nv12_core = pixel_ssd_nv12_core;
    //计算SSIM
    pixf-&gt;ssim_4x4x2_core = ssim_4x4x2_core;
    pixf-&gt;ssim_end4 = ssim_end4;
    pixf-&gt;vsad = pixel_vsad;
    pixf-&gt;asd8 = pixel_asd8;

    pixf-&gt;intra_sad_x3_4x4    = x264_intra_sad_x3_4x4;
    pixf-&gt;intra_satd_x3_4x4   = x264_intra_satd_x3_4x4;
    pixf-&gt;intra_sad_x3_8x8    = x264_intra_sad_x3_8x8;
    pixf-&gt;intra_sa8d_x3_8x8   = x264_intra_sa8d_x3_8x8;
    pixf-&gt;intra_sad_x3_8x8c   = x264_intra_sad_x3_8x8c;
    pixf-&gt;intra_satd_x3_8x8c  = x264_intra_satd_x3_8x8c;
    pixf-&gt;intra_sad_x3_8x16c  = x264_intra_sad_x3_8x16c;
    pixf-&gt;intra_satd_x3_8x16c = x264_intra_satd_x3_8x16c;
    pixf-&gt;intra_sad_x3_16x16  = x264_intra_sad_x3_16x16;
    pixf-&gt;intra_satd_x3_16x16 = x264_intra_satd_x3_16x16;

    //后面的初始化基本上都是汇编优化过的函数

#if HIGH_BIT_DEPTH
#if HAVE_MMX
    if( cpu&amp;X264_CPU_MMX2 )
    {
        INIT7( sad, _mmx2 );
        INIT7_NAME( sad_aligned, sad, _mmx2 );
        INIT7( sad_x3, _mmx2 );
        INIT7( sad_x4, _mmx2 );
        INIT8( satd, _mmx2 );
        INIT7( satd_x3, _mmx2 );
        INIT7( satd_x4, _mmx2 );
        INIT4( hadamard_ac, _mmx2 );
        INIT8( ssd, _mmx2 );
        INIT_ADS( _mmx2 );

        pixf-&gt;ssd_nv12_core = x264_pixel_ssd_nv12_core_mmx2;
        pixf-&gt;var[PIXEL_16x16] = x264_pixel_var_16x16_mmx2;
        pixf-&gt;var[PIXEL_8x8]   = x264_pixel_var_8x8_mmx2;
#if ARCH_X86
        pixf-&gt;var2[PIXEL_8x8]  = x264_pixel_var2_8x8_mmx2;
        pixf-&gt;var2[PIXEL_8x16] = x264_pixel_var2_8x16_mmx2;
#endif

        pixf-&gt;intra_sad_x3_4x4    = x264_intra_sad_x3_4x4_mmx2;
        pixf-&gt;intra_satd_x3_4x4   = x264_intra_satd_x3_4x4_mmx2;
        pixf-&gt;intra_sad_x3_8x8    = x264_intra_sad_x3_8x8_mmx2;
        pixf-&gt;intra_sad_x3_8x8c   = x264_intra_sad_x3_8x8c_mmx2;
        pixf-&gt;intra_satd_x3_8x8c  = x264_intra_satd_x3_8x8c_mmx2;
        pixf-&gt;intra_sad_x3_8x16c  = x264_intra_sad_x3_8x16c_mmx2;
        pixf-&gt;intra_satd_x3_8x16c = x264_intra_satd_x3_8x16c_mmx2;
        pixf-&gt;intra_sad_x3_16x16  = x264_intra_sad_x3_16x16_mmx2;
        pixf-&gt;intra_satd_x3_16x16 = x264_intra_satd_x3_16x16_mmx2;
    }
    if( cpu&amp;X264_CPU_SSE2 )
    {
        INIT4_NAME( sad_aligned, sad, _sse2_aligned );
        INIT5( ssd, _sse2 );
        INIT6( satd, _sse2 );
        pixf-&gt;satd[PIXEL_4x16] = x264_pixel_satd_4x16_sse2;

        pixf-&gt;sa8d[PIXEL_16x16] = x264_pixel_sa8d_16x16_sse2;
        pixf-&gt;sa8d[PIXEL_8x8]   = x264_pixel_sa8d_8x8_sse2;
#if ARCH_X86_64
        pixf-&gt;intra_sa8d_x3_8x8 = x264_intra_sa8d_x3_8x8_sse2;
        pixf-&gt;sa8d_satd[PIXEL_16x16] = x264_pixel_sa8d_satd_16x16_sse2;
#endif
        pixf-&gt;intra_sad_x3_4x4  = x264_intra_sad_x3_4x4_sse2;
        pixf-&gt;ssd_nv12_core = x264_pixel_ssd_nv12_core_sse2;
        pixf-&gt;ssim_4x4x2_core  = x264_pixel_ssim_4x4x2_core_sse2;
        pixf-&gt;ssim_end4        = x264_pixel_ssim_end4_sse2;
        pixf-&gt;var[PIXEL_16x16] = x264_pixel_var_16x16_sse2;
        pixf-&gt;var[PIXEL_8x8]   = x264_pixel_var_8x8_sse2;
        pixf-&gt;var2[PIXEL_8x8]  = x264_pixel_var2_8x8_sse2;
        pixf-&gt;var2[PIXEL_8x16] = x264_pixel_var2_8x16_sse2;
        pixf-&gt;intra_sad_x3_8x8 = x264_intra_sad_x3_8x8_sse2;
}
//此处省略大量的X86、ARM等平台的汇编函数初始化代码
}
</pre><br />x264_pixel_init()的源代码非常的长，主要原因在于它把C语言版本的函数以及各种平台的汇编函数都写到一块了（不知道现在最新的版本是不是还是这样）。x264_pixel_init()包含了大量和像素计算有关的函数，包括SAD、SATD、SSD、SSIM等等。它的输入参数x264_pixel_function_t是一个结构体，其中包含了各种像素计算的函数接口。x264_pixel_function_t的定义如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_14_6290058" name="code" class="cpp">typedef struct
{
    x264_pixel_cmp_t  sad[8];
    x264_pixel_cmp_t  ssd[8];
    x264_pixel_cmp_t satd[8];
    x264_pixel_cmp_t ssim[7];
    x264_pixel_cmp_t sa8d[4];
    x264_pixel_cmp_t mbcmp[8]; /* either satd or sad for subpel refine and mode decision */
    x264_pixel_cmp_t mbcmp_unaligned[8]; /* unaligned mbcmp for subpel */
    x264_pixel_cmp_t fpelcmp[8]; /* either satd or sad for fullpel motion search */
    x264_pixel_cmp_x3_t fpelcmp_x3[7];
    x264_pixel_cmp_x4_t fpelcmp_x4[7];
    x264_pixel_cmp_t sad_aligned[8]; /* Aligned SAD for mbcmp */
    int (*vsad)( pixel *, intptr_t, int );
    int (*asd8)( pixel *pix1, intptr_t stride1, pixel *pix2, intptr_t stride2, int height );
    uint64_t (*sa8d_satd[1])( pixel *pix1, intptr_t stride1, pixel *pix2, intptr_t stride2 );

    uint64_t (*var[4])( pixel *pix, intptr_t stride );
    int (*var2[4])( pixel *pix1, intptr_t stride1,
                    pixel *pix2, intptr_t stride2, int *ssd );
    uint64_t (*hadamard_ac[4])( pixel *pix, intptr_t stride );

    void (*ssd_nv12_core)( pixel *pixuv1, intptr_t stride1,
                           pixel *pixuv2, intptr_t stride2, int width, int height,
                           uint64_t *ssd_u, uint64_t *ssd_v );
    void (*ssim_4x4x2_core)( const pixel *pix1, intptr_t stride1,
                             const pixel *pix2, intptr_t stride2, int sums[2][4] );
    float (*ssim_end4)( int sum0[5][4], int sum1[5][4], int width );

    /* multiple parallel calls to cmp. */
    x264_pixel_cmp_x3_t sad_x3[7];
    x264_pixel_cmp_x4_t sad_x4[7];
    x264_pixel_cmp_x3_t satd_x3[7];
    x264_pixel_cmp_x4_t satd_x4[7];

    /* abs-diff-sum for successive elimination.
     * may round width up to a multiple of 16. */
    int (*ads[7])( int enc_dc[4], uint16_t *sums, int delta,
                   uint16_t *cost_mvx, int16_t *mvs, int width, int thresh );

    /* calculate satd or sad of V, H, and DC modes. */
    void (*intra_mbcmp_x3_16x16)( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_satd_x3_16x16) ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_sad_x3_16x16)  ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_mbcmp_x3_4x4)  ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_satd_x3_4x4)   ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_sad_x3_4x4)    ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_mbcmp_x3_chroma)( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_satd_x3_chroma) ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_sad_x3_chroma)  ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_mbcmp_x3_8x16c) ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_satd_x3_8x16c)  ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_sad_x3_8x16c)   ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_mbcmp_x3_8x8c)  ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_satd_x3_8x8c)   ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_sad_x3_8x8c)    ( pixel *fenc, pixel *fdec, int res[3] );
    void (*intra_mbcmp_x3_8x8)  ( pixel *fenc, pixel edge[36], int res[3] );
    void (*intra_sa8d_x3_8x8)   ( pixel *fenc, pixel edge[36], int res[3] );
    void (*intra_sad_x3_8x8)    ( pixel *fenc, pixel edge[36], int res[3] );
    /* find minimum satd or sad of all modes, and set fdec.
     * may be NULL, in which case just use pred+satd instead. */
    int (*intra_mbcmp_x9_4x4)( pixel *fenc, pixel *fdec, uint16_t *bitcosts );
    int (*intra_satd_x9_4x4) ( pixel *fenc, pixel *fdec, uint16_t *bitcosts );
    int (*intra_sad_x9_4x4)  ( pixel *fenc, pixel *fdec, uint16_t *bitcosts );
    int (*intra_mbcmp_x9_8x8)( pixel *fenc, pixel *fdec, pixel edge[36], uint16_t *bitcosts, uint16_t *satds );
    int (*intra_sa8d_x9_8x8) ( pixel *fenc, pixel *fdec, pixel edge[36], uint16_t *bitcosts, uint16_t *satds );
    int (*intra_sad_x9_8x8)  ( pixel *fenc, pixel *fdec, pixel edge[36], uint16_t *bitcosts, uint16_t *satds );
} x264_pixel_function_t;</pre>在x264_pixel_init()中定义了好几个宏，用于给x264_pixel_function_t结构体中的函数接口赋值。例如“INIT8( sad, )”用于给x264_pixel_function_t中的sad[8]赋值。该宏展开后的代码如下。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_15_6752334" name="code" class="cpp">pixf-&gt;sad[PIXEL_16x16] = x264_pixel_sad_16x16;
pixf-&gt;sad[PIXEL_16x8]  = x264_pixel_sad_16x8;
pixf-&gt;sad[PIXEL_8x16]  = x264_pixel_sad_8x16;
pixf-&gt;sad[PIXEL_8x8]   = x264_pixel_sad_8x8;
pixf-&gt;sad[PIXEL_8x4]   = x264_pixel_sad_8x4;
pixf-&gt;sad[PIXEL_4x8]   = x264_pixel_sad_4x8;
pixf-&gt;sad[PIXEL_4x4]   = x264_pixel_sad_4x4;
pixf-&gt;sad[PIXEL_4x16]  = x264_pixel_sad_4x16;</pre>“INIT8( ssd, )” 用于给x264_pixel_function_t中的ssd[8]赋值。该宏展开后的代码如下。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_16_6309539" name="code" class="cpp">pixf-&gt;ssd[PIXEL_16x16] = x264_pixel_ssd_16x16;
pixf-&gt;ssd[PIXEL_16x8]  = x264_pixel_ssd_16x8; 
pixf-&gt;ssd[PIXEL_8x16]  = x264_pixel_ssd_8x16;
pixf-&gt;ssd[PIXEL_8x8]   = x264_pixel_ssd_8x8; 
pixf-&gt;ssd[PIXEL_8x4]   = x264_pixel_ssd_8x4; 
pixf-&gt;ssd[PIXEL_4x8]   = x264_pixel_ssd_4x8; 
pixf-&gt;ssd[PIXEL_4x4]   = x264_pixel_ssd_4x4; 
pixf-&gt;ssd[PIXEL_4x16]  = x264_pixel_ssd_4x16;</pre>“INIT8( satd, )” 用于给x264_pixel_function_t中的satd[8]赋值。该宏展开后的代码如下。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_17_3216785" name="code" class="cpp">pixf-&gt;satd[PIXEL_16x16] = x264_pixel_satd_16x16;
pixf-&gt;satd[PIXEL_16x8]  = x264_pixel_satd_16x8; 
pixf-&gt;satd[PIXEL_8x16]  = x264_pixel_satd_8x16;
pixf-&gt;satd[PIXEL_8x8]   = x264_pixel_satd_8x8; 
pixf-&gt;satd[PIXEL_8x4]   = x264_pixel_satd_8x4; 
pixf-&gt;satd[PIXEL_4x8]   = x264_pixel_satd_4x8; 
pixf-&gt;satd[PIXEL_4x4]   = x264_pixel_satd_4x4; 
pixf-&gt;satd[PIXEL_4x16]  = x264_pixel_satd_4x16;</pre>下文打算分别记录SAD、SSD和SATD计算的函数x264_pixel_sad_4x4()，x264_pixel_ssd_4x4()，和x264_pixel_satd_4x4()。此外再记录一个一次性“批量”计算4个点的函数x264_pixel_sad_x4_4x4()。<br /><br /><h3>相关知识简述</h3><span style="white-space:pre">	</span>简单记录几个像素计算中的概念。SAD和SATD主要用于帧内预测模式以及帧间预测模式的判断。有关SAD、SATD、SSD的定义如下：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">SAD（Sum of Absolute Difference）也可以称为SAE（Sum of Absolute Error），即绝对误差和。它的计算方法就是求出两个像素块对应像素点的差值，将这些差值分别求绝对值之后再进行累加。<br />SATD（Sum of Absolute Transformed Difference）即Hadamard变换后再绝对值求和。它和SAD的区别在于多了一个“变换”。<br />SSD（Sum of Squared Difference）也可以称为SSE（Sum of Squared Error），即差值的平方和。它和SAD的区别在于多了一个“平方”。</blockquote><br /><p><span style="white-space:pre">	</span>H.264中使用SAD和SATD进行宏块预测模式的判断。早期的编码器使用SAD进行计算，近期的编码器多使用SATD进行计算。为什么使用SATD而不使用SAD呢？关键原因在于编码之后码流的大小是和图像块DCT变换后频域信息紧密相关的，而和变换前的时域信息关联性小一些。SAD只能反应时域信息；SATD却可以反映频域信息，而且计算复杂度也低于DCT变换，因此是比较合适的模式选择的依据。</p><span style="white-space:pre">	</span>使用SAD进行模式选择的示例如下所示。下面这张图代表了一个普通的Intra16x16的宏块的像素。它的下方包含了使用Vertical，Horizontal，DC和Plane四种帧内预测模式预测的像素。通过计算可以得到这几种预测像素和原始像素之间的SAD（SAE）分别为3985，5097，4991，2539。由于Plane模式的SAD取值最小，由此可以断定Plane模式对于这个宏块来说是最好的帧内预测模式。<br /><div style="text-align: center;"><img src="https://img-blog.csdn.net/20150511160749652?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><div style="text-align: center;"><br /></div><div style="text-align: center;"><img src="https://img-blog.csdn.net/20150511161649556?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><br /><h3>x264_pixel_sad_4x4()</h3>x264_pixel_sad_4x4()用于计算4x4块的SAD。该函数的定义位于common\pixel.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_18_9775365" name="code" class="cpp">   static int x264_pixel_sad_4x4( pixel *pix1, intptr_t i_stride_pix1,
                 pixel *pix2, intptr_t i_stride_pix2 )
	{
		int i_sum = 0;
		for( int y = 0; y &lt; 4; y++ ) //4个像素
		{
			for( int x = 0; x &lt; 4; x++ ) //4个像素
			{
				i_sum += abs( pix1[x] - pix2[x] );//相减之后求绝对值，然后累加
			}
			pix1 += i_stride_pix1;
			pix2 += i_stride_pix2;
		}
		return i_sum;
	}</pre>可以看出x264_pixel_sad_4x4()将两个4x4图像块对应点相减之后，调用abs()求出绝对值，然后累加到i_sum变量上。<br /><br /><h3>x264_pixel_sad_x4_4x4()</h3>x264_pixel_sad_4x4()用于计算4个4x4块的SAD。该函数的定义位于common\pixel.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_19_7696367" name="code" class="cpp">	static void x264_pixel_sad_x4_4x4( pixel *fenc, pixel *pix0, pixel *pix1,pixel *pix2, pixel *pix3,
										  intptr_t i_stride, int scores[4] )
	{
		scores[0] = x264_pixel_sad_4x4( fenc, 16, pix0, i_stride );
		scores[1] = x264_pixel_sad_4x4( fenc, 16, pix1, i_stride );
		scores[2] = x264_pixel_sad_4x4( fenc, 16, pix2, i_stride );
		scores[3] = x264_pixel_sad_4x4( fenc, 16, pix3, i_stride );
	}</pre>可以看出，x264_pixel_sad_4x4()计算了起始点在pix0，pix1，pix2，pix3四个4x4的图像块和fenc之间的SAD，并将结果存储于scores[4]数组中。<br /><br /><h3>x264_pixel_ssd_4x4()</h3>x264_pixel_ssd_4x4()用于计算4x4块的SSD。该函数的定义位于common\pixel.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_20_8092604" name="code" class="cpp">	static int x264_pixel_ssd_4x4( pixel *pix1, intptr_t i_stride_pix1,
					 pixel *pix2, intptr_t i_stride_pix2 )
	{
		int i_sum = 0;
		for( int y = 0; y &lt; 4; y++ ) //4个像素
		{
			for( int x = 0; x &lt; 4; x++ ) //4个像素
			{
				int d = pix1[x] - pix2[x]; //相减
				i_sum += d*d;              //平方之后，累加
			}
			pix1 += i_stride_pix1;
			pix2 += i_stride_pix2;
		}
		return i_sum;
	}</pre>可以看出x264_pixel_ssd_4x4()将两个4x4图像块对应点相减之后，取了平方值，然后累加到i_sum变量上。<br /><br /><h3>x264_pixel_satd_4x4()</h3>x264_pixel_satd_4x4()用于计算4x4块的SATD。该函数的定义位于common\pixel.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_21_8837505" name="code" class="cpp">//SAD（Sum of Absolute Difference）=SAE（Sum of Absolute Error)即绝对误差和
//SATD（Sum of Absolute Transformed Difference）即hadamard变换后再绝对值求和
//
//为什么帧内模式选择要用SATD？
//SAD即绝对误差和，仅反映残差时域差异，影响PSNR值，不能有效反映码流的大小。
//SATD即将残差经哈德曼变换的4x4块的预测残差绝对值总和，可以将其看作简单的时频变换，其值在一定程度上可以反映生成码流的大小。
//4x4的SATD
static NOINLINE int x264_pixel_satd_4x4( pixel *pix1, intptr_t i_pix1, pixel *pix2, intptr_t i_pix2 )
{
    sum2_t tmp[4][2];
    sum2_t a0, a1, a2, a3, b0, b1;
    sum2_t sum = 0;

    for( int i = 0; i &lt; 4; i++, pix1 += i_pix1, pix2 += i_pix2 )
    {
        a0 = pix1[0] - pix2[0];
        a1 = pix1[1] - pix2[1];
        b0 = (a0+a1) + ((a0-a1)&lt;&lt;BITS_PER_SUM);
        a2 = pix1[2] - pix2[2];
        a3 = pix1[3] - pix2[3];
        b1 = (a2+a3) + ((a2-a3)&lt;&lt;BITS_PER_SUM);
        tmp[i][0] = b0 + b1;
        tmp[i][1] = b0 - b1;
    }
    for( int i = 0; i &lt; 2; i++ )
    {
        HADAMARD4( a0, a1, a2, a3, tmp[0][i], tmp[1][i], tmp[2][i], tmp[3][i] );
        a0 = abs2(a0) + abs2(a1) + abs2(a2) + abs2(a3);
        sum += ((sum_t)a0) + (a0&gt;&gt;BITS_PER_SUM);
    }
    return sum &gt;&gt; 1;
}
</pre>有关x264_pixel_satd_4x4()中的Hadamard变换在下面的DCT变换中再进行分析。可以看出该函数调用了一个宏HADAMARD4()用于Hadamard变换的计算，并最终将两个像素块Hadamard变换后对应元素求差的绝对值之后，累加到sum变量上。<br /><br /><h2>x264_dct_init()</h2>x264_dct_init()用于初始化DCT变换和DCT反变换相关的汇编函数。该函数的定义位于common\dct.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_22_4217232" name="code" class="cpp">/****************************************************************************
 * x264_dct_init:
 ****************************************************************************/
void x264_dct_init( int cpu, x264_dct_function_t *dctf )
{
	//C语言版本
	//4x4DCT变换
    dctf-&gt;sub4x4_dct    = sub4x4_dct;
    dctf-&gt;add4x4_idct   = add4x4_idct;
    //8x8块：分解成4个4x4DCT变换，调用4次sub4x4_dct()
    dctf-&gt;sub8x8_dct    = sub8x8_dct;
    dctf-&gt;sub8x8_dct_dc = sub8x8_dct_dc;
    dctf-&gt;add8x8_idct   = add8x8_idct;
    dctf-&gt;add8x8_idct_dc = add8x8_idct_dc;

    dctf-&gt;sub8x16_dct_dc = sub8x16_dct_dc;
    //16x16块：分解成4个8x8块，调用4次sub8x8_dct()
    //实际上每个sub8x8_dct()又分解成4个4x4DCT变换，调用4次sub4x4_dct()
    dctf-&gt;sub16x16_dct  = sub16x16_dct;
    dctf-&gt;add16x16_idct = add16x16_idct;
    dctf-&gt;add16x16_idct_dc = add16x16_idct_dc;
    //8x8DCT，注意：后缀是_dct8
    dctf-&gt;sub8x8_dct8   = sub8x8_dct8;
    dctf-&gt;add8x8_idct8  = add8x8_idct8;

    dctf-&gt;sub16x16_dct8  = sub16x16_dct8;
    dctf-&gt;add16x16_idct8 = add16x16_idct8;
    //Hadamard变换
    dctf-&gt;dct4x4dc  = dct4x4dc;
    dctf-&gt;idct4x4dc = idct4x4dc;

    dctf-&gt;dct2x4dc = dct2x4dc;

#if HIGH_BIT_DEPTH
#if HAVE_MMX
    if( cpu&amp;X264_CPU_MMX )
    {
        dctf-&gt;sub4x4_dct    = x264_sub4x4_dct_mmx;
        dctf-&gt;sub8x8_dct    = x264_sub8x8_dct_mmx;
        dctf-&gt;sub16x16_dct  = x264_sub16x16_dct_mmx;
    }
    if( cpu&amp;X264_CPU_SSE2 )
    {
        dctf-&gt;add4x4_idct     = x264_add4x4_idct_sse2;
        dctf-&gt;dct4x4dc        = x264_dct4x4dc_sse2;
        dctf-&gt;idct4x4dc       = x264_idct4x4dc_sse2;
        dctf-&gt;sub8x8_dct8     = x264_sub8x8_dct8_sse2;
        dctf-&gt;sub16x16_dct8   = x264_sub16x16_dct8_sse2;
        dctf-&gt;add8x8_idct     = x264_add8x8_idct_sse2;
        dctf-&gt;add16x16_idct   = x264_add16x16_idct_sse2;
        dctf-&gt;add8x8_idct8    = x264_add8x8_idct8_sse2;
        dctf-&gt;add16x16_idct8    = x264_add16x16_idct8_sse2;
        dctf-&gt;sub8x8_dct_dc   = x264_sub8x8_dct_dc_sse2;
        dctf-&gt;add8x8_idct_dc  = x264_add8x8_idct_dc_sse2;
        dctf-&gt;sub8x16_dct_dc  = x264_sub8x16_dct_dc_sse2;
        dctf-&gt;add16x16_idct_dc= x264_add16x16_idct_dc_sse2;
    }
    if( cpu&amp;X264_CPU_SSE4 )
    {
        dctf-&gt;sub8x8_dct8     = x264_sub8x8_dct8_sse4;
        dctf-&gt;sub16x16_dct8   = x264_sub16x16_dct8_sse4;
    }
    if( cpu&amp;X264_CPU_AVX )
    {
        dctf-&gt;add4x4_idct     = x264_add4x4_idct_avx;
        dctf-&gt;dct4x4dc        = x264_dct4x4dc_avx;
        dctf-&gt;idct4x4dc       = x264_idct4x4dc_avx;
        dctf-&gt;sub8x8_dct8     = x264_sub8x8_dct8_avx;
        dctf-&gt;sub16x16_dct8   = x264_sub16x16_dct8_avx;
        dctf-&gt;add8x8_idct     = x264_add8x8_idct_avx;
        dctf-&gt;add16x16_idct   = x264_add16x16_idct_avx;
        dctf-&gt;add8x8_idct8    = x264_add8x8_idct8_avx;
        dctf-&gt;add16x16_idct8  = x264_add16x16_idct8_avx;
        dctf-&gt;add8x8_idct_dc  = x264_add8x8_idct_dc_avx;
        dctf-&gt;sub8x16_dct_dc  = x264_sub8x16_dct_dc_avx;
        dctf-&gt;add16x16_idct_dc= x264_add16x16_idct_dc_avx;
    }
#endif // HAVE_MMX
#else // !HIGH_BIT_DEPTH
    //MMX版本
#if HAVE_MMX
    if( cpu&amp;X264_CPU_MMX )
    {
        dctf-&gt;sub4x4_dct    = x264_sub4x4_dct_mmx;
        dctf-&gt;add4x4_idct   = x264_add4x4_idct_mmx;
        dctf-&gt;idct4x4dc     = x264_idct4x4dc_mmx;
        dctf-&gt;sub8x8_dct_dc = x264_sub8x8_dct_dc_mmx2;
    //此处省略大量的X86、ARM等平台的汇编函数初始化代码
}
</pre><br />从源代码可以看出，x264_dct_init()初始化了一系列的DCT变换的函数，这些DCT函数名称有如下规律：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">（1）DCT函数名称前面有“sub”，代表对两块像素相减得到残差之后，再进行DCT变换。<br />（2）DCT反变换函数名称前面有“add”，代表将DCT反变换之后的残差数据叠加到预测数据上。<br />（3）以“dct8”为结尾的函数使用了8x8DCT，其余函数是用的都是4x4DCT。</blockquote><p>x264_dct_init()的输入参数x264_dct_function_t是一个结构体，其中包含了各种DCT函数的接口。x264_dct_function_t的定义如下所示。</p><pre code_snippet_id="664118" snippet_file_name="blog_20150511_23_9629978" name="code" class="cpp">typedef struct
{
    // pix1  stride = FENC_STRIDE
    // pix2  stride = FDEC_STRIDE
    // p_dst stride = FDEC_STRIDE
    void (*sub4x4_dct)   ( dctcoef dct[16], pixel *pix1, pixel *pix2 );
    void (*add4x4_idct)  ( pixel *p_dst, dctcoef dct[16] );

    void (*sub8x8_dct)   ( dctcoef dct[4][16], pixel *pix1, pixel *pix2 );
    void (*sub8x8_dct_dc)( dctcoef dct[4], pixel *pix1, pixel *pix2 );
    void (*add8x8_idct)  ( pixel *p_dst, dctcoef dct[4][16] );
    void (*add8x8_idct_dc) ( pixel *p_dst, dctcoef dct[4] );

    void (*sub8x16_dct_dc)( dctcoef dct[8], pixel *pix1, pixel *pix2 );

    void (*sub16x16_dct) ( dctcoef dct[16][16], pixel *pix1, pixel *pix2 );
    void (*add16x16_idct)( pixel *p_dst, dctcoef dct[16][16] );
    void (*add16x16_idct_dc) ( pixel *p_dst, dctcoef dct[16] );

    void (*sub8x8_dct8)  ( dctcoef dct[64], pixel *pix1, pixel *pix2 );
    void (*add8x8_idct8) ( pixel *p_dst, dctcoef dct[64] );

    void (*sub16x16_dct8) ( dctcoef dct[4][64], pixel *pix1, pixel *pix2 );
    void (*add16x16_idct8)( pixel *p_dst, dctcoef dct[4][64] );

    void (*dct4x4dc) ( dctcoef d[16] );
    void (*idct4x4dc)( dctcoef d[16] );

    void (*dct2x4dc)( dctcoef dct[8], dctcoef dct4x4[8][16] );

} x264_dct_function_t;
</pre>x264_dct_init()的工作就是对x264_dct_function_t中的函数指针进行赋值。由于DCT函数很多，不便于一一研究，下文仅举例分析几个典型的4x4DCT函数：4x4DCT变换函数sub4x4_dct()，4x4IDCT变换函数add4x4_idct()，8x8块的4x4DCT变换函数sub8x8_dct()，16x16块的4x4DCT变换函数sub16x16_dct()，4x4Hadamard变换函数dct4x4dc()。<br /><br /><h3>相关知识简述</h3><span style="white-space:pre">	</span>简单记录一下DCT相关的知识。DCT变换的核心理念就是把图像的低频信息（对应大面积平坦区域）变换到系数矩阵的左上角，而把高频信息变换到系数矩阵的右下角，这样就可以在压缩的时候（量化）去除掉人眼不敏感的高频信息（位于矩阵右下角的系数）从而达到压缩数据的目的。二维8x8DCT变换常见的示意图如下所示。<br /><div style="text-align: center;"><img src="https://img-blog.csdn.net/20150511161914759?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><span style="white-space:pre">	</span>早期的DCT变换都使用了8x8的矩阵（变换系数为小数）。在H.264标准中新提出了一种4x4的矩阵。这种4x4 DCT变换的系数都是整数，一方面提高了运算的准确性，一方面也利于代码的优化。4x4整数DCT变换的示意图如下所示（作为对比，右侧为4x4块的Hadamard变换的示意图）。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511162230043?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><p>4x4整数DCT变换的公式如下所示。</p><p style="text-align: center;"><img src="https://img-blog.csdn.net/20150511162328571?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" />&nbsp;</p>对该公式中的矩阵乘法可以转换为2次一维DCT变换：首先对4x4块中的每行像素进行一维DCT变换，然后再对4x4块中的每列像素进行一维DCT变换。而一维的DCT变换是可以改造成为蝶形快速算法的，如下所示。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511162540800?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div>同理，DCT反变换就是DCT变换的逆变换。DCT反变换的公式如下所示。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511162517834?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div>同理，DCT反变换的矩阵乘法也可以改造成为2次一维IDCT变换：首先对4x4块中的每行像素进行一维IDCT变换，然后再对4x4块中的每列像素进行一维IDCT变换。而一维的IDCT变换也可以改造成为蝶形快速算法，如下所示。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511162742215?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div>除了4x4DCT变换之外，新版本的H.264标准中还引入了一种8x8DCT。目前针对这种8x8DCT我还没有做研究，暂时不做记录。<br /><br /><h3>sub4x4_dct()</h3>sub4x4_dct()可以将两块4x4的图像相减求残差后，进行DCT变换。该函数的定义位于common\dct.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_24_26216" name="code" class="cpp">/*
 * 求残差用
 * 注意求的是一个“方块”形像素
 *
 * 参数的含义如下：
 * diff：输出的残差数据
 * i_size：方块的大小
 * pix1：输入数据1
 * i_pix1：输入数据1一行像素大小（stride）
 * pix2：输入数据2
 * i_pix2：输入数据2一行像素大小（stride）
 *
 */
static inline void pixel_sub_wxh( dctcoef *diff, int i_size,
                                  pixel *pix1, int i_pix1, pixel *pix2, int i_pix2 )
{
    for( int y = 0; y &lt; i_size; y++ )
    {
        for( int x = 0; x &lt; i_size; x++ )
            diff[x + y*i_size] = pix1[x] - pix2[x];//求残差
        pix1 += i_pix1;//前进到下一行
        pix2 += i_pix2;
    }
}
//4x4DCT变换
//注意首先获取pix1和pix2两块数据的残差，然后再进行变换
//返回dct[16]
static void sub4x4_dct( dctcoef dct[16], pixel *pix1, pixel *pix2 )
{
    dctcoef d[16];
    dctcoef tmp[16];
    //获取残差数据，存入d[16]
    //pix1一般为编码帧（enc）
    //pix2一般为重建帧（dec）
    pixel_sub_wxh( d, 4, pix1, FENC_STRIDE, pix2, FDEC_STRIDE );

    //处理残差d[16]
    //蝶形算法：横向4个像素
    for( int i = 0; i &lt; 4; i++ )
    {
        int s03 = d[i*4+0] + d[i*4+3];
        int s12 = d[i*4+1] + d[i*4+2];
        int d03 = d[i*4+0] - d[i*4+3];
        int d12 = d[i*4+1] - d[i*4+2];

        tmp[0*4+i] =   s03 +   s12;
        tmp[1*4+i] = 2*d03 +   d12;
        tmp[2*4+i] =   s03 -   s12;
        tmp[3*4+i] =   d03 - 2*d12;
    }
    //蝶形算法：纵向
    for( int i = 0; i &lt; 4; i++ )
    {
        int s03 = tmp[i*4+0] + tmp[i*4+3];
        int s12 = tmp[i*4+1] + tmp[i*4+2];
        int d03 = tmp[i*4+0] - tmp[i*4+3];
        int d12 = tmp[i*4+1] - tmp[i*4+2];

        dct[i*4+0] =   s03 +   s12;
        dct[i*4+1] = 2*d03 +   d12;
        dct[i*4+2] =   s03 -   s12;
        dct[i*4+3] =   d03 - 2*d12;
    }
}
</pre>从源代码可以看出，sub4x4_dct()首先调用pixel_sub_wxh()求出两个输入图像块的残差，然后使用蝶形快速算法计算残差图像的DCT系数。<br /><br /><h3>add4x4_idct()</h3>add4x4_idct()可以将残差数据进行DCT反变换，并将变换后得到的残差像素数据叠加到预测数据上。该函数的定义位于common\dct.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_25_5438962" name="code" class="cpp">//4x4DCT反变换（“add”代表叠加到已有的像素上）
static void add4x4_idct( pixel *p_dst, dctcoef dct[16] )
{
    dctcoef d[16];
    dctcoef tmp[16];

    for( int i = 0; i &lt; 4; i++ )
    {
        int s02 =  dct[0*4+i]     +  dct[2*4+i];
        int d02 =  dct[0*4+i]     -  dct[2*4+i];
        int s13 =  dct[1*4+i]     + (dct[3*4+i]&gt;&gt;1);
        int d13 = (dct[1*4+i]&gt;&gt;1) -  dct[3*4+i];

        tmp[i*4+0] = s02 + s13;
        tmp[i*4+1] = d02 + d13;
        tmp[i*4+2] = d02 - d13;
        tmp[i*4+3] = s02 - s13;
    }

    for( int i = 0; i &lt; 4; i++ )
    {
        int s02 =  tmp[0*4+i]     +  tmp[2*4+i];
        int d02 =  tmp[0*4+i]     -  tmp[2*4+i];
        int s13 =  tmp[1*4+i]     + (tmp[3*4+i]&gt;&gt;1);
        int d13 = (tmp[1*4+i]&gt;&gt;1) -  tmp[3*4+i];

        d[0*4+i] = ( s02 + s13 + 32 ) &gt;&gt; 6;
        d[1*4+i] = ( d02 + d13 + 32 ) &gt;&gt; 6;
        d[2*4+i] = ( d02 - d13 + 32 ) &gt;&gt; 6;
        d[3*4+i] = ( s02 - s13 + 32 ) &gt;&gt; 6;
    }


    for( int y = 0; y &lt; 4; y++ )
    {
        for( int x = 0; x &lt; 4; x++ )
            p_dst[x] = x264_clip_pixel( p_dst[x] + d[y*4+x] );
        p_dst += FDEC_STRIDE;
    }
}</pre>从源代码可以看出，add4x4_idct()首先采用快速蝶形算法对DCT系数进行DCT反变换后得到残差像素数据，然后再将残差数据叠加到p_dst指向的像素上。需要注意这里是“叠加”而不是“赋值”。<br /><br /><h3>sub8x8_dct()</h3>sub8x8_dct()可以将两块8x8的图像相减求残差后，进行4x4DCT变换。该函数的定义位于common\dct.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_26_7787046" name="code" class="cpp">//8x8块：分解成4个4x4DCT变换，调用4次sub4x4_dct()
//返回dct[4][16]
static void sub8x8_dct( dctcoef dct[4][16], pixel *pix1, pixel *pix2 )
{
	/*
	 * 8x8 宏块被划分为4个4x4子块
	 *
	 * +---+---+
	 * | 0 | 1 |
	 * +---+---+
	 * | 2 | 3 |
	 * +---+---+
	 *
	 */
    sub4x4_dct( dct[0], &amp;pix1[0], &amp;pix2[0] );
    sub4x4_dct( dct[1], &amp;pix1[4], &amp;pix2[4] );
    sub4x4_dct( dct[2], &amp;pix1[4*FENC_STRIDE+0], &amp;pix2[4*FDEC_STRIDE+0] );
    sub4x4_dct( dct[3], &amp;pix1[4*FENC_STRIDE+4], &amp;pix2[4*FDEC_STRIDE+4] );
}</pre>从源代码可以看出， sub8x8_dct()将8x8的图像块分成4个4x4的图像块，分别调用了sub4x4_dct()。<br /><br /><h3>sub16x16_dct()</h3>sub16x16_dct()可以将两块16x16的图像相减求残差后，进行4x4DCT变换。该函数的定义位于common\dct.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_27_1247946" name="code" class="cpp">//16x16块：分解成4个8x8的块做DCT变换，调用4次sub8x8_dct()
//返回dct[16][16]
static void sub16x16_dct( dctcoef dct[16][16], pixel *pix1, pixel *pix2 )
{
	/*
	 * 16x16 宏块被划分为4个8x8子块
	 *
	 * +--------+--------+
	 * |        |        |
	 * |   0    |   1    |
	 * |        |        |
	 * +--------+--------+
	 * |        |        |
	 * |   2    |   3    |
	 * |        |        |
	 * +--------+--------+
	 *
	 */
    sub8x8_dct( &amp;dct[ 0], &amp;pix1[0], &amp;pix2[0] );  //0
    sub8x8_dct( &amp;dct[ 4], &amp;pix1[8], &amp;pix2[8] );  //1
    sub8x8_dct( &amp;dct[ 8], &amp;pix1[8*FENC_STRIDE+0], &amp;pix2[8*FDEC_STRIDE+0] );  //2
    sub8x8_dct( &amp;dct[12], &amp;pix1[8*FENC_STRIDE+8], &amp;pix2[8*FDEC_STRIDE+8] );  //3
}</pre>从源代码可以看出， sub8x8_dct()将16x16的图像块分成4个8x8的图像块，分别调用了sub8x8_dct()。而sub8x8_dct()实际上又调用了4次sub4x4_dct()。所以可以得知，不论sub16x16_dct()，sub8x8_dct()还是sub4x4_dct()，本质都是进行4x4DCT。<br /><br /><h3>dct4x4dc()</h3>dct4x4dc()可以将输入的4x4图像块进行Hadamard变换。该函数的定义位于common\dct.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_28_6104284" name="code" class="cpp">//Hadamard变换
static void dct4x4dc( dctcoef d[16] )
{
    dctcoef tmp[16];

    //蝶形算法：横向的4个像素
    for( int i = 0; i &lt; 4; i++ )
    {

        int s01 = d[i*4+0] + d[i*4+1];
        int d01 = d[i*4+0] - d[i*4+1];
        int s23 = d[i*4+2] + d[i*4+3];
        int d23 = d[i*4+2] - d[i*4+3];

        tmp[0*4+i] = s01 + s23;
        tmp[1*4+i] = s01 - s23;
        tmp[2*4+i] = d01 - d23;
        tmp[3*4+i] = d01 + d23;
    }
    //蝶形算法：纵向
    for( int i = 0; i &lt; 4; i++ )
    {
        int s01 = tmp[i*4+0] + tmp[i*4+1];
        int d01 = tmp[i*4+0] - tmp[i*4+1];
        int s23 = tmp[i*4+2] + tmp[i*4+3];
        int d23 = tmp[i*4+2] - tmp[i*4+3];

        d[i*4+0] = ( s01 + s23 + 1 ) &gt;&gt; 1;
        d[i*4+1] = ( s01 - s23 + 1 ) &gt;&gt; 1;
        d[i*4+2] = ( d01 - d23 + 1 ) &gt;&gt; 1;
        d[i*4+3] = ( d01 + d23 + 1 ) &gt;&gt; 1;
    }
}</pre>从源代码可以看出，dct4x4dc()实现了Hadamard快速蝶形算法。<br /><br /><h2>x264_mc_init()</h2>x264_mc_init()用于初始化运动补偿相关的汇编函数。该函数的定义位于common\mc.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_29_1234407" name="code" class="cpp">//运动补偿
void x264_mc_init( int cpu, x264_mc_functions_t *pf, int cpu_independent )
{
	//亮度运动补偿
    pf-&gt;mc_luma   = mc_luma;
    //获得匹配块
    pf-&gt;get_ref   = get_ref;

    pf-&gt;mc_chroma = mc_chroma;
    //求平均
    pf-&gt;avg[PIXEL_16x16]= pixel_avg_16x16;
    pf-&gt;avg[PIXEL_16x8] = pixel_avg_16x8;
    pf-&gt;avg[PIXEL_8x16] = pixel_avg_8x16;
    pf-&gt;avg[PIXEL_8x8]  = pixel_avg_8x8;
    pf-&gt;avg[PIXEL_8x4]  = pixel_avg_8x4;
    pf-&gt;avg[PIXEL_4x16] = pixel_avg_4x16;
    pf-&gt;avg[PIXEL_4x8]  = pixel_avg_4x8;
    pf-&gt;avg[PIXEL_4x4]  = pixel_avg_4x4;
    pf-&gt;avg[PIXEL_4x2]  = pixel_avg_4x2;
    pf-&gt;avg[PIXEL_2x8]  = pixel_avg_2x8;
    pf-&gt;avg[PIXEL_2x4]  = pixel_avg_2x4;
    pf-&gt;avg[PIXEL_2x2]  = pixel_avg_2x2;
    //加权相关
    pf-&gt;weight    = x264_mc_weight_wtab;
    pf-&gt;offsetadd = x264_mc_weight_wtab;
    pf-&gt;offsetsub = x264_mc_weight_wtab;
    pf-&gt;weight_cache = x264_weight_cache;
    //赋值-只包含了方形的
    pf-&gt;copy_16x16_unaligned = mc_copy_w16;
    pf-&gt;copy[PIXEL_16x16] = mc_copy_w16;
    pf-&gt;copy[PIXEL_8x8]   = mc_copy_w8;
    pf-&gt;copy[PIXEL_4x4]   = mc_copy_w4;

    pf-&gt;store_interleave_chroma       = store_interleave_chroma;
    pf-&gt;load_deinterleave_chroma_fenc = load_deinterleave_chroma_fenc;
    pf-&gt;load_deinterleave_chroma_fdec = load_deinterleave_chroma_fdec;
    //拷贝像素-不论像素块大小
    pf-&gt;plane_copy = x264_plane_copy_c;
    pf-&gt;plane_copy_interleave = x264_plane_copy_interleave_c;
    pf-&gt;plane_copy_deinterleave = x264_plane_copy_deinterleave_c;
    pf-&gt;plane_copy_deinterleave_rgb = x264_plane_copy_deinterleave_rgb_c;
    pf-&gt;plane_copy_deinterleave_v210 = x264_plane_copy_deinterleave_v210_c;
    //关键：半像素内插
    pf-&gt;hpel_filter = hpel_filter;
    //几个空函数
    pf-&gt;prefetch_fenc_420 = prefetch_fenc_null;
    pf-&gt;prefetch_fenc_422 = prefetch_fenc_null;
    pf-&gt;prefetch_ref  = prefetch_ref_null;
    pf-&gt;memcpy_aligned = memcpy;
    pf-&gt;memzero_aligned = memzero_aligned;
    //降低分辨率-线性内插（不是半像素内插）
    pf-&gt;frame_init_lowres_core = frame_init_lowres_core;

    pf-&gt;integral_init4h = integral_init4h;
    pf-&gt;integral_init8h = integral_init8h;
    pf-&gt;integral_init4v = integral_init4v;
    pf-&gt;integral_init8v = integral_init8v;

    pf-&gt;mbtree_propagate_cost = mbtree_propagate_cost;
    pf-&gt;mbtree_propagate_list = mbtree_propagate_list;
    //各种汇编版本
#if HAVE_MMX
    x264_mc_init_mmx( cpu, pf );
#endif
#if HAVE_ALTIVEC
    if( cpu&amp;X264_CPU_ALTIVEC )
        x264_mc_altivec_init( pf );
#endif
#if HAVE_ARMV6
    x264_mc_init_arm( cpu, pf );
#endif
#if ARCH_AARCH64
    x264_mc_init_aarch64( cpu, pf );
#endif

    if( cpu_independent )
    {
        pf-&gt;mbtree_propagate_cost = mbtree_propagate_cost;
        pf-&gt;mbtree_propagate_list = mbtree_propagate_list;
    }
}
</pre><br />从源代码可以看出，x264_mc_init()中包含了大量的像素内插、拷贝、求平均的函数。这些函数都是用于在H.264编码过程中进行运动估计和运动补偿的。x264_mc_init()的参数x264_mc_functions_t是一个结构体，其中包含了运动补偿函数相关的函数接口。x264_mc_functions_t的定义如下。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_30_7519205" name="code" class="cpp">typedef struct
{
    void (*mc_luma)( pixel *dst, intptr_t i_dst, pixel **src, intptr_t i_src,
                     int mvx, int mvy, int i_width, int i_height, const x264_weight_t *weight );

    /* may round up the dimensions if they're not a power of 2 */
    pixel* (*get_ref)( pixel *dst, intptr_t *i_dst, pixel **src, intptr_t i_src,
                       int mvx, int mvy, int i_width, int i_height, const x264_weight_t *weight );

    /* mc_chroma may write up to 2 bytes of garbage to the right of dst,
     * so it must be run from left to right. */
    void (*mc_chroma)( pixel *dstu, pixel *dstv, intptr_t i_dst, pixel *src, intptr_t i_src,
                       int mvx, int mvy, int i_width, int i_height );

    void (*avg[12])( pixel *dst,  intptr_t dst_stride, pixel *src1, intptr_t src1_stride,
                     pixel *src2, intptr_t src2_stride, int i_weight );

    /* only 16x16, 8x8, and 4x4 defined */
    void (*copy[7])( pixel *dst, intptr_t dst_stride, pixel *src, intptr_t src_stride, int i_height );
    void (*copy_16x16_unaligned)( pixel *dst, intptr_t dst_stride, pixel *src, intptr_t src_stride, int i_height );

    void (*store_interleave_chroma)( pixel *dst, intptr_t i_dst, pixel *srcu, pixel *srcv, int height );
    void (*load_deinterleave_chroma_fenc)( pixel *dst, pixel *src, intptr_t i_src, int height );
    void (*load_deinterleave_chroma_fdec)( pixel *dst, pixel *src, intptr_t i_src, int height );

    void (*plane_copy)( pixel *dst, intptr_t i_dst, pixel *src, intptr_t i_src, int w, int h );
    void (*plane_copy_interleave)( pixel *dst,  intptr_t i_dst, pixel *srcu, intptr_t i_srcu,
                                   pixel *srcv, intptr_t i_srcv, int w, int h );
    /* may write up to 15 pixels off the end of each plane */
    void (*plane_copy_deinterleave)( pixel *dstu, intptr_t i_dstu, pixel *dstv, intptr_t i_dstv,
                                     pixel *src,  intptr_t i_src, int w, int h );
    void (*plane_copy_deinterleave_rgb)( pixel *dsta, intptr_t i_dsta, pixel *dstb, intptr_t i_dstb,
                                         pixel *dstc, intptr_t i_dstc, pixel *src,  intptr_t i_src, int pw, int w, int h );
    void (*plane_copy_deinterleave_v210)( pixel *dsty, intptr_t i_dsty,
                                          pixel *dstc, intptr_t i_dstc,
                                          uint32_t *src, intptr_t i_src, int w, int h );
    void (*hpel_filter)( pixel *dsth, pixel *dstv, pixel *dstc, pixel *src,
                         intptr_t i_stride, int i_width, int i_height, int16_t *buf );

    /* prefetch the next few macroblocks of fenc or fdec */
    void (*prefetch_fenc)    ( pixel *pix_y, intptr_t stride_y, pixel *pix_uv, intptr_t stride_uv, int mb_x );
    void (*prefetch_fenc_420)( pixel *pix_y, intptr_t stride_y, pixel *pix_uv, intptr_t stride_uv, int mb_x );
    void (*prefetch_fenc_422)( pixel *pix_y, intptr_t stride_y, pixel *pix_uv, intptr_t stride_uv, int mb_x );
    /* prefetch the next few macroblocks of a hpel reference frame */
    void (*prefetch_ref)( pixel *pix, intptr_t stride, int parity );

    void *(*memcpy_aligned)( void *dst, const void *src, size_t n );
    void (*memzero_aligned)( void *dst, size_t n );

    /* successive elimination prefilter */
    void (*integral_init4h)( uint16_t *sum, pixel *pix, intptr_t stride );
    void (*integral_init8h)( uint16_t *sum, pixel *pix, intptr_t stride );
    void (*integral_init4v)( uint16_t *sum8, uint16_t *sum4, intptr_t stride );
    void (*integral_init8v)( uint16_t *sum8, intptr_t stride );

    void (*frame_init_lowres_core)( pixel *src0, pixel *dst0, pixel *dsth, pixel *dstv, pixel *dstc,
                                    intptr_t src_stride, intptr_t dst_stride, int width, int height );
    weight_fn_t *weight;
    weight_fn_t *offsetadd;
    weight_fn_t *offsetsub;
    void (*weight_cache)( x264_t *, x264_weight_t * );

    void (*mbtree_propagate_cost)( int16_t *dst, uint16_t *propagate_in, uint16_t *intra_costs,
                                   uint16_t *inter_costs, uint16_t *inv_qscales, float *fps_factor, int len );

    void (*mbtree_propagate_list)( x264_t *h, uint16_t *ref_costs, int16_t (*mvs)[2],
                                   int16_t *propagate_amount, uint16_t *lowres_costs,
                                   int bipred_weight, int mb_y, int len, int list );
} x264_mc_functions_t;
</pre>x264_mc_init()的工作就是对x264_mc_functions_t中的函数指针进行赋值。由于运动估计和运动补偿在x264中属于相对复杂的环节，其中许多函数的作用很难三言两语表述出来，因此只举一个相对简单的例子——半像素内插函数hpel_filter()。<br /><br /><h3>相关知识简述</h3><span style="white-space:pre">	</span>简单记录一下半像素插值的知识。《H.264标准》中规定，运动估计为1/4像素精度。因此在H.264编码和解码的过程中，需要将画面中的像素进行插值——简单地说就是把原先的1个像素点拓展成4x4一共16个点。下图显示了H.264编码和解码过程中像素插值情况。可以看出原先的G点的右下方通过插值的方式产生了a、b、c、d等一共16个点。<br /><div style="text-align: center;"><img src="https://img-blog.csdn.net/20150511163017167?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><span style="white-space:pre">	</span>如图所示，1/4像素内插一般分成两步：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">（1）半像素内插。这一步通过6抽头滤波器获得5个半像素点。<br />（2）线性内插。这一步通过简单的线性内插获得剩余的1/4像素点。</blockquote><p><span style="white-space:pre">	</span>图中半像素内插点为b、m、h、s、j五个点。半像素内插方法是对整像素点进行6 抽头滤波得出，滤波器的权重为(1/32, -5/32, 5/8, 5/8, -5/32, 1/32)。例如b的计算公式为：</p><p style="text-align: center;"><strong>b=round( (E - 5F + 20G + 20H - 5I + J ) / 32)</strong></p>剩下几个半像素点的计算关系如下：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">m：由B、D、H、N、S、U计算<br />h：由A、C、G、M、R、T计算<br />s：由K、L、M、N、P、Q计算<br />j：由cc、dd、h、m、ee、ff计算。需要注意j点的运算量比较大，因为cc、dd、ee、ff都需要通过半像素内插方法进行计算。</blockquote><p>在获得半像素点之后，就可以通过简单的线性内插获得1/4像素内插点了。1/4像素内插的方式如下图所示。例如图中a点的计算公式如下：</p><p style="text-align: center;"><strong>A=round( (G+b)/2 )</strong></p>在这里有一点需要注意：位于4个角的e、g、p、r四个点并不是通过j点计算计算的，而是通过b、h、s、m四个半像素点计算的。<br /><p style="text-align: center;"><img src="https://img-blog.csdn.net/20150511163543694?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></p><p><br /></p><h3>hpel_filter()</h3>hpel_filter()用于进行半像素插值。该函数的定义位于common\mc.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_31_8471849" name="code" class="cpp">//半像素插值公式
//b= (E - 5F + 20G + 20H - 5I + J)/32
//              x
//d取1，水平滤波器；d取stride，垂直滤波器（这里没有除以32）
#define TAPFILTER(pix, d) ((pix)[x-2*d] + (pix)[x+3*d] - 5*((pix)[x-d] + (pix)[x+2*d]) + 20*((pix)[x] + (pix)[x+d]))

/*
 * 半像素插值
 * dsth：水平滤波得到的半像素点(aa,bb,b,s,gg,hh)
 * dstv：垂直滤波的到的半像素点(cc,dd,h,m,ee,ff)
 * dstc：“水平+垂直”滤波得到的位于4个像素中间的半像素点（j）
 *
 * 半像素插值示意图如下：
 *
 *         A aa B
 *
 *         C bb D
 *
 * E   F   G  b H   I   J
 *
 * cc  dd  h  j m  ee  ff
 *
 * K   L   M  s N   P   Q
 *
 *         R gg S
 *
 *         T hh U
 *
 * 计算公式如下：
 * b=round( (E - 5F + 20G + 20H - 5I + J ) / 32)
 *
 * 剩下几个半像素点的计算关系如下：
 * m：由B、D、H、N、S、U计算
 * h：由A、C、G、M、R、T计算
 * s：由K、L、M、N、P、Q计算
 * j：由cc、dd、h、m、ee、ff计算。需要注意j点的运算量比较大，因为cc、dd、ee、ff都需要通过半像素内插方法进行计算。
 *
 */
static void hpel_filter( pixel *dsth, pixel *dstv, pixel *dstc, pixel *src,
                         intptr_t stride, int width, int height, int16_t *buf )
{
    const int pad = (BIT_DEPTH &gt; 9) ? (-10 * PIXEL_MAX) : 0;
    /*
     * 几种半像素点之间的位置关系
     *
     * X： 像素点
     * H：水平滤波半像素点
     * V：垂直滤波半像素点
     * C： 中间位置半像素点
     *
	 * X   H   X       X       X
	 *
	 * V   C
	 *
	 * X       X       X       X
	 *
	 *
	 *
	 * X       X       X       X
	 *
	 */
    //一行一行处理
    for( int y = 0; y &lt; height; y++ )
    {
    	//一个一个点处理
    	//每个整像素点都对应h，v，c三个半像素点
    	//v
        for( int x = -2; x &lt; width+3; x++ )//(aa,bb,b,s,gg,hh),结果存入buf
        {
        	//垂直滤波半像素点
            int v = TAPFILTER(src,stride);
            dstv[x] = x264_clip_pixel( (v + 16) &gt;&gt; 5 );
            /* transform v for storage in a 16-bit integer */
            //这应该是给dstc计算使用的？
            buf[x+2] = v + pad;
        }
        //c
        for( int x = 0; x &lt; width; x++ )
            dstc[x] = x264_clip_pixel( (TAPFILTER(buf+2,1) - 32*pad + 512) &gt;&gt; 10 );//四个相邻像素中间的半像素点
        //h
        for( int x = 0; x &lt; width; x++ )
            dsth[x] = x264_clip_pixel( (TAPFILTER(src,1) + 16) &gt;&gt; 5 );//水平滤波半像素点
        dsth += stride;
        dstv += stride;
        dstc += stride;
        src += stride;
    }
}
</pre><br /><p>从源代码可以看出，hpel_filter()中包含了一个宏TAPFILTER()用来完成半像素点像素值的计算。在完成半像素插值工作后，dsth中存储的是经过水平插值后的半像素点，dstv中存储的是经过垂直插值后的半像素点，dstc中存储的是位于4个相邻像素点中间位置的半像素点。这三块内存中的点的位置关系如下图所示（灰色的点是整像素点）。</p><p style="text-align: center;"><img src="https://img-blog.csdn.net/20150511164004851" alt="" /><br /></p><br /><h2>x264_quant_init()</h2>x264_quant_init()初始化量化和反量化相关的汇编函数。该函数的定义位于common\quant.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_32_1376341" name="code" class="cpp">//量化
void x264_quant_init( x264_t *h, int cpu, x264_quant_function_t *pf )
{
	//这个好像是针对8x8DCT的
    pf-&gt;quant_8x8 = quant_8x8;

    //量化4x4=16个
    pf-&gt;quant_4x4 = quant_4x4;
    //注意：处理4个4x4的块
    pf-&gt;quant_4x4x4 = quant_4x4x4;
    //Intra16x16中，16个DC系数Hadamard变换后对的它们量化
    pf-&gt;quant_4x4_dc = quant_4x4_dc;
    pf-&gt;quant_2x2_dc = quant_2x2_dc;
    //反量化4x4=16个
    pf-&gt;dequant_4x4 = dequant_4x4;
    pf-&gt;dequant_4x4_dc = dequant_4x4_dc;
    pf-&gt;dequant_8x8 = dequant_8x8;

    pf-&gt;idct_dequant_2x4_dc = idct_dequant_2x4_dc;
    pf-&gt;idct_dequant_2x4_dconly = idct_dequant_2x4_dconly;

    pf-&gt;optimize_chroma_2x2_dc = optimize_chroma_2x2_dc;
    pf-&gt;optimize_chroma_2x4_dc = optimize_chroma_2x4_dc;

    pf-&gt;denoise_dct = x264_denoise_dct;
    pf-&gt;decimate_score15 = x264_decimate_score15;
    pf-&gt;decimate_score16 = x264_decimate_score16;
    pf-&gt;decimate_score64 = x264_decimate_score64;

    pf-&gt;coeff_last4 = x264_coeff_last4;
    pf-&gt;coeff_last8 = x264_coeff_last8;
    pf-&gt;coeff_last[  DCT_LUMA_AC] = x264_coeff_last15;
    pf-&gt;coeff_last[ DCT_LUMA_4x4] = x264_coeff_last16;
    pf-&gt;coeff_last[ DCT_LUMA_8x8] = x264_coeff_last64;
    pf-&gt;coeff_level_run4 = x264_coeff_level_run4;
    pf-&gt;coeff_level_run8 = x264_coeff_level_run8;
    pf-&gt;coeff_level_run[  DCT_LUMA_AC] = x264_coeff_level_run15;
    pf-&gt;coeff_level_run[ DCT_LUMA_4x4] = x264_coeff_level_run16;

#if HIGH_BIT_DEPTH
#if HAVE_MMX
    INIT_TRELLIS( sse2 );
    if( cpu&amp;X264_CPU_MMX2 )
    {
#if ARCH_X86
        pf-&gt;denoise_dct = x264_denoise_dct_mmx;
        pf-&gt;decimate_score15 = x264_decimate_score15_mmx2;
        pf-&gt;decimate_score16 = x264_decimate_score16_mmx2;
        pf-&gt;decimate_score64 = x264_decimate_score64_mmx2;
        pf-&gt;coeff_last8 = x264_coeff_last8_mmx2;
        pf-&gt;coeff_last[  DCT_LUMA_AC] = x264_coeff_last15_mmx2;
        pf-&gt;coeff_last[ DCT_LUMA_4x4] = x264_coeff_last16_mmx2;
        pf-&gt;coeff_last[ DCT_LUMA_8x8] = x264_coeff_last64_mmx2;
        pf-&gt;coeff_level_run8 = x264_coeff_level_run8_mmx2;
        pf-&gt;coeff_level_run[  DCT_LUMA_AC] = x264_coeff_level_run15_mmx2;
        pf-&gt;coeff_level_run[ DCT_LUMA_4x4] = x264_coeff_level_run16_mmx2;
#endif
        pf-&gt;coeff_last4 = x264_coeff_last4_mmx2;
        pf-&gt;coeff_level_run4 = x264_coeff_level_run4_mmx2;
        if( cpu&amp;X264_CPU_LZCNT )
            pf-&gt;coeff_level_run4 = x264_coeff_level_run4_mmx2_lzcnt;
    }
    //此处省略大量的X86、ARM等平台的汇编函数初始化代码
}
</pre><br />从源代码可以看出，x264_quant_init ()初始化了一系列的量化相关的函数。它的输入参数x264_quant_function_t是一个结构体，其中包含了和量化相关各种函数指针。x264_quant_function_t的定义如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_33_725803" name="code" class="cpp">typedef struct
{
    int (*quant_8x8)  ( dctcoef dct[64], udctcoef mf[64], udctcoef bias[64] );
    int (*quant_4x4)  ( dctcoef dct[16], udctcoef mf[16], udctcoef bias[16] );
    int (*quant_4x4x4)( dctcoef dct[4][16], udctcoef mf[16], udctcoef bias[16] );
    int (*quant_4x4_dc)( dctcoef dct[16], int mf, int bias );
    int (*quant_2x2_dc)( dctcoef dct[4], int mf, int bias );

    void (*dequant_8x8)( dctcoef dct[64], int dequant_mf[6][64], int i_qp );
    void (*dequant_4x4)( dctcoef dct[16], int dequant_mf[6][16], int i_qp );
    void (*dequant_4x4_dc)( dctcoef dct[16], int dequant_mf[6][16], int i_qp );

    void (*idct_dequant_2x4_dc)( dctcoef dct[8], dctcoef dct4x4[8][16], int dequant_mf[6][16], int i_qp );
    void (*idct_dequant_2x4_dconly)( dctcoef dct[8], int dequant_mf[6][16], int i_qp );

    int (*optimize_chroma_2x2_dc)( dctcoef dct[4], int dequant_mf );
    int (*optimize_chroma_2x4_dc)( dctcoef dct[8], int dequant_mf );

    void (*denoise_dct)( dctcoef *dct, uint32_t *sum, udctcoef *offset, int size );

    int (*decimate_score15)( dctcoef *dct );
    int (*decimate_score16)( dctcoef *dct );
    int (*decimate_score64)( dctcoef *dct );
    int (*coeff_last[14])( dctcoef *dct );
    int (*coeff_last4)( dctcoef *dct );
    int (*coeff_last8)( dctcoef *dct );
    int (*coeff_level_run[13])( dctcoef *dct, x264_run_level_t *runlevel );
    int (*coeff_level_run4)( dctcoef *dct, x264_run_level_t *runlevel );
    int (*coeff_level_run8)( dctcoef *dct, x264_run_level_t *runlevel );

#define TRELLIS_PARAMS const int *unquant_mf, const uint8_t *zigzag, int lambda2,\
                       int last_nnz, dctcoef *coefs, dctcoef *quant_coefs, dctcoef *dct,\
                       uint8_t *cabac_state_sig, uint8_t *cabac_state_last,\
                       uint64_t level_state0, uint16_t level_state1
    int (*trellis_cabac_4x4)( TRELLIS_PARAMS, int b_ac );
    int (*trellis_cabac_8x8)( TRELLIS_PARAMS, int b_interlaced );
    int (*trellis_cabac_4x4_psy)( TRELLIS_PARAMS, int b_ac, dctcoef *fenc_dct, int psy_trellis );
    int (*trellis_cabac_8x8_psy)( TRELLIS_PARAMS, int b_interlaced, dctcoef *fenc_dct, int psy_trellis );
    int (*trellis_cabac_dc)( TRELLIS_PARAMS, int num_coefs );
    int (*trellis_cabac_chroma_422_dc)( TRELLIS_PARAMS );
} x264_quant_function_t;
</pre>x264_quant_init ()的工作就是对x264_quant_function_t中的函数指针进行赋值。下文举例分析其中2个函数：4x4矩阵量化函数quant_4x4()，4个4x4矩阵量化函数quant_4x4x4()。<br /><br /><h3>相关知识简述</h3><p><span style="white-space:pre">	</span>简单记录一下量化的概念。量化是H.264视频压缩编码中对视频质量影响最大的地方，也是会导致“信息丢失”的地方。量化的原理可以表示为下面公式：</p><p style="text-align: center;"><strong>FQ=round(y/Qstep)</strong></p><p><span style="white-space:pre">	</span>其中，y 为输入样本点编码，Qstep为量化步长，FQ 为y 的量化值，round()为取整函数（其输出为与输入实数最近的整数）。其相反过程，即反量化为：</p><div style="text-align: center;"><strong>y’＝FQ*Qstep</strong></div><span style="white-space:pre">	</span>如果Qstep较大，则量化值FQ取值较小，其相应的编码长度较小，但是但反量化时损失较多的图像细节信息。简而言之，Qstep越大，视频压缩编码后体积越小，视频质量越差。<br /><span style="white-space:pre">	</span>在H.264 中，量化步长Qstep 共有52 个值，如下表所示。其中QP 是量化参数，是量化步长的序号。当QP 取最小值0 时代表最精细的量化，当QP 取最大值51 时代表最粗糙的量化。QP 每增加6，Qstep 增加一倍。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511163843762?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><p><span style="white-space:pre">	</span>《H.264标准》中规定，量化过程除了完成本职工作外，还需要完成它前一步DCT变换中“系数相乘”的工作。这一步骤的推导过程不再记录，直接给出最终的公式（这个公式完全为整数运算，同时避免了除法的使用）：</p><div style="text-align: center;"><strong>|Zij| = (|Wij|*MF + f)&gt;&gt;qbits</strong></div><p style="text-align: center;"><strong>sign(Zij) = sign (Wij)</strong></p>其中：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">sign()为符号函数。<br />Wij为DCT变换后的系数。<br />MF的值如下表所示。表中只列出对应QP 值为0 到5 的MF 值。QP大于6之后，将QP实行对6取余数操作，再找到MF的值。<br />qbits计算公式为“qbits = 15 + floor(QP/6)”。即它的值随QP 值每增加6 而增加1。<br />f 是偏移量（用于改善恢复图像的视觉效果）。对帧内预测图像块取2^qbits/3，对帧间预测图像块取2^qbits/6。</blockquote><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511164216562?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div>为了更形象的显示MF的取值，做了下面一张示意图。图中深蓝色代表MF取值较大的点，而浅蓝色代表MF取值较小的点。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511164228886" alt="" /></div><br /><h3>quant_4x4()</h3>quant_4x4()用于对4x4的DCT残差矩阵进行量化。该函数的定义位于common\quant.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_34_2267874" name="code" class="cpp">//4x4量化
//输入输出都是dct[16]
static int quant_4x4( dctcoef dct[16], udctcoef mf[16], udctcoef bias[16] )
{
    int nz = 0;
    //循环16个元素
    for( int i = 0; i &lt; 16; i++ )
        QUANT_ONE( dct[i], mf[i], bias[i] );
    return !!nz;
}</pre>可以看出quant_4x4()循环16次调用了QUANT_ONE()完成了量化工作。并且将DCT系数值，MF值，bias偏移值直接传递给了该宏。<br /><br /><h3>QUANT_ONE()</h3>QUANT_ONE()完成了一个DCT系数的量化工作，它的定义如下。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_35_6110457" name="code" class="cpp">//量化1个元素
#define QUANT_ONE( coef, mf, f ) \
{ \
    if( (coef) &gt; 0 ) \
        (coef) = (f + (coef)) * (mf) &gt;&gt; 16; \
    else \
        (coef) = - ((f - (coef)) * (mf) &gt;&gt; 16); \
    nz |= (coef); \
}</pre>从QUANT_ONE()的定义可以看出，它实现了上文提到的H.264标准中的量化公式。<br /><br /><h3>quant_4x4x4()</h3>quant_4x4x4()用于对4个4x4的DCT残差矩阵进行量化。该函数的定义位于common\quant.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_36_1556224" name="code" class="cpp">//处理4个4x4量化
//输入输出都是dct[4][16]
static int quant_4x4x4( dctcoef dct[4][16], udctcoef mf[16], udctcoef bias[16] )
{
    int nza = 0;
    //处理4个
    for( int j = 0; j &lt; 4; j++ )
    {
        int nz = 0;
        //量化
        for( int i = 0; i &lt; 16; i++ )
            QUANT_ONE( dct[j][i], mf[i], bias[i] );
        nza |= (!!nz)&lt;&lt;j;
    }
    return nza;
}</pre>从quant_4x4x4()的定义可以看出，该函数相当于调用了4次quant_4x4()函数。<br /><br /><h2>x264_deblock_init()</h2>x264_deblock_init()用于初始化去块效应滤波器相关的汇编函数。该函数的定义位于common\deblock.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_37_6686345" name="code" class="cpp">//去块效应滤波
void x264_deblock_init( int cpu, x264_deblock_function_t *pf, int b_mbaff )
{
	//注意：标记“v”的垂直滤波器是处理水平边界用的
	//亮度-普通滤波器-边界强度Bs=1,2,3
    pf-&gt;deblock_luma[1] = deblock_v_luma_c;
    pf-&gt;deblock_luma[0] = deblock_h_luma_c;
    //色度的
    pf-&gt;deblock_chroma[1] = deblock_v_chroma_c;
    pf-&gt;deblock_h_chroma_420 = deblock_h_chroma_c;
    pf-&gt;deblock_h_chroma_422 = deblock_h_chroma_422_c;
    //亮度-强滤波器-边界强度Bs=4
    pf-&gt;deblock_luma_intra[1] = deblock_v_luma_intra_c;
    pf-&gt;deblock_luma_intra[0] = deblock_h_luma_intra_c;
    pf-&gt;deblock_chroma_intra[1] = deblock_v_chroma_intra_c;
    pf-&gt;deblock_h_chroma_420_intra = deblock_h_chroma_intra_c;
    pf-&gt;deblock_h_chroma_422_intra = deblock_h_chroma_422_intra_c;
    pf-&gt;deblock_luma_mbaff = deblock_h_luma_mbaff_c;
    pf-&gt;deblock_chroma_420_mbaff = deblock_h_chroma_mbaff_c;
    pf-&gt;deblock_luma_intra_mbaff = deblock_h_luma_intra_mbaff_c;
    pf-&gt;deblock_chroma_420_intra_mbaff = deblock_h_chroma_intra_mbaff_c;
    pf-&gt;deblock_strength = deblock_strength_c;

#if HAVE_MMX
    if( cpu&amp;X264_CPU_MMX2 )
    {
#if ARCH_X86
        pf-&gt;deblock_luma[1] = x264_deblock_v_luma_mmx2;
        pf-&gt;deblock_luma[0] = x264_deblock_h_luma_mmx2;
        pf-&gt;deblock_chroma[1] = x264_deblock_v_chroma_mmx2;
        pf-&gt;deblock_h_chroma_420 = x264_deblock_h_chroma_mmx2;
        pf-&gt;deblock_chroma_420_mbaff = x264_deblock_h_chroma_mbaff_mmx2;
        pf-&gt;deblock_h_chroma_422 = x264_deblock_h_chroma_422_mmx2;
        pf-&gt;deblock_h_chroma_422_intra = x264_deblock_h_chroma_422_intra_mmx2;
        pf-&gt;deblock_luma_intra[1] = x264_deblock_v_luma_intra_mmx2;
        pf-&gt;deblock_luma_intra[0] = x264_deblock_h_luma_intra_mmx2;
        pf-&gt;deblock_chroma_intra[1] = x264_deblock_v_chroma_intra_mmx2;
        pf-&gt;deblock_h_chroma_420_intra = x264_deblock_h_chroma_intra_mmx2;
        pf-&gt;deblock_chroma_420_intra_mbaff = x264_deblock_h_chroma_intra_mbaff_mmx2;
#endif
    //此处省略大量的X86、ARM等平台的汇编函数初始化代码
}
</pre><br />从源代码可以看出，x264_deblock_init()中初始化了一系列环路滤波函数。这些函数名称的规则如下：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">（1）包含“v”的是垂直滤波器，用于处理水平边界；包含“h”的是水平滤波器，用于处理垂直边界。<br />（2）包含“luma”的是亮度滤波器，包含“chroma”的是色度滤波器。<br />（3）包含“intra”的是处理边界强度Bs为4的强滤波器，不包含“intra”的是普通滤波器。</blockquote><p>x264_deblock_init()的输入参数x264_deblock_function_t是一个结构体，其中包含了环路滤波器相关的函数指针。x264_deblock_function_t的定义如下所示。</p><pre code_snippet_id="664118" snippet_file_name="blog_20150511_38_462889" name="code" class="cpp">typedef struct
{
    x264_deblock_inter_t deblock_luma[2];
    x264_deblock_inter_t deblock_chroma[2];
    x264_deblock_inter_t deblock_h_chroma_420;
    x264_deblock_inter_t deblock_h_chroma_422;
    x264_deblock_intra_t deblock_luma_intra[2];
    x264_deblock_intra_t deblock_chroma_intra[2];
    x264_deblock_intra_t deblock_h_chroma_420_intra;
    x264_deblock_intra_t deblock_h_chroma_422_intra;
    x264_deblock_inter_t deblock_luma_mbaff;
    x264_deblock_inter_t deblock_chroma_mbaff;
    x264_deblock_inter_t deblock_chroma_420_mbaff;
    x264_deblock_inter_t deblock_chroma_422_mbaff;
    x264_deblock_intra_t deblock_luma_intra_mbaff;
    x264_deblock_intra_t deblock_chroma_intra_mbaff;
    x264_deblock_intra_t deblock_chroma_420_intra_mbaff;
    x264_deblock_intra_t deblock_chroma_422_intra_mbaff;
    void (*deblock_strength) ( uint8_t nnz[X264_SCAN8_SIZE], int8_t ref[2][X264_SCAN8_LUMA_SIZE],
                               int16_t mv[2][X264_SCAN8_LUMA_SIZE][2], uint8_t bs[2][8][4], int mvy_limit,
                               int bframe );
} x264_deblock_function_t;</pre>x264_deblock_init()的工作就是对x264_deblock_function_t中的函数指针进行赋值。可以看出x264_deblock_function_t中很多的元素是一个包含2个元素的数组，例如deblock_luma[2]，deblock_luma_intra[2]等。这些数组中的元素[0]一般是水平滤波器，而元素[1]是垂直滤波器。下文将会举例分析一个普通边界的亮度垂直滤波器函数deblock_v_luma_c()。<br /><br /><h3>相关知识简述</h3><span style="white-space:pre">	</span>简单记录一下环路滤波（去块效应滤波）的知识。X264的重建帧（通过解码得到）一般情况下会出现方块效应。产生这种效应的原因主要有两个：<br /><blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">（1）DCT变换后的量化造成误差（主要原因）。<br />（2）运动补偿</blockquote><span style="white-space:pre">	</span>正是由于这种块效应的存在，才需要添加环路滤波器调整相邻的“块”边缘上的像素值以减轻这种视觉上的不连续感。下面一张图显示了环路滤波的效果。图中左边的图没有使用环路滤波，而右边的图使用了环路滤波。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511164554495?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><br /><strong>环路滤波分类</strong><br /><span style="white-space:pre">	</span>环路滤波器根据滤波的强度可以分为两种：<br /><span style="white-space:pre">	</span>（1）普通滤波器。针对边界的Bs（边界强度）为1、2、3的滤波器。此时环路滤波涉及到方块边界周围的6个点（边界两边各3个点）：p2，p1，p0，q0，q1，q2。需要处理4个点（边界两边各2个点，只以p点为例）：<br /><div style="text-align: center;"><strong>p0’ = p0 + (((q0 - p0 ) &lt;&lt; 2) + (p1 - q1) + 4) &gt;&gt; 3</strong></div><strong></strong><div style="text-align: center;"><strong>p1’ = ( p2 + ( ( p0 + q0 + 1 ) &gt;&gt; 1) – 2p1 ) &gt;&gt; 1</strong></div><span style="white-space:pre">	</span>（2）强滤波器。针对边界的Bs（边界强度）为4的滤波器。此时环路滤波涉及到方块边界周围的8个点（边界两边各4个点）：p3，p2，p1，p0，q0，q1，q2，q3。需要处理6个点（边界两边各3个点，只以p点为例）：<br /><div style="text-align: center;"><strong>p0’ = ( p2 + 2*p1 + 2*p0 + 2*q0 + q1 + 4 ) &gt;&gt; 3</strong></div><div style="text-align: center;"><strong>p1’ = ( p2 + p1 + p0 + q0 + 2 ) &gt;&gt; 2</strong></div><div style="text-align: center;"><strong>p2’ = ( 2*p3 + 3*p2 + p1 + p0 + q0 + 4 ) &gt;&gt; 3</strong></div><span style="white-space:pre">	</span>其中上文中提到的边界强度Bs的判定方式如下。<br /><table border="1" cellspacing="0" cellpadding="0" align="center" width="500"> <tbody><tr>  <td valign="top"><p align="center">条件（针对两边的图像块）</p></td>  <td valign="top"><p align="center">Bs</p></td> </tr> <tr>  <td valign="top"><p align="center">有一个块为帧内预测 + 边界为宏块边界</p></td>  <td valign="top"><p align="center">4</p></td> </tr> <tr>  <td valign="top"><p align="center">有一个块为帧内预测</p></td>  <td valign="top"><p align="center">3</p></td> </tr> <tr>  <td valign="top"><p align="center">有一个块对残差编码</p></td>  <td valign="top"><p align="center">2</p></td> </tr> <tr>  <td valign="top"><p align="center">运动矢量差不小于1像素</p></td>  <td valign="top"><p align="center">1</p></td> </tr> <tr>  <td valign="top"><p align="center">运动补偿参考帧不同</p></td>  <td valign="top"><p align="center">1</p></td> </tr> <tr>  <td valign="top"><p align="center">其它</p></td>  <td valign="top"><p align="center">0</p></td> </tr></tbody></table><br /><span style="white-space:pre">	</span>总体说来，与帧内预测相关的图像块（帧内预测块）的边界强度比较大，取值为3或者4；与运动补偿相关的图像块（帧间预测块）的边界强度比较小，取值为1。<br /><br /><strong>环路滤波的门限</strong><br /><span style="white-space:pre">	</span>并不是所有的块的边界处都需要环路滤波。例如画面中物体的边界正好和块的边界重合的话，就不能进行滤波，否则会使画面中物体的边界变模糊。因此需要区别开物体边界和块效应边界。一般情况下，物体边界两边的像素值差别很大，而块效应边界两边像素值差别比较小。《H.264标准》以这个特点定义了2个变量alpha和beta来判决边界是否需要进行环路滤波。只有满足下面三个条件的时候才能进行环路滤波：<br /><div style="text-align: center;"><strong>| p0 - q0 | &lt; alpha</strong></div><div style="text-align: center;"><strong>| p1 – p0 | &lt; beta</strong></div><div style="text-align: center;"><strong>| q1 - q0 | &lt; beta</strong></div><span style="white-space:pre">	</span>简而言之，就是边界两边的两个点的像素值不能太大，即不能超过alpha；边界一边的前两个点之间的像素值也不能太大，即不能超过beta。其中alpha和beta是根据量化参数QP推算出来（具体方法不再记录）。总体说来QP越大，alpha和beta的值也越大，也就越容易触发环路滤波。由于QP越大表明压缩的程度越大，所以也可以得知高压缩比的情况下更需要进行环路滤波。<br /><br /><h3>deblock_v_luma_c()</h3>deblock_v_luma_c()是一个普通强度的垂直滤波器，用于处理边界强度Bs为1，2，3的水平边界。该函数的定义位于common\deblock.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_39_7054490" name="code" class="cpp">//去块效应滤波-普通滤波，Bs为1,2,3
//垂直（Vertical）滤波器
//      边界
//         x
//         x
// 边界----------
//         x
//         x
//
//
static void deblock_v_luma_c( pixel *pix, intptr_t stride, int alpha, int beta, int8_t *tc0 )
{
	//xstride=stride（用于选择滤波的像素）
	//ystride=1
    deblock_luma_c( pix, stride, 1, alpha, beta, tc0 );
}
</pre>可以看出deblock_v_luma_c()调用了另一个函数deblock_luma_c()。需要注意传递给deblock_luma_c()是一个水平滤波器和垂直滤波器都会调用的“通用”滤波器函数。在这里传递给deblock_luma_c()第二个参数xstride的值为stride，第三个参数ystride的值为1。<br /><br /><h3>deblock_luma_c()</h3>deblock_luma_c()是一个通用的滤波器函数，定义如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_40_2782881" name="code" class="cpp">//去块效应滤波-普通滤波，Bs为1,2,3
static inline void deblock_luma_c( pixel *pix, intptr_t xstride, intptr_t ystride, int alpha, int beta, int8_t *tc0 )
{
    for( int i = 0; i &lt; 4; i++ )
    {
        if( tc0[i] &lt; 0 )
        {
            pix += 4*ystride;
            continue;
        }
        //滤4个像素
        for( int d = 0; d &lt; 4; d++, pix += ystride )
            deblock_edge_luma_c( pix, xstride, alpha, beta, tc0[i] );
    }
}
</pre>从源代码中可以看出，具体的滤波在deblock_edge_luma_c()中完成。处理完一个像素后，会继续处理与当前像素距离为ystride的像素。<br /><br /><h3>deblock_edge_luma_c()</h3>deblock_edge_luma_c()用于完成具体的滤波工作。该函数的定义如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_41_7356595" name="code" class="cpp">/* From ffmpeg */
//去块效应滤波-普通滤波，Bs为1,2,3
//从FFmpeg复制过来的？
static ALWAYS_INLINE void deblock_edge_luma_c( pixel *pix, intptr_t xstride, int alpha, int beta, int8_t tc0 )
{
	//p和q
	//如果xstride=stride，ystride=1
	//就是处理纵向的6个像素
	//对应的是方块的横向边界的滤波，即如下所示：
	//        p2
	//        p1
	//        p0
	//=====图像边界=====
	//        q0
	//        q1
	//        q2
	//
	//如果xstride=1，ystride=stride
	//就是处理纵向的6个像素
	//对应的是方块的横向边界的滤波，即如下所示：
	//          ||
	// p2 p1 p0 || q0 q1 q2
	//          ||
	//          边界

	//注意：这里乘的是xstride

    int p2 = pix[-3*xstride];
    int p1 = pix[-2*xstride];
    int p0 = pix[-1*xstride];
    int q0 = pix[ 0*xstride];
    int q1 = pix[ 1*xstride];
    int q2 = pix[ 2*xstride];
	//计算方法参考相关的标准
	//alpha和beta是用于检查图像内容的2个参数
	//只有满足if()里面3个取值条件的时候（只涉及边界旁边的4个点），才会滤波
    if( abs( p0 - q0 ) &lt; alpha &amp;&amp; abs( p1 - p0 ) &lt; beta &amp;&amp; abs( q1 - q0 ) &lt; beta )
    {
        int tc = tc0;
        int delta;
        //上面2个点（p0，p2）满足条件的时候，滤波p1
        //int x264_clip3( int v, int i_min, int i_max )用于限幅
        if( abs( p2 - p0 ) &lt; beta )
        {
            if( tc0 )
                pix[-2*xstride] = p1 + x264_clip3( (( p2 + ((p0 + q0 + 1) &gt;&gt; 1)) &gt;&gt; 1) - p1, -tc0, tc0 );
            tc++;
        }
        //下面2个点（q0，q2）满足条件的时候，滤波q1
        if( abs( q2 - q0 ) &lt; beta )
        {
            if( tc0 )
                pix[ 1*xstride] = q1 + x264_clip3( (( q2 + ((p0 + q0 + 1) &gt;&gt; 1)) &gt;&gt; 1) - q1, -tc0, tc0 );
            tc++;
        }

        delta = x264_clip3( (((q0 - p0 ) &lt;&lt; 2) + (p1 - q1) + 4) &gt;&gt; 3, -tc, tc );
        //p0
        pix[-1*xstride] = x264_clip_pixel( p0 + delta );    /* p0' */
        //q0
        pix[ 0*xstride] = x264_clip_pixel( q0 - delta );    /* q0' */
    }
}</pre>从源代码可以看出，deblock_edge_luma_c()实现了前文记录的滤波公式。<br /><br /><h3>deblock_h_luma_c()</h3>deblock_h_luma_c()是一个普通强度的水平滤波器，用于处理边界强度Bs为1，2，3的垂直边界。该函数的定义如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_42_9181291" name="code" class="cpp">//去块效应滤波-普通滤波，Bs为1,2,3
//水平（Horizontal）滤波器
//      边界
//       |
// x x x | x x x
//       |
static void deblock_h_luma_c( pixel *pix, intptr_t stride, int alpha, int beta, int8_t *tc0 )
{
	//xstride=1（用于选择滤波的像素）
	//ystride=stride
    deblock_luma_c( pix, 1, stride, alpha, beta, tc0 );
}</pre>从源代码可以看出，和deblock_v_luma_c()类似，deblock_h_luma_c()同样调用了deblock_luma_c()函数。唯一的不同在于它传递给deblock_luma_c()的第2个参数xstride为1，第3个参数ystride为stride。<br /><br /><h2>mbcmp_init()</h2>mbcmp_init()函数决定了x264_pixel_function_t中的像素比较的一系列函数（mbcmp[]）使用SAD还是SATD。该函数的定义位于encoder\encoder.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_43_2118804" name="code" class="cpp">//决定了像素比较的时候用SAD还是SATD
static void mbcmp_init( x264_t *h )
{
	//b_lossless一般为0
    //主要看i_subpel_refine，大于1的话就使用SATD
    int satd = !h-&gt;mb.b_lossless &amp;&amp; h-&gt;param.analyse.i_subpel_refine &gt; 1;

    //sad或者satd赋值给mbcmp
    memcpy( h-&gt;pixf.mbcmp, satd ? h-&gt;pixf.satd : h-&gt;pixf.sad_aligned, sizeof(h-&gt;pixf.mbcmp) );
    memcpy( h-&gt;pixf.mbcmp_unaligned, satd ? h-&gt;pixf.satd : h-&gt;pixf.sad, sizeof(h-&gt;pixf.mbcmp_unaligned) );
    h-&gt;pixf.intra_mbcmp_x3_16x16 = satd ? h-&gt;pixf.intra_satd_x3_16x16 : h-&gt;pixf.intra_sad_x3_16x16;
    h-&gt;pixf.intra_mbcmp_x3_8x16c = satd ? h-&gt;pixf.intra_satd_x3_8x16c : h-&gt;pixf.intra_sad_x3_8x16c;
    h-&gt;pixf.intra_mbcmp_x3_8x8c  = satd ? h-&gt;pixf.intra_satd_x3_8x8c  : h-&gt;pixf.intra_sad_x3_8x8c;
    h-&gt;pixf.intra_mbcmp_x3_8x8 = satd ? h-&gt;pixf.intra_sa8d_x3_8x8 : h-&gt;pixf.intra_sad_x3_8x8;
    h-&gt;pixf.intra_mbcmp_x3_4x4 = satd ? h-&gt;pixf.intra_satd_x3_4x4 : h-&gt;pixf.intra_sad_x3_4x4;
    h-&gt;pixf.intra_mbcmp_x9_4x4 = h-&gt;param.b_cpu_independent || h-&gt;mb.b_lossless ? NULL
                               : satd ? h-&gt;pixf.intra_satd_x9_4x4 : h-&gt;pixf.intra_sad_x9_4x4;
    h-&gt;pixf.intra_mbcmp_x9_8x8 = h-&gt;param.b_cpu_independent || h-&gt;mb.b_lossless ? NULL
                               : satd ? h-&gt;pixf.intra_sa8d_x9_8x8 : h-&gt;pixf.intra_sad_x9_8x8;
    satd &amp;= h-&gt;param.analyse.i_me_method == X264_ME_TESA;
    memcpy( h-&gt;pixf.fpelcmp, satd ? h-&gt;pixf.satd : h-&gt;pixf.sad, sizeof(h-&gt;pixf.fpelcmp) );
    memcpy( h-&gt;pixf.fpelcmp_x3, satd ? h-&gt;pixf.satd_x3 : h-&gt;pixf.sad_x3, sizeof(h-&gt;pixf.fpelcmp_x3) );
    memcpy( h-&gt;pixf.fpelcmp_x4, satd ? h-&gt;pixf.satd_x4 : h-&gt;pixf.sad_x4, sizeof(h-&gt;pixf.fpelcmp_x4) );
}
</pre><br />从mbcmp_init()的源代码可以看出，当i_subpel_refine取值大于1的时候，satd变量为1，此时后续代码中赋值给mbcmp[]相关的一系列函数指针的函数就是SATD函数；当i_subpel_refine取值小于等于1的时候，satd变量为0，此时后续代码中赋值给mbcmp[]相关的一系列函数指针的函数就是SAD函数。<br /><br />至此x264_encoder_open()的源代码就分析完毕了。下文继续分析x264_encoder_headers()和x264_encoder_close()函数。<br /><br /><br /><h1>x264_encoder_headers()</h1>x264_encoder_headers()是libx264的一个API函数，用于输出SPS/PPS/SEI这些H.264码流的头信息。该函数的声明如下。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_44_5579702" name="code" class="cpp">/* x264_encoder_headers:
 *      return the SPS and PPS that will be used for the whole stream.
 *      *pi_nal is the number of NAL units outputted in pp_nal.
 *      returns the number of bytes in the returned NALs.
 *      returns negative on error.
 *      the payloads of all output NALs are guaranteed to be sequential in memory. */
int     x264_encoder_headers( x264_t *, x264_nal_t **pp_nal, int *pi_nal );</pre>x264_encoder_headers()的定义位于encoder\encoder.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_45_9040601" name="code" class="cpp">/****************************************************************************
 * x264_encoder_headers:
 * 注释和处理：雷霄骅
 * http://blog.csdn.net/leixiaohua1020
 * leixiaohua1020@126.com
 ****************************************************************************/
//输出文件头（SPS、PPS、SEI）
int x264_encoder_headers( x264_t *h, x264_nal_t **pp_nal, int *pi_nal )
{
    int frame_size = 0;
    /* init bitstream context */
    h-&gt;out.i_nal = 0;
    bs_init( &amp;h-&gt;out.bs, h-&gt;out.p_bitstream, h-&gt;out.i_bitstream );

    /* Write SEI, SPS and PPS. */

    /* generate sequence parameters */
    //输出SPS
    x264_nal_start( h, NAL_SPS, NAL_PRIORITY_HIGHEST );
    x264_sps_write( &amp;h-&gt;out.bs, h-&gt;sps );
    if( x264_nal_end( h ) )
        return -1;

    /* generate picture parameters */
    x264_nal_start( h, NAL_PPS, NAL_PRIORITY_HIGHEST );
    //输出PPS
    x264_pps_write( &amp;h-&gt;out.bs, h-&gt;sps, h-&gt;pps );
    if( x264_nal_end( h ) )
        return -1;

    /* identify ourselves */
    x264_nal_start( h, NAL_SEI, NAL_PRIORITY_DISPOSABLE );
    //输出SEI（其中包含了配置信息）
    if( x264_sei_version_write( h, &amp;h-&gt;out.bs ) )
        return -1;
    if( x264_nal_end( h ) )
        return -1;

    frame_size = x264_encoder_encapsulate_nals( h, 0 );
    if( frame_size &lt; 0 )
        return -1;

    /* now set output*/
    *pi_nal = h-&gt;out.i_nal;
    *pp_nal = &amp;h-&gt;out.nal[0];
    h-&gt;out.i_nal = 0;

    return frame_size;
}
</pre><br />从源代码可以看出，x264_encoder_headers()分别调用了x264_sps_write()，x264_pps_write()，x264_sei_version_write()输出了SPS，PPS，和SEI信息。在输出每个NALU之前，需要调用x264_nal_start()，在输出NALU之后，需要调用x264_nal_end()。下文继续分析上述三个函数。<br /><br /><h2>x264_sps_write()</h2>x264_sps_write()用于输出SPS。该函数的定义位于encoder\set.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_46_9752483" name="code" class="cpp">//输出SPS
void x264_sps_write( bs_t *s, x264_sps_t *sps )
{
    bs_realign( s );
    //型profile，8bit
    bs_write( s, 8, sps-&gt;i_profile_idc );
    bs_write1( s, sps-&gt;b_constraint_set0 );
    bs_write1( s, sps-&gt;b_constraint_set1 );
    bs_write1( s, sps-&gt;b_constraint_set2 );
    bs_write1( s, sps-&gt;b_constraint_set3 );

    bs_write( s, 4, 0 );    /* reserved */
    //级level，8bit
    bs_write( s, 8, sps-&gt;i_level_idc );
    //本SPS的 id号
    bs_write_ue( s, sps-&gt;i_id );

    if( sps-&gt;i_profile_idc &gt;= PROFILE_HIGH )
    {
    	//色度取样格式
		//0代表单色
		//1代表4:2:0
		//2代表4:2:2
		//3代表4:4:4
        bs_write_ue( s, sps-&gt;i_chroma_format_idc );
        if( sps-&gt;i_chroma_format_idc == CHROMA_444 )
            bs_write1( s, 0 ); // separate_colour_plane_flag
        //亮度
        //颜色位深=bit_depth_luma_minus8+8
        bs_write_ue( s, BIT_DEPTH-8 ); // bit_depth_luma_minus8
        //色度与亮度一样
        bs_write_ue( s, BIT_DEPTH-8 ); // bit_depth_chroma_minus8
        bs_write1( s, sps-&gt;b_qpprime_y_zero_transform_bypass );
        bs_write1( s, 0 ); // seq_scaling_matrix_present_flag
    }
    //log2_max_frame_num_minus4主要是为读取另一个句法元素frame_num服务的
    //frame_num 是最重要的句法元素之一
    //这个句法元素指明了frame_num的所能达到的最大值：
    //MaxFrameNum = 2^( log2_max_frame_num_minus4 + 4 )
    bs_write_ue( s, sps-&gt;i_log2_max_frame_num - 4 );
    //pic_order_cnt_type 指明了poc (picture order count) 的编码方法
    //poc标识图像的播放顺序。
    //由于H.264使用了B帧预测，使得图像的解码顺序并不一定等于播放顺序，但它们之间存在一定的映射关系
    //poc 可以由frame-num 通过映射关系计算得来，也可以索性由编码器显式地传送。
    //H.264 中一共定义了三种poc 的编码方法
    bs_write_ue( s, sps-&gt;i_poc_type );
    if( sps-&gt;i_poc_type == 0 )
        bs_write_ue( s, sps-&gt;i_log2_max_poc_lsb - 4 );
    //num_ref_frames 指定参考帧队列可能达到的最大长度，解码器依照这个句法元素的值开辟存储区，这个存储区用于存放已解码的参考帧，
    //H.264 规定最多可用16 个参考帧，因此最大值为16。
    bs_write_ue( s, sps-&gt;i_num_ref_frames );
    bs_write1( s, sps-&gt;b_gaps_in_frame_num_value_allowed );
    //pic_width_in_mbs_minus1加1后为图像宽（以宏块为单位）：
    //           PicWidthInMbs = pic_width_in_mbs_minus1 + 1
    //以像素为单位图像宽度（亮度）：width=PicWidthInMbs*16
    bs_write_ue( s, sps-&gt;i_mb_width - 1 );
    //pic_height_in_map_units_minus1加1后指明图像高度（以宏块为单位）
    bs_write_ue( s, (sps-&gt;i_mb_height &gt;&gt; !sps-&gt;b_frame_mbs_only) - 1);
    bs_write1( s, sps-&gt;b_frame_mbs_only );
    if( !sps-&gt;b_frame_mbs_only )
        bs_write1( s, sps-&gt;b_mb_adaptive_frame_field );
    bs_write1( s, sps-&gt;b_direct8x8_inference );

    bs_write1( s, sps-&gt;b_crop );
    if( sps-&gt;b_crop )
    {
        int h_shift = sps-&gt;i_chroma_format_idc == CHROMA_420 || sps-&gt;i_chroma_format_idc == CHROMA_422;
        int v_shift = sps-&gt;i_chroma_format_idc == CHROMA_420;
        bs_write_ue( s, sps-&gt;crop.i_left   &gt;&gt; h_shift );
        bs_write_ue( s, sps-&gt;crop.i_right  &gt;&gt; h_shift );
        bs_write_ue( s, sps-&gt;crop.i_top    &gt;&gt; v_shift );
        bs_write_ue( s, sps-&gt;crop.i_bottom &gt;&gt; v_shift );
    }

    bs_write1( s, sps-&gt;b_vui );
    if( sps-&gt;b_vui )
    {
        bs_write1( s, sps-&gt;vui.b_aspect_ratio_info_present );
        if( sps-&gt;vui.b_aspect_ratio_info_present )
        {
            int i;
            static const struct { uint8_t w, h, sar; } sar[] =
            {
                // aspect_ratio_idc = 0 -&gt; unspecified
                {  1,  1, 1 }, { 12, 11, 2 }, { 10, 11, 3 }, { 16, 11, 4 },
                { 40, 33, 5 }, { 24, 11, 6 }, { 20, 11, 7 }, { 32, 11, 8 },
                { 80, 33, 9 }, { 18, 11, 10}, { 15, 11, 11}, { 64, 33, 12},
                {160, 99, 13}, {  4,  3, 14}, {  3,  2, 15}, {  2,  1, 16},
                // aspect_ratio_idc = [17..254] -&gt; reserved
                { 0, 0, 255 }
            };
            for( i = 0; sar[i].sar != 255; i++ )
            {
                if( sar[i].w == sps-&gt;vui.i_sar_width &amp;&amp;
                    sar[i].h == sps-&gt;vui.i_sar_height )
                    break;
            }
            bs_write( s, 8, sar[i].sar );
            if( sar[i].sar == 255 ) /* aspect_ratio_idc (extended) */
            {
                bs_write( s, 16, sps-&gt;vui.i_sar_width );
                bs_write( s, 16, sps-&gt;vui.i_sar_height );
            }
        }

        bs_write1( s, sps-&gt;vui.b_overscan_info_present );
        if( sps-&gt;vui.b_overscan_info_present )
            bs_write1( s, sps-&gt;vui.b_overscan_info );

        bs_write1( s, sps-&gt;vui.b_signal_type_present );
        if( sps-&gt;vui.b_signal_type_present )
        {
            bs_write( s, 3, sps-&gt;vui.i_vidformat );
            bs_write1( s, sps-&gt;vui.b_fullrange );
            bs_write1( s, sps-&gt;vui.b_color_description_present );
            if( sps-&gt;vui.b_color_description_present )
            {
                bs_write( s, 8, sps-&gt;vui.i_colorprim );
                bs_write( s, 8, sps-&gt;vui.i_transfer );
                bs_write( s, 8, sps-&gt;vui.i_colmatrix );
            }
        }

        bs_write1( s, sps-&gt;vui.b_chroma_loc_info_present );
        if( sps-&gt;vui.b_chroma_loc_info_present )
        {
            bs_write_ue( s, sps-&gt;vui.i_chroma_loc_top );
            bs_write_ue( s, sps-&gt;vui.i_chroma_loc_bottom );
        }

        bs_write1( s, sps-&gt;vui.b_timing_info_present );
        if( sps-&gt;vui.b_timing_info_present )
        {
            bs_write32( s, sps-&gt;vui.i_num_units_in_tick );
            bs_write32( s, sps-&gt;vui.i_time_scale );
            bs_write1( s, sps-&gt;vui.b_fixed_frame_rate );
        }

        bs_write1( s, sps-&gt;vui.b_nal_hrd_parameters_present );
        if( sps-&gt;vui.b_nal_hrd_parameters_present )
        {
            bs_write_ue( s, sps-&gt;vui.hrd.i_cpb_cnt - 1 );
            bs_write( s, 4, sps-&gt;vui.hrd.i_bit_rate_scale );
            bs_write( s, 4, sps-&gt;vui.hrd.i_cpb_size_scale );

            bs_write_ue( s, sps-&gt;vui.hrd.i_bit_rate_value - 1 );
            bs_write_ue( s, sps-&gt;vui.hrd.i_cpb_size_value - 1 );

            bs_write1( s, sps-&gt;vui.hrd.b_cbr_hrd );

            bs_write( s, 5, sps-&gt;vui.hrd.i_initial_cpb_removal_delay_length - 1 );
            bs_write( s, 5, sps-&gt;vui.hrd.i_cpb_removal_delay_length - 1 );
            bs_write( s, 5, sps-&gt;vui.hrd.i_dpb_output_delay_length - 1 );
            bs_write( s, 5, sps-&gt;vui.hrd.i_time_offset_length );
        }

        bs_write1( s, sps-&gt;vui.b_vcl_hrd_parameters_present );

        if( sps-&gt;vui.b_nal_hrd_parameters_present || sps-&gt;vui.b_vcl_hrd_parameters_present )
            bs_write1( s, 0 );   /* low_delay_hrd_flag */

        bs_write1( s, sps-&gt;vui.b_pic_struct_present );
        bs_write1( s, sps-&gt;vui.b_bitstream_restriction );
        if( sps-&gt;vui.b_bitstream_restriction )
        {
            bs_write1( s, sps-&gt;vui.b_motion_vectors_over_pic_boundaries );
            bs_write_ue( s, sps-&gt;vui.i_max_bytes_per_pic_denom );
            bs_write_ue( s, sps-&gt;vui.i_max_bits_per_mb_denom );
            bs_write_ue( s, sps-&gt;vui.i_log2_max_mv_length_horizontal );
            bs_write_ue( s, sps-&gt;vui.i_log2_max_mv_length_vertical );
            bs_write_ue( s, sps-&gt;vui.i_num_reorder_frames );
            bs_write_ue( s, sps-&gt;vui.i_max_dec_frame_buffering );
        }
    }

    //RBSP拖尾
    //无论比特流当前位置是否字节对齐 ， 都向其中写入一个比特1及若干个（0~7个）比特0 ， 使其字节对齐
    bs_rbsp_trailing( s );
    bs_flush( s );
}
</pre><br />可以看出x264_sps_write()将x264_sps_t结构体中的信息输出出来形成了一个NALU。有关SPS相关的知识可以参考《H.264标准》。<br /><br /><h2>x264_pps_write()</h2>x264_pps_write()用于输出PPS。该函数的定义位于encoder\set.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_47_8753280" name="code" class="cpp">//输出PPS
void x264_pps_write( bs_t *s, x264_sps_t *sps, x264_pps_t *pps )
{
    bs_realign( s );
    //PPS的ID
    bs_write_ue( s, pps-&gt;i_id );
    //该PPS引用的SPS的ID
    bs_write_ue( s, pps-&gt;i_sps_id );
    //entropy_coding_mode_flag
    //0表示熵编码使用CAVLC，1表示熵编码使用CABAC
    bs_write1( s, pps-&gt;b_cabac );
    bs_write1( s, pps-&gt;b_pic_order );
    bs_write_ue( s, pps-&gt;i_num_slice_groups - 1 );

    bs_write_ue( s, pps-&gt;i_num_ref_idx_l0_default_active - 1 );
    bs_write_ue( s, pps-&gt;i_num_ref_idx_l1_default_active - 1 );
    //P Slice 是否使用加权预测？
    bs_write1( s, pps-&gt;b_weighted_pred );
    //B Slice 是否使用加权预测？
    bs_write( s, 2, pps-&gt;b_weighted_bipred );
    //pic_init_qp_minus26加26后用以指明亮度分量的QP的初始值。
    bs_write_se( s, pps-&gt;i_pic_init_qp - 26 - QP_BD_OFFSET );
    bs_write_se( s, pps-&gt;i_pic_init_qs - 26 - QP_BD_OFFSET );
    bs_write_se( s, pps-&gt;i_chroma_qp_index_offset );

    bs_write1( s, pps-&gt;b_deblocking_filter_control );
    bs_write1( s, pps-&gt;b_constrained_intra_pred );
    bs_write1( s, pps-&gt;b_redundant_pic_cnt );

    if( pps-&gt;b_transform_8x8_mode || pps-&gt;i_cqm_preset != X264_CQM_FLAT )
    {
        bs_write1( s, pps-&gt;b_transform_8x8_mode );
        bs_write1( s, (pps-&gt;i_cqm_preset != X264_CQM_FLAT) );
        if( pps-&gt;i_cqm_preset != X264_CQM_FLAT )
        {
            scaling_list_write( s, pps, CQM_4IY );
            scaling_list_write( s, pps, CQM_4IC );
            bs_write1( s, 0 ); // Cr = Cb
            scaling_list_write( s, pps, CQM_4PY );
            scaling_list_write( s, pps, CQM_4PC );
            bs_write1( s, 0 ); // Cr = Cb
            if( pps-&gt;b_transform_8x8_mode )
            {
                if( sps-&gt;i_chroma_format_idc == CHROMA_444 )
                {
                    scaling_list_write( s, pps, CQM_8IY+4 );
                    scaling_list_write( s, pps, CQM_8IC+4 );
                    bs_write1( s, 0 ); // Cr = Cb
                    scaling_list_write( s, pps, CQM_8PY+4 );
                    scaling_list_write( s, pps, CQM_8PC+4 );
                    bs_write1( s, 0 ); // Cr = Cb
                }
                else
                {
                    scaling_list_write( s, pps, CQM_8IY+4 );
                    scaling_list_write( s, pps, CQM_8PY+4 );
                }
            }
        }
        bs_write_se( s, pps-&gt;i_chroma_qp_index_offset );
    }

    //RBSP拖尾
    //无论比特流当前位置是否字节对齐 ， 都向其中写入一个比特1及若干个（0~7个）比特0 ， 使其字节对齐
    bs_rbsp_trailing( s );
    bs_flush( s );
}
</pre><br />可以看出x264_pps_write()将x264_pps_t结构体中的信息输出出来形成了一个NALU。<br /><br /><h2>x264_sei_version_write()</h2>x264_sei_version_write()用于输出SEI。SEI中一般存储了H.264中的一些附加信息，例如下图中红色方框中的文字就是x264存储在SEI中的中的信息。<br /><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511165601183" alt="" /></div>x264_sei_version_write()的定义位于encoder\set.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_48_6707301" name="code" class="cpp">//输出SEI（其中包含了配置信息）
int x264_sei_version_write( x264_t *h, bs_t *s )
{
    // random ID number generated according to ISO-11578
    static const uint8_t uuid[16] =
    {
        0xdc, 0x45, 0xe9, 0xbd, 0xe6, 0xd9, 0x48, 0xb7,
        0x96, 0x2c, 0xd8, 0x20, 0xd9, 0x23, 0xee, 0xef
    };
    //把设置信息转换为字符串
    char *opts = x264_param2string( &amp;h-&gt;param, 0 );
    char *payload;
    int length;

    if( !opts )
        return -1;
    CHECKED_MALLOC( payload, 200 + strlen( opts ) );

    memcpy( payload, uuid, 16 );
    //配置信息的内容
    //opts字符串内容还是挺多的
    sprintf( payload+16, &quot;x264 - core %d%s - H.264/MPEG-4 AVC codec - &quot;
             &quot;Copy%s 2003-2014 - http://www.videolan.org/x264.html - options: %s&quot;,
             X264_BUILD, X264_VERSION, HAVE_GPL?&quot;left&quot;:&quot;right&quot;, opts );
    length = strlen(payload)+1;
    //输出SEI
    //数据类型为USER_DATA_UNREGISTERED
    x264_sei_write( s, (uint8_t *)payload, length, SEI_USER_DATA_UNREGISTERED );

    x264_free( opts );
    x264_free( payload );
    return 0;
fail:
    x264_free( opts );
    return -1;
}
</pre><br />从源代码可以看出，x264_sei_version_write()首先调用了x264_param2string()将当前的配置参数保存到字符串opts[]中，然后调用sprintf()结合opt[]生成完整的SEI信息，最后调用x264_sei_write()输出SEI信息。在这个过程中涉及到一个libx264的API函数x264_param2string()。<br /><br /><h3>x264_param2string()</h3>x264_param2string()用于将当前设置转换为字符串输出出来。该函数的声明如下。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_49_8249372" name="code" class="cpp">/* x264_param2string: return a (malloced) string containing most of
 * the encoding options */
char *x264_param2string( x264_param_t *p, int b_res );</pre>x264_param2string()的定义位于common\common.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_50_3171751" name="code" class="cpp">/****************************************************************************
 * x264_param2string:
 ****************************************************************************/
//把设置信息转换为字符串
char *x264_param2string( x264_param_t *p, int b_res )
{
    int len = 1000;
    char *buf, *s;
    if( p-&gt;rc.psz_zones )
        len += strlen(p-&gt;rc.psz_zones);
    //1000字节？
    buf = s = x264_malloc( len );
    if( !buf )
        return NULL;

    if( b_res )
    {
        s += sprintf( s, &quot;%dx%d &quot;, p-&gt;i_width, p-&gt;i_height );
        s += sprintf( s, &quot;fps=%u/%u &quot;, p-&gt;i_fps_num, p-&gt;i_fps_den );
        s += sprintf( s, &quot;timebase=%u/%u &quot;, p-&gt;i_timebase_num, p-&gt;i_timebase_den );
        s += sprintf( s, &quot;bitdepth=%d &quot;, BIT_DEPTH );
    }

    if( p-&gt;b_opencl )
        s += sprintf( s, &quot;opencl=%d &quot;, p-&gt;b_opencl );
    s += sprintf( s, &quot;cabac=%d&quot;, p-&gt;b_cabac );
    s += sprintf( s, &quot; ref=%d&quot;, p-&gt;i_frame_reference );
    s += sprintf( s, &quot; deblock=%d:%d:%d&quot;, p-&gt;b_deblocking_filter,
                  p-&gt;i_deblocking_filter_alphac0, p-&gt;i_deblocking_filter_beta );
    s += sprintf( s, &quot; analyse=%#x:%#x&quot;, p-&gt;analyse.intra, p-&gt;analyse.inter );
    s += sprintf( s, &quot; me=%s&quot;, x264_motion_est_names[ p-&gt;analyse.i_me_method ] );
    s += sprintf( s, &quot; subme=%d&quot;, p-&gt;analyse.i_subpel_refine );
    s += sprintf( s, &quot; psy=%d&quot;, p-&gt;analyse.b_psy );
    if( p-&gt;analyse.b_psy )
        s += sprintf( s, &quot; psy_rd=%.2f:%.2f&quot;, p-&gt;analyse.f_psy_rd, p-&gt;analyse.f_psy_trellis );
    s += sprintf( s, &quot; mixed_ref=%d&quot;, p-&gt;analyse.b_mixed_references );
    s += sprintf( s, &quot; me_range=%d&quot;, p-&gt;analyse.i_me_range );
    s += sprintf( s, &quot; chroma_me=%d&quot;, p-&gt;analyse.b_chroma_me );
    s += sprintf( s, &quot; trellis=%d&quot;, p-&gt;analyse.i_trellis );
    s += sprintf( s, &quot; 8x8dct=%d&quot;, p-&gt;analyse.b_transform_8x8 );
    s += sprintf( s, &quot; cqm=%d&quot;, p-&gt;i_cqm_preset );
    s += sprintf( s, &quot; deadzone=%d,%d&quot;, p-&gt;analyse.i_luma_deadzone[0], p-&gt;analyse.i_luma_deadzone[1] );
    s += sprintf( s, &quot; fast_pskip=%d&quot;, p-&gt;analyse.b_fast_pskip );
    s += sprintf( s, &quot; chroma_qp_offset=%d&quot;, p-&gt;analyse.i_chroma_qp_offset );
    s += sprintf( s, &quot; threads=%d&quot;, p-&gt;i_threads );
    s += sprintf( s, &quot; lookahead_threads=%d&quot;, p-&gt;i_lookahead_threads );
    s += sprintf( s, &quot; sliced_threads=%d&quot;, p-&gt;b_sliced_threads );
    if( p-&gt;i_slice_count )
        s += sprintf( s, &quot; slices=%d&quot;, p-&gt;i_slice_count );
    if( p-&gt;i_slice_count_max )
        s += sprintf( s, &quot; slices_max=%d&quot;, p-&gt;i_slice_count_max );
    if( p-&gt;i_slice_max_size )
        s += sprintf( s, &quot; slice_max_size=%d&quot;, p-&gt;i_slice_max_size );
    if( p-&gt;i_slice_max_mbs )
        s += sprintf( s, &quot; slice_max_mbs=%d&quot;, p-&gt;i_slice_max_mbs );
    if( p-&gt;i_slice_min_mbs )
        s += sprintf( s, &quot; slice_min_mbs=%d&quot;, p-&gt;i_slice_min_mbs );
    s += sprintf( s, &quot; nr=%d&quot;, p-&gt;analyse.i_noise_reduction );
    s += sprintf( s, &quot; decimate=%d&quot;, p-&gt;analyse.b_dct_decimate );
    s += sprintf( s, &quot; interlaced=%s&quot;, p-&gt;b_interlaced ? p-&gt;b_tff ? &quot;tff&quot; : &quot;bff&quot; : p-&gt;b_fake_interlaced ? &quot;fake&quot; : &quot;0&quot; );
    s += sprintf( s, &quot; bluray_compat=%d&quot;, p-&gt;b_bluray_compat );
    if( p-&gt;b_stitchable )
        s += sprintf( s, &quot; stitchable=%d&quot;, p-&gt;b_stitchable );

    s += sprintf( s, &quot; constrained_intra=%d&quot;, p-&gt;b_constrained_intra );

    s += sprintf( s, &quot; bframes=%d&quot;, p-&gt;i_bframe );
    if( p-&gt;i_bframe )
    {
        s += sprintf( s, &quot; b_pyramid=%d b_adapt=%d b_bias=%d direct=%d weightb=%d open_gop=%d&quot;,
                      p-&gt;i_bframe_pyramid, p-&gt;i_bframe_adaptive, p-&gt;i_bframe_bias,
                      p-&gt;analyse.i_direct_mv_pred, p-&gt;analyse.b_weighted_bipred, p-&gt;b_open_gop );
    }
    s += sprintf( s, &quot; weightp=%d&quot;, p-&gt;analyse.i_weighted_pred &gt; 0 ? p-&gt;analyse.i_weighted_pred : 0 );

    if( p-&gt;i_keyint_max == X264_KEYINT_MAX_INFINITE )
        s += sprintf( s, &quot; keyint=infinite&quot; );
    else
        s += sprintf( s, &quot; keyint=%d&quot;, p-&gt;i_keyint_max );
    s += sprintf( s, &quot; keyint_min=%d scenecut=%d intra_refresh=%d&quot;,
                  p-&gt;i_keyint_min, p-&gt;i_scenecut_threshold, p-&gt;b_intra_refresh );

    if( p-&gt;rc.b_mb_tree || p-&gt;rc.i_vbv_buffer_size )
        s += sprintf( s, &quot; rc_lookahead=%d&quot;, p-&gt;rc.i_lookahead );

    s += sprintf( s, &quot; rc=%s mbtree=%d&quot;, p-&gt;rc.i_rc_method == X264_RC_ABR ?
                               ( p-&gt;rc.b_stat_read ? &quot;2pass&quot; : p-&gt;rc.i_vbv_max_bitrate == p-&gt;rc.i_bitrate ? &quot;cbr&quot; : &quot;abr&quot; )
                               : p-&gt;rc.i_rc_method == X264_RC_CRF ? &quot;crf&quot; : &quot;cqp&quot;, p-&gt;rc.b_mb_tree );
    if( p-&gt;rc.i_rc_method == X264_RC_ABR || p-&gt;rc.i_rc_method == X264_RC_CRF )
    {
        if( p-&gt;rc.i_rc_method == X264_RC_CRF )
            s += sprintf( s, &quot; crf=%.1f&quot;, p-&gt;rc.f_rf_constant );
        else
            s += sprintf( s, &quot; bitrate=%d ratetol=%.1f&quot;,
                          p-&gt;rc.i_bitrate, p-&gt;rc.f_rate_tolerance );
        s += sprintf( s, &quot; qcomp=%.2f qpmin=%d qpmax=%d qpstep=%d&quot;,
                      p-&gt;rc.f_qcompress, p-&gt;rc.i_qp_min, p-&gt;rc.i_qp_max, p-&gt;rc.i_qp_step );
        if( p-&gt;rc.b_stat_read )
            s += sprintf( s, &quot; cplxblur=%.1f qblur=%.1f&quot;,
                          p-&gt;rc.f_complexity_blur, p-&gt;rc.f_qblur );
        if( p-&gt;rc.i_vbv_buffer_size )
        {
            s += sprintf( s, &quot; vbv_maxrate=%d vbv_bufsize=%d&quot;,
                          p-&gt;rc.i_vbv_max_bitrate, p-&gt;rc.i_vbv_buffer_size );
            if( p-&gt;rc.i_rc_method == X264_RC_CRF )
                s += sprintf( s, &quot; crf_max=%.1f&quot;, p-&gt;rc.f_rf_constant_max );
        }
    }
    else if( p-&gt;rc.i_rc_method == X264_RC_CQP )
        s += sprintf( s, &quot; qp=%d&quot;, p-&gt;rc.i_qp_constant );

    if( p-&gt;rc.i_vbv_buffer_size )
        s += sprintf( s, &quot; nal_hrd=%s filler=%d&quot;, x264_nal_hrd_names[p-&gt;i_nal_hrd], p-&gt;rc.b_filler );
    if( p-&gt;crop_rect.i_left | p-&gt;crop_rect.i_top | p-&gt;crop_rect.i_right | p-&gt;crop_rect.i_bottom )
        s += sprintf( s, &quot; crop_rect=%u,%u,%u,%u&quot;, p-&gt;crop_rect.i_left, p-&gt;crop_rect.i_top,
                                                   p-&gt;crop_rect.i_right, p-&gt;crop_rect.i_bottom );
    if( p-&gt;i_frame_packing &gt;= 0 )
        s += sprintf( s, &quot; frame-packing=%d&quot;, p-&gt;i_frame_packing );

    if( !(p-&gt;rc.i_rc_method == X264_RC_CQP &amp;&amp; p-&gt;rc.i_qp_constant == 0) )
    {
        s += sprintf( s, &quot; ip_ratio=%.2f&quot;, p-&gt;rc.f_ip_factor );
        if( p-&gt;i_bframe &amp;&amp; !p-&gt;rc.b_mb_tree )
            s += sprintf( s, &quot; pb_ratio=%.2f&quot;, p-&gt;rc.f_pb_factor );
        s += sprintf( s, &quot; aq=%d&quot;, p-&gt;rc.i_aq_mode );
        if( p-&gt;rc.i_aq_mode )
            s += sprintf( s, &quot;:%.2f&quot;, p-&gt;rc.f_aq_strength );
        if( p-&gt;rc.psz_zones )
            s += sprintf( s, &quot; zones=%s&quot;, p-&gt;rc.psz_zones );
        else if( p-&gt;rc.i_zones )
            s += sprintf( s, &quot; zones&quot; );
    }

    return buf;
}
</pre><br />可以看出x264_param2string()几乎遍历了libx264的所有设置选项，使用“s += sprintf()”的形式将它们连接成一个很长的字符串，并最终将该字符串返回。<br /><p><br /></p><p><br /></p><h1>x264_encoder_close()</h1><p>x264_encoder_close()是libx264的一个API函数。该函数用于关闭编码器，同时输出一些统计信息。该函数执行的时候输出的统计信息如下图所示。</p><div style="text-align: center;">&nbsp;<img src="https://img-blog.csdn.net/20150511165759790" alt="" /></div>x264_encoder_close()的声明如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_51_1748220" name="code" class="cpp">/* x264_encoder_close:
 *      close an encoder handler */
void    x264_encoder_close  ( x264_t * );</pre>x264_encoder_close()的定义位于encoder\encoder.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_52_8099057" name="code" class="cpp">/****************************************************************************
 * x264_encoder_close:
 * 注释和处理：雷霄骅
 * http://blog.csdn.net/leixiaohua1020
 * leixiaohua1020@126.com
 ****************************************************************************/
void    x264_encoder_close  ( x264_t *h )
{
    int64_t i_yuv_size = FRAME_SIZE( h-&gt;param.i_width * h-&gt;param.i_height );
    int64_t i_mb_count_size[2][7] = {{0}};
    char buf[200];
    int b_print_pcm = h-&gt;stat.i_mb_count[SLICE_TYPE_I][I_PCM]
                   || h-&gt;stat.i_mb_count[SLICE_TYPE_P][I_PCM]
                   || h-&gt;stat.i_mb_count[SLICE_TYPE_B][I_PCM];

    x264_lookahead_delete( h );

#if HAVE_OPENCL
    x264_opencl_lookahead_delete( h );
    x264_opencl_function_t *ocl = h-&gt;opencl.ocl;
#endif

    if( h-&gt;param.b_sliced_threads )
        x264_threadpool_wait_all( h );
    if( h-&gt;param.i_threads &gt; 1 )
        x264_threadpool_delete( h-&gt;threadpool );
    if( h-&gt;param.i_lookahead_threads &gt; 1 )
        x264_threadpool_delete( h-&gt;lookaheadpool );
    if( h-&gt;i_thread_frames &gt; 1 )
    {
        for( int i = 0; i &lt; h-&gt;i_thread_frames; i++ )
            if( h-&gt;thread[i]-&gt;b_thread_active )
            {
                assert( h-&gt;thread[i]-&gt;fenc-&gt;i_reference_count == 1 );
                x264_frame_delete( h-&gt;thread[i]-&gt;fenc );
            }

        x264_t *thread_prev = h-&gt;thread[h-&gt;i_thread_phase];
        x264_thread_sync_ratecontrol( h, thread_prev, h );
        x264_thread_sync_ratecontrol( thread_prev, thread_prev, h );
        h-&gt;i_frame = thread_prev-&gt;i_frame + 1 - h-&gt;i_thread_frames;
    }
    h-&gt;i_frame++;

    /*
     * x264控制台输出示例
     *
     * x264 [info]: using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX
     * x264 [info]: profile High, level 2.1
     * x264 [info]: frame I:2     Avg QP:20.51  size: 20184  PSNR Mean Y:45.32 U:47.54 V:47.62 Avg:45.94 Global:45.52
     * x264 [info]: frame P:33    Avg QP:23.08  size:  3230  PSNR Mean Y:43.23 U:47.06 V:46.87 Avg:44.15 Global:44.00
     * x264 [info]: frame B:65    Avg QP:27.87  size:   352  PSNR Mean Y:42.76 U:47.21 V:47.05 Avg:43.79 Global:43.65
     * x264 [info]: consecutive B-frames:  3.0% 10.0% 63.0% 24.0%
     * x264 [info]: mb I  I16..4: 15.3% 37.5% 47.3%
     * x264 [info]: mb P  I16..4:  0.6%  0.4%  0.2%  P16..4: 34.6% 21.2% 12.7%  0.0%  0.0%    skip:30.4%
     * x264 [info]: mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 21.2%  4.1%  0.7%  direct: 0.8%  skip:73.1%  L0:28.7% L1:53.0% BI:18.3%
     * x264 [info]: 8x8 transform intra:37.1% inter:51.0%
     * x264 [info]: coded y,uvDC,uvAC intra: 74.1% 83.3% 58.9% inter: 10.4% 6.6% 0.4%
     * x264 [info]: i16 v,h,dc,p: 21% 25%  7% 48%
     * x264 [info]: i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 23% 13%  6%  5%  5%  6%  8% 10%
     * x264 [info]: i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 20%  9%  7%  7%  8%  8%  7% 12%
     * x264 [info]: i8c dc,h,v,p: 43% 20% 27% 10%
     * x264 [info]: Weighted P-Frames: Y:0.0% UV:0.0%
     * x264 [info]: ref P L0: 62.5% 19.7% 13.8%  4.0%
     * x264 [info]: ref B L0: 88.8%  9.4%  1.9%
     * x264 [info]: ref B L1: 92.6%  7.4%
     * x264 [info]: PSNR Mean Y:42.967 U:47.163 V:47.000 Avg:43.950 Global:43.796 kb/s:339.67
     *
     * encoded 100 frames, 178.25 fps, 339.67 kb/s
     *
     */

    /* Slices used and PSNR */
    /* 示例
     * x264 [info]: frame I:2     Avg QP:20.51  size: 20184  PSNR Mean Y:45.32 U:47.54 V:47.62 Avg:45.94 Global:45.52
     * x264 [info]: frame P:33    Avg QP:23.08  size:  3230  PSNR Mean Y:43.23 U:47.06 V:46.87 Avg:44.15 Global:44.00
     * x264 [info]: frame B:65    Avg QP:27.87  size:   352  PSNR Mean Y:42.76 U:47.21 V:47.05 Avg:43.79 Global:43.65
     */
    for( int i = 0; i &lt; 3; i++ )
    {
        static const uint8_t slice_order[] = { SLICE_TYPE_I, SLICE_TYPE_P, SLICE_TYPE_B };
        int i_slice = slice_order[i];

        if( h-&gt;stat.i_frame_count[i_slice] &gt; 0 )
        {
            int i_count = h-&gt;stat.i_frame_count[i_slice];
            double dur =  h-&gt;stat.f_frame_duration[i_slice];
            if( h-&gt;param.analyse.b_psnr )
            {
            	//输出统计信息-包含PSNR
            	//注意PSNR都是通过SSD换算过来的，换算方法就是调用x264_psnr()方法
                x264_log( h, X264_LOG_INFO,
                          &quot;frame %c:%-5d Avg QP:%5.2f  size:%6.0f  PSNR Mean Y:%5.2f U:%5.2f V:%5.2f Avg:%5.2f Global:%5.2f\n&quot;,
                          slice_type_to_char[i_slice],
                          i_count,
                          h-&gt;stat.f_frame_qp[i_slice] / i_count,
                          (double)h-&gt;stat.i_frame_size[i_slice] / i_count,
                          h-&gt;stat.f_psnr_mean_y[i_slice] / dur, h-&gt;stat.f_psnr_mean_u[i_slice] / dur, h-&gt;stat.f_psnr_mean_v[i_slice] / dur,
                          h-&gt;stat.f_psnr_average[i_slice] / dur,
                          x264_psnr( h-&gt;stat.f_ssd_global[i_slice], dur * i_yuv_size ) );
            }
            else
            {
            	//输出统计信息-不包含PSNR
                x264_log( h, X264_LOG_INFO,
                          &quot;frame %c:%-5d Avg QP:%5.2f  size:%6.0f\n&quot;,
                          slice_type_to_char[i_slice],
                          i_count,
                          h-&gt;stat.f_frame_qp[i_slice] / i_count,
                          (double)h-&gt;stat.i_frame_size[i_slice] / i_count );
            }
        }
    }
    /* 示例
     * x264 [info]: consecutive B-frames:  3.0% 10.0% 63.0% 24.0%
     *
     */
    if( h-&gt;param.i_bframe &amp;&amp; h-&gt;stat.i_frame_count[SLICE_TYPE_B] )
    {
    	//B帧相关信息
        char *p = buf;
        int den = 0;
        // weight by number of frames (including the I/P-frames) that are in a sequence of N B-frames
        for( int i = 0; i &lt;= h-&gt;param.i_bframe; i++ )
            den += (i+1) * h-&gt;stat.i_consecutive_bframes[i];
        for( int i = 0; i &lt;= h-&gt;param.i_bframe; i++ )
            p += sprintf( p, &quot; %4.1f%%&quot;, 100. * (i+1) * h-&gt;stat.i_consecutive_bframes[i] / den );
        x264_log( h, X264_LOG_INFO, &quot;consecutive B-frames:%s\n&quot;, buf );
    }

    for( int i_type = 0; i_type &lt; 2; i_type++ )
        for( int i = 0; i &lt; X264_PARTTYPE_MAX; i++ )
        {
            if( i == D_DIRECT_8x8 ) continue; /* direct is counted as its own type */
            i_mb_count_size[i_type][x264_mb_partition_pixel_table[i]] += h-&gt;stat.i_mb_partition[i_type][i];
        }

    /* MB types used */
    /* 示例
     * x264 [info]: mb I  I16..4: 15.3% 37.5% 47.3%
     * x264 [info]: mb P  I16..4:  0.6%  0.4%  0.2%  P16..4: 34.6% 21.2% 12.7%  0.0%  0.0%    skip:30.4%
     * x264 [info]: mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 21.2%  4.1%  0.7%  direct: 0.8%  skip:73.1%  L0:28.7% L1:53.0% BI:18.3%
     */
    if( h-&gt;stat.i_frame_count[SLICE_TYPE_I] &gt; 0 )
    {
        int64_t *i_mb_count = h-&gt;stat.i_mb_count[SLICE_TYPE_I];
        double i_count = h-&gt;stat.i_frame_count[SLICE_TYPE_I] * h-&gt;mb.i_mb_count / 100.0;
        //Intra宏块信息-存于buf
        //从左到右3个信息，依次为I16x16,I8x8,I4x4
        x264_print_intra( i_mb_count, i_count, b_print_pcm, buf );
        x264_log( h, X264_LOG_INFO, &quot;mb I  %s\n&quot;, buf );
    }
    if( h-&gt;stat.i_frame_count[SLICE_TYPE_P] &gt; 0 )
    {
        int64_t *i_mb_count = h-&gt;stat.i_mb_count[SLICE_TYPE_P];
        double i_count = h-&gt;stat.i_frame_count[SLICE_TYPE_P] * h-&gt;mb.i_mb_count / 100.0;
        int64_t *i_mb_size = i_mb_count_size[SLICE_TYPE_P];
        //Intra宏块信息-存于buf
        x264_print_intra( i_mb_count, i_count, b_print_pcm, buf );
        //Intra宏块信息-放在最前面
        //后面添加P宏块信息
        //从左到右6个信息，依次为P16x16, P16x8+P8x16, P8x8, P8x4+P4x8, P4x4, PSKIP
        x264_log( h, X264_LOG_INFO,
                  &quot;mb P  %s  P16..4: %4.1f%% %4.1f%% %4.1f%% %4.1f%% %4.1f%%    skip:%4.1f%%\n&quot;,
                  buf,
                  i_mb_size[PIXEL_16x16] / (i_count*4),
                  (i_mb_size[PIXEL_16x8] + i_mb_size[PIXEL_8x16]) / (i_count*4),
                  i_mb_size[PIXEL_8x8] / (i_count*4),
                  (i_mb_size[PIXEL_8x4] + i_mb_size[PIXEL_4x8]) / (i_count*4),
                  i_mb_size[PIXEL_4x4] / (i_count*4),
                  i_mb_count[P_SKIP] / i_count );
    }
    if( h-&gt;stat.i_frame_count[SLICE_TYPE_B] &gt; 0 )
    {
        int64_t *i_mb_count = h-&gt;stat.i_mb_count[SLICE_TYPE_B];
        double i_count = h-&gt;stat.i_frame_count[SLICE_TYPE_B] * h-&gt;mb.i_mb_count / 100.0;
        double i_mb_list_count;
        int64_t *i_mb_size = i_mb_count_size[SLICE_TYPE_B];
        int64_t list_count[3] = {0}; /* 0 == L0, 1 == L1, 2 == BI */
        //Intra宏块信息
        x264_print_intra( i_mb_count, i_count, b_print_pcm, buf );
        for( int i = 0; i &lt; X264_PARTTYPE_MAX; i++ )
            for( int j = 0; j &lt; 2; j++ )
            {
                int l0 = x264_mb_type_list_table[i][0][j];
                int l1 = x264_mb_type_list_table[i][1][j];
                if( l0 || l1 )
                    list_count[l1+l0*l1] += h-&gt;stat.i_mb_count[SLICE_TYPE_B][i] * 2;
            }
        list_count[0] += h-&gt;stat.i_mb_partition[SLICE_TYPE_B][D_L0_8x8];
        list_count[1] += h-&gt;stat.i_mb_partition[SLICE_TYPE_B][D_L1_8x8];
        list_count[2] += h-&gt;stat.i_mb_partition[SLICE_TYPE_B][D_BI_8x8];
        i_mb_count[B_DIRECT] += (h-&gt;stat.i_mb_partition[SLICE_TYPE_B][D_DIRECT_8x8]+2)/4;
        i_mb_list_count = (list_count[0] + list_count[1] + list_count[2]) / 100.0;
        //Intra宏块信息-放在最前面
        //后面添加B宏块信息
        //从左到右5个信息，依次为B16x16, B16x8+B8x16, B8x8, BDIRECT, BSKIP
        //
        //SKIP和DIRECT区别
        //P_SKIP的CBP为0,无像素残差，无运动矢量残
        //B_SKIP宏块的模式为B_DIRECT且CBP为0,无像素残差，无运动矢量残
        //B_DIRECT的CBP不为0,有像素残差，无运动矢量残
        sprintf( buf + strlen(buf), &quot;  B16..8: %4.1f%% %4.1f%% %4.1f%%  direct:%4.1f%%  skip:%4.1f%%&quot;,
                 i_mb_size[PIXEL_16x16] / (i_count*4),
                 (i_mb_size[PIXEL_16x8] + i_mb_size[PIXEL_8x16]) / (i_count*4),
                 i_mb_size[PIXEL_8x8] / (i_count*4),
                 i_mb_count[B_DIRECT] / i_count,
                 i_mb_count[B_SKIP]   / i_count );
        if( i_mb_list_count != 0 )
            sprintf( buf + strlen(buf), &quot;  L0:%4.1f%% L1:%4.1f%% BI:%4.1f%%&quot;,
                     list_count[0] / i_mb_list_count,
                     list_count[1] / i_mb_list_count,
                     list_count[2] / i_mb_list_count );
        x264_log( h, X264_LOG_INFO, &quot;mb B  %s\n&quot;, buf );
    }
    //码率控制信息
    /* 示例
     * x264 [info]: final ratefactor: 20.01
     */
    x264_ratecontrol_summary( h );

    if( h-&gt;stat.i_frame_count[SLICE_TYPE_I] + h-&gt;stat.i_frame_count[SLICE_TYPE_P] + h-&gt;stat.i_frame_count[SLICE_TYPE_B] &gt; 0 )
    {
#define SUM3(p) (p[SLICE_TYPE_I] + p[SLICE_TYPE_P] + p[SLICE_TYPE_B])
#define SUM3b(p,o) (p[SLICE_TYPE_I][o] + p[SLICE_TYPE_P][o] + p[SLICE_TYPE_B][o])
        int64_t i_i8x8 = SUM3b( h-&gt;stat.i_mb_count, I_8x8 );
        int64_t i_intra = i_i8x8 + SUM3b( h-&gt;stat.i_mb_count, I_4x4 )
                                 + SUM3b( h-&gt;stat.i_mb_count, I_16x16 );
        int64_t i_all_intra = i_intra + SUM3b( h-&gt;stat.i_mb_count, I_PCM);
        int64_t i_skip = SUM3b( h-&gt;stat.i_mb_count, P_SKIP )
                       + SUM3b( h-&gt;stat.i_mb_count, B_SKIP );
        const int i_count = h-&gt;stat.i_frame_count[SLICE_TYPE_I] +
                            h-&gt;stat.i_frame_count[SLICE_TYPE_P] +
                            h-&gt;stat.i_frame_count[SLICE_TYPE_B];
        int64_t i_mb_count = (int64_t)i_count * h-&gt;mb.i_mb_count;
        int64_t i_inter = i_mb_count - i_skip - i_intra;
        const double duration = h-&gt;stat.f_frame_duration[SLICE_TYPE_I] +
                                h-&gt;stat.f_frame_duration[SLICE_TYPE_P] +
                                h-&gt;stat.f_frame_duration[SLICE_TYPE_B];
        float f_bitrate = SUM3(h-&gt;stat.i_frame_size) / duration / 125;
        //隔行
        if( PARAM_INTERLACED )
        {
            char *fieldstats = buf;
            fieldstats[0] = 0;
            if( i_inter )
                fieldstats += sprintf( fieldstats, &quot; inter:%.1f%%&quot;, h-&gt;stat.i_mb_field[1] * 100.0 / i_inter );
            if( i_skip )
                fieldstats += sprintf( fieldstats, &quot; skip:%.1f%%&quot;, h-&gt;stat.i_mb_field[2] * 100.0 / i_skip );
            x264_log( h, X264_LOG_INFO, &quot;field mbs: intra: %.1f%%%s\n&quot;,
                      h-&gt;stat.i_mb_field[0] * 100.0 / i_intra, buf );
        }
        //8x8DCT信息
        if( h-&gt;pps-&gt;b_transform_8x8_mode )
        {
            buf[0] = 0;
            if( h-&gt;stat.i_mb_count_8x8dct[0] )
                sprintf( buf, &quot; inter:%.1f%%&quot;, 100. * h-&gt;stat.i_mb_count_8x8dct[1] / h-&gt;stat.i_mb_count_8x8dct[0] );
            x264_log( h, X264_LOG_INFO, &quot;8x8 transform intra:%.1f%%%s\n&quot;, 100. * i_i8x8 / i_intra, buf );
        }

        if( (h-&gt;param.analyse.i_direct_mv_pred == X264_DIRECT_PRED_AUTO ||
            (h-&gt;stat.i_direct_frames[0] &amp;&amp; h-&gt;stat.i_direct_frames[1]))
            &amp;&amp; h-&gt;stat.i_frame_count[SLICE_TYPE_B] )
        {
            x264_log( h, X264_LOG_INFO, &quot;direct mvs  spatial:%.1f%% temporal:%.1f%%\n&quot;,
                      h-&gt;stat.i_direct_frames[1] * 100. / h-&gt;stat.i_frame_count[SLICE_TYPE_B],
                      h-&gt;stat.i_direct_frames[0] * 100. / h-&gt;stat.i_frame_count[SLICE_TYPE_B] );
        }

        buf[0] = 0;
        int csize = CHROMA444 ? 4 : 1;
        if( i_mb_count != i_all_intra )
            sprintf( buf, &quot; inter: %.1f%% %.1f%% %.1f%%&quot;,
                     h-&gt;stat.i_mb_cbp[1] * 100.0 / ((i_mb_count - i_all_intra)*4),
                     h-&gt;stat.i_mb_cbp[3] * 100.0 / ((i_mb_count - i_all_intra)*csize),
                     h-&gt;stat.i_mb_cbp[5] * 100.0 / ((i_mb_count - i_all_intra)*csize) );
        /*
         * 示例
         * x264 [info]: coded y,uvDC,uvAC intra: 74.1% 83.3% 58.9% inter: 10.4% 6.6% 0.4%
         */
        x264_log( h, X264_LOG_INFO, &quot;coded y,%s,%s intra: %.1f%% %.1f%% %.1f%%%s\n&quot;,
                  CHROMA444?&quot;u&quot;:&quot;uvDC&quot;, CHROMA444?&quot;v&quot;:&quot;uvAC&quot;,
                  h-&gt;stat.i_mb_cbp[0] * 100.0 / (i_all_intra*4),
                  h-&gt;stat.i_mb_cbp[2] * 100.0 / (i_all_intra*csize),
                  h-&gt;stat.i_mb_cbp[4] * 100.0 / (i_all_intra*csize), buf );

        /*
         * 帧内预测信息
         * 从上到下分别为I16x16,I8x8,I4x4
         * 从左到右顺序为Vertical, Horizontal, DC, Plane ....
         *
         * 示例
         *
         * x264 [info]: i16 v,h,dc,p: 21% 25%  7% 48%
         * x264 [info]: i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 23% 13%  6%  5%  5%  6%  8% 10%
         * x264 [info]: i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 20%  9%  7%  7%  8%  8%  7% 12%
         * x264 [info]: i8c dc,h,v,p: 43% 20% 27% 10%
         *
         */
        int64_t fixed_pred_modes[4][9] = {{0}};
        int64_t sum_pred_modes[4] = {0};
        for( int i = 0; i &lt;= I_PRED_16x16_DC_128; i++ )
        {
            fixed_pred_modes[0][x264_mb_pred_mode16x16_fix[i]] += h-&gt;stat.i_mb_pred_mode[0][i];
            sum_pred_modes[0] += h-&gt;stat.i_mb_pred_mode[0][i];
        }
        if( sum_pred_modes[0] )
            x264_log( h, X264_LOG_INFO, &quot;i16 v,h,dc,p: %2.0f%% %2.0f%% %2.0f%% %2.0f%%\n&quot;,
                      fixed_pred_modes[0][0] * 100.0 / sum_pred_modes[0],
                      fixed_pred_modes[0][1] * 100.0 / sum_pred_modes[0],
                      fixed_pred_modes[0][2] * 100.0 / sum_pred_modes[0],
                      fixed_pred_modes[0][3] * 100.0 / sum_pred_modes[0] );

        for( int i = 1; i &lt;= 2; i++ )
        {
            for( int j = 0; j &lt;= I_PRED_8x8_DC_128; j++ )
            {
                fixed_pred_modes[i][x264_mb_pred_mode4x4_fix(j)] += h-&gt;stat.i_mb_pred_mode[i][j];
                sum_pred_modes[i] += h-&gt;stat.i_mb_pred_mode[i][j];
            }
            if( sum_pred_modes[i] )
                x264_log( h, X264_LOG_INFO, &quot;i%d v,h,dc,ddl,ddr,vr,hd,vl,hu: %2.0f%% %2.0f%% %2.0f%% %2.0f%% %2.0f%% %2.0f%% %2.0f%% %2.0f%% %2.0f%%\n&quot;, (3-i)*4,
                          fixed_pred_modes[i][0] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][1] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][2] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][3] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][4] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][5] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][6] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][7] * 100.0 / sum_pred_modes[i],
                          fixed_pred_modes[i][8] * 100.0 / sum_pred_modes[i] );
        }
        for( int i = 0; i &lt;= I_PRED_CHROMA_DC_128; i++ )
        {
            fixed_pred_modes[3][x264_mb_chroma_pred_mode_fix[i]] += h-&gt;stat.i_mb_pred_mode[3][i];
            sum_pred_modes[3] += h-&gt;stat.i_mb_pred_mode[3][i];
        }
        if( sum_pred_modes[3] &amp;&amp; !CHROMA444 )
            x264_log( h, X264_LOG_INFO, &quot;i8c dc,h,v,p: %2.0f%% %2.0f%% %2.0f%% %2.0f%%\n&quot;,
                      fixed_pred_modes[3][0] * 100.0 / sum_pred_modes[3],
                      fixed_pred_modes[3][1] * 100.0 / sum_pred_modes[3],
                      fixed_pred_modes[3][2] * 100.0 / sum_pred_modes[3],
                      fixed_pred_modes[3][3] * 100.0 / sum_pred_modes[3] );

        if( h-&gt;param.analyse.i_weighted_pred &gt;= X264_WEIGHTP_SIMPLE &amp;&amp; h-&gt;stat.i_frame_count[SLICE_TYPE_P] &gt; 0 )
            x264_log( h, X264_LOG_INFO, &quot;Weighted P-Frames: Y:%.1f%% UV:%.1f%%\n&quot;,
                      h-&gt;stat.i_wpred[0] * 100.0 / h-&gt;stat.i_frame_count[SLICE_TYPE_P],
                      h-&gt;stat.i_wpred[1] * 100.0 / h-&gt;stat.i_frame_count[SLICE_TYPE_P] );

        /*
         * 参考帧信息
         * 从左到右依次为不同序号的参考帧
         *
         * 示例
         *
         * x264 [info]: ref P L0: 62.5% 19.7% 13.8%  4.0%
         * x264 [info]: ref B L0: 88.8%  9.4%  1.9%
         * x264 [info]: ref B L1: 92.6%  7.4%
         *
         */
        for( int i_list = 0; i_list &lt; 2; i_list++ )
            for( int i_slice = 0; i_slice &lt; 2; i_slice++ )
            {
                char *p = buf;
                int64_t i_den = 0;
                int i_max = 0;
                for( int i = 0; i &lt; X264_REF_MAX*2; i++ )
                    if( h-&gt;stat.i_mb_count_ref[i_slice][i_list][i] )
                    {
                        i_den += h-&gt;stat.i_mb_count_ref[i_slice][i_list][i];
                        i_max = i;
                    }
                if( i_max == 0 )
                    continue;
                for( int i = 0; i &lt;= i_max; i++ )
                    p += sprintf( p, &quot; %4.1f%%&quot;, 100. * h-&gt;stat.i_mb_count_ref[i_slice][i_list][i] / i_den );
                x264_log( h, X264_LOG_INFO, &quot;ref %c L%d:%s\n&quot;, &quot;PB&quot;[i_slice], i_list, buf );
            }

        if( h-&gt;param.analyse.b_ssim )
        {
            float ssim = SUM3( h-&gt;stat.f_ssim_mean_y ) / duration;
            x264_log( h, X264_LOG_INFO, &quot;SSIM Mean Y:%.7f (%6.3fdb)\n&quot;, ssim, x264_ssim( ssim ) );
        }
        /*
         * 示例
         *
         * x264 [info]: PSNR Mean Y:42.967 U:47.163 V:47.000 Avg:43.950 Global:43.796 kb/s:339.67
         *
         */
        if( h-&gt;param.analyse.b_psnr )
        {
            x264_log( h, X264_LOG_INFO,
                      &quot;PSNR Mean Y:%6.3f U:%6.3f V:%6.3f Avg:%6.3f Global:%6.3f kb/s:%.2f\n&quot;,
                      SUM3( h-&gt;stat.f_psnr_mean_y ) / duration,
                      SUM3( h-&gt;stat.f_psnr_mean_u ) / duration,
                      SUM3( h-&gt;stat.f_psnr_mean_v ) / duration,
                      SUM3( h-&gt;stat.f_psnr_average ) / duration,
                      x264_psnr( SUM3( h-&gt;stat.f_ssd_global ), duration * i_yuv_size ),
                      f_bitrate );
        }
        else
            x264_log( h, X264_LOG_INFO, &quot;kb/s:%.2f\n&quot;, f_bitrate );
    }

    //各种释放

    /* rc */
    x264_ratecontrol_delete( h );

    /* param */
    if( h-&gt;param.rc.psz_stat_out )
        free( h-&gt;param.rc.psz_stat_out );
    if( h-&gt;param.rc.psz_stat_in )
        free( h-&gt;param.rc.psz_stat_in );

    x264_cqm_delete( h );
    x264_free( h-&gt;nal_buffer );
    x264_free( h-&gt;reconfig_h );
    x264_analyse_free_costs( h );

    if( h-&gt;i_thread_frames &gt; 1 )
        h = h-&gt;thread[h-&gt;i_thread_phase];

    /* frames */
    x264_frame_delete_list( h-&gt;frames.unused[0] );
    x264_frame_delete_list( h-&gt;frames.unused[1] );
    x264_frame_delete_list( h-&gt;frames.current );
    x264_frame_delete_list( h-&gt;frames.blank_unused );

    h = h-&gt;thread[0];

    for( int i = 0; i &lt; h-&gt;i_thread_frames; i++ )
        if( h-&gt;thread[i]-&gt;b_thread_active )
            for( int j = 0; j &lt; h-&gt;thread[i]-&gt;i_ref[0]; j++ )
                if( h-&gt;thread[i]-&gt;fref[0][j] &amp;&amp; h-&gt;thread[i]-&gt;fref[0][j]-&gt;b_duplicate )
                    x264_frame_delete( h-&gt;thread[i]-&gt;fref[0][j] );

    if( h-&gt;param.i_lookahead_threads &gt; 1 )
        for( int i = 0; i &lt; h-&gt;param.i_lookahead_threads; i++ )
            x264_free( h-&gt;lookahead_thread[i] );

    for( int i = h-&gt;param.i_threads - 1; i &gt;= 0; i-- )
    {
        x264_frame_t **frame;

        if( !h-&gt;param.b_sliced_threads || i == 0 )
        {
            for( frame = h-&gt;thread[i]-&gt;frames.reference; *frame; frame++ )
            {
                assert( (*frame)-&gt;i_reference_count &gt; 0 );
                (*frame)-&gt;i_reference_count--;
                if( (*frame)-&gt;i_reference_count == 0 )
                    x264_frame_delete( *frame );
            }
            frame = &amp;h-&gt;thread[i]-&gt;fdec;
            if( *frame )
            {
                assert( (*frame)-&gt;i_reference_count &gt; 0 );
                (*frame)-&gt;i_reference_count--;
                if( (*frame)-&gt;i_reference_count == 0 )
                    x264_frame_delete( *frame );
            }
            x264_macroblock_cache_free( h-&gt;thread[i] );
        }
        x264_macroblock_thread_free( h-&gt;thread[i], 0 );
        x264_free( h-&gt;thread[i]-&gt;out.p_bitstream );
        x264_free( h-&gt;thread[i]-&gt;out.nal );
        x264_pthread_mutex_destroy( &amp;h-&gt;thread[i]-&gt;mutex );
        x264_pthread_cond_destroy( &amp;h-&gt;thread[i]-&gt;cv );
        x264_free( h-&gt;thread[i] );
    }
#if HAVE_OPENCL
    x264_opencl_close_library( ocl );
#endif
}
</pre><br />从源代码可以看出，x264_encoder_close()主要用于输出编码的统计信息。源代码中已经做了比较充分的注释，就不再详细叙述了。其中输出日志的时候用到了libx264中输出日志的API函数libx264()，下面记录一下。<br /><br /><h3>x264_log()</h3>x264_log()用于输出日志。该函数的定义位于common\common.c，如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_53_6675526" name="code" class="cpp">/****************************************************************************
 * x264_log:
 ****************************************************************************/
//日志输出函数
void x264_log( x264_t *h, int i_level, const char *psz_fmt, ... )
{
    if( !h || i_level &lt;= h-&gt;param.i_log_level )
    {
        va_list arg;
        va_start( arg, psz_fmt );
        if( !h )
            x264_log_default( NULL, i_level, psz_fmt, arg );//默认日志输出函数
        else
            h-&gt;param.pf_log( h-&gt;param.p_log_private, i_level, psz_fmt, arg );
        va_end( arg );
    }
}
</pre><br />可以看出x264_log()再开始的时候做了一个判断：只有该条日志级别i_level小于当前系统的日志级别param.i_log_level的时候，才会输出日志。libx264中定义了下面几种日志级别，数值越小，代表日志越紧急。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_54_3582772" name="code" class="cpp">/* Log level */
#define X264_LOG_NONE          (-1)
#define X264_LOG_ERROR          0
#define X264_LOG_WARNING        1
#define X264_LOG_INFO           2
#define X264_LOG_DEBUG          3</pre>接下来x264_log()会根据输入的结构体x264_t是否为空来决定是调用x264_log_default()或者是x264_t中的param.pf_log()函数。假如都使用默认配置的话，param.pf_log()在x264_param_default()函数中也会被设置为指向x264_log_default()。因此可以继续看一下x264_log_default()函数。<br /><br /><h3>x264_log_default()</h3>x264_log_default()是libx264默认的日志输出函数。该函数的定义如下所示。<br /><pre code_snippet_id="664118" snippet_file_name="blog_20150511_55_108334" name="code" class="cpp">//默认日志输出函数
static void x264_log_default( void *p_unused, int i_level, const char *psz_fmt, va_list arg )
{
    char *psz_prefix;
    //日志级别
    switch( i_level )
    {
        case X264_LOG_ERROR:
            psz_prefix = &quot;error&quot;;
            break;
        case X264_LOG_WARNING:
            psz_prefix = &quot;warning&quot;;
            break;
        case X264_LOG_INFO:
            psz_prefix = &quot;info&quot;;
            break;
        case X264_LOG_DEBUG:
            psz_prefix = &quot;debug&quot;;
            break;
        default:
            psz_prefix = &quot;unknown&quot;;
            break;
    }
    //日志级别两边加上“[]”
    //输出到stderr
    fprintf( stderr, &quot;x264 [%s]: &quot;, psz_prefix );
    x264_vfprintf( stderr, psz_fmt, arg );
}
</pre><br />从源代码可以看出，x264_log_default()会在日志信息前面加上形如“x264 [日志级别]”的信息，然后将处理后的日志输出到stderr。<br /><br /><br />至此，对x264中x264_encoder_open()，x264_encoder_headers()，和x264_encoder_close()这三个函数的分析就完成了。下一篇文章继续记录x264编码器主干部分的x264_encoder_encode()函数。<br /><br /><br /><br /><strong><span style="color:#990000;">雷霄骅<br />leixiaohua1020@126.com<br />http://blog.csdn.net/leixiaohua1020</span></strong><br /><br />            </div>
                </div>
				<div style="display:none;" class="hide-article-box text-center csdn-tracking-statistics tracking-click" data-mod="popu_376">
			<a class="btn btn-red-hollow" id="btn-readmore">阅读更多</a>
		</div>
        	</article>
	
		<div class="article-bar-bottom">
				<div class="article-copyright">
			版权声明：本文为博主原创文章，未经博主允许不得转载。			https://blog.csdn.net/leixiaohua1020/article/details/45644367		</div>
						<div class="tags-box artic-tag-box">
			<span class="label">文章标签：</span>
						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=x264&t=blog" target="_blank">x264						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=libx264&t=blog" target="_blank">libx264						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=视频&t=blog" target="_blank">视频						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=源代码&t=blog" target="_blank">源代码						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=初始化&t=blog" target="_blank">初始化						</a>
		</div>
						<div class="tags-box">
			<span class="label">个人分类：</span>
						<a class="tag-link" href="https://blog.csdn.net/leixiaohua1020/article/category/2619503"  target="_blank">x264						</a>
		</div>
						<div class="tags-box">
			<span class="label">所属专栏：</span>
						<a class="tag-link" href="https://blog.csdn.net/column/details/osmedia.html" target="_blank">开源多媒体项目源代码分析</a>
						</a>
		</div>
			</div>
	
	<!-- !empty($pre_next_article[0]) -->
		</div>
<script>
    $(".MathJax").remove();
</script>

<script type="text/javascript" src="https://static-blog.csdn.net/mdeditor/public/res/bower-libs/MathJax/MathJax@js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
			"HTML-CSS": {
					linebreaks: { automatic: true, width: "94%container" },
					imageFont: null
			},
			tex2jax: {
				preview: "none"
			},
			mml2jax: {
				preview: 'none'
			}
	});
</script>
<script>
	(function(){
		var btnReadmore = $("#btn-readmore");
		if(btnReadmore.length>0){
			var winH = $(window).height();
			var articleBox = $("div.article_content");
			var artH = articleBox.height();
			if(artH > winH*2){
				articleBox.css({
					'height':winH*2+'px',
					'overflow':'hidden'
				})
				btnReadmore.click(function(){
					articleBox.removeAttr("style");
					$(this).parent().remove();
				})
			}else{
				btnReadmore.parent().remove();
			}
		}
	})()
</script>        <div class="edu-promotion"></div>
<script type="text/javascript">
	var edu_ad_is_big_data = 0;
	var edu_ad_id_mapping = {"0":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"1":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"8":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"2":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1"],"3":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"6":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"12":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"14":["https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcweb","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"15":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcjg","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1"],"16":["https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1"],"28":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcai","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"29":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1"],"30":["https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1"],"32":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcaq"],"33":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gccxrs","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1"],"35":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"37":["https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1"],"7":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"17":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1"],"34":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcbt"],"36":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"31":["https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"19":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"20":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"]};
</script>        <a id="commentBox"></a>
<div class="comment-box" style="display:none;">
	  	<div class="unlogin-box text-center">
		想对作者说点什么？
		<!-- $curl 当前地址 -->
		<a href="https://passport.csdn.net/account/login?from=https://blog.csdn.net/leixiaohua1020/article/details/45644367#commentBox" class="btn btn-sm btn-red">我来说一句</a>
	</div>
			<div class="comment-list-container">
		<a id="comments"></a>
		<div class="comment-list-box">
		</div>
		<div id="commentPage" class="pagination-box d-none"></div>
		<div class="opt-box text-center">
			<button class="btn btn-sm btn-link-blue" id="btnMoreComment"></button>
		</div>
	</div>
</div>        <div class="recommend-box" style="display:none;">
            		<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/zhubosa/article/details/51321783" target="_blank" strategy="BlogCommendFromBaidu_0">
				<em>x264</em> 参数详解【很强大、很细致，不再为不懂啥意思很烦恼】			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/zhubosa/article/details/51321783" target="_blank" >
				【 翻译 】<em>x264</em>参数介绍（一、帧类型和码率控制）

2010年10月2日
评论 发表评论


翻译自：http://mewiki.project357.com/wiki/<em>X264</em>_Se...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/zhubosa" title="zhubosa" target="_blank">
					<img src="https://avatar.csdn.net/0/5/D/3_zhubosa.jpg" alt="zhubosa" class="avatar-pic">
					<span class="name">zhubosa</span>
				</a>
			</p>
			<p>
				<span class="date">2016-05-05 12:11:12</span>
			</p>
			<p>
				<span class="read-num">阅读数：5380</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/leixiaohua1020/article/details/12720135" target="_blank" strategy="BlogCommendFromBaidu_1">
				<em>x264</em>编码指南——码率控制			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/leixiaohua1020/article/details/12720135" target="_blank" >
				<em>x264</em>是一个 H.264/MPEG4 AVC <em>编码器</em>，本指南将指导新手如何创建高质量的H.264视频。

    对于普通用户通常有两种码率控制模式：crf（Constant Rate Factor...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/leixiaohua1020" title="leixiaohua1020" target="_blank">
					<img src="https://avatar.csdn.net/A/7/6/3_leixiaohua1020.jpg" alt="leixiaohua1020" class="avatar-pic">
					<span class="name">leixiaohua1020</span>
				</a>
			</p>
			<p>
				<span class="date">2013-10-14 23:20:00</span>
			</p>
			<p>
				<span class="read-num">阅读数：22839</span>
			</p>
		</div>
	</div>
								<div class="recommend-item-box recommend-ad-box" id="ad1"></div>
				<script>
				  var width = $("div.recommend-box").outerWidth() - 48;
					NEWS_FEED({
						w: width,
						h : 90,
						showid : 'GNKXx7',
						placeholderId: "ad1",
						inject : 'define',
						define : {
							imagePosition : 'right',
							imageBorderRadius : 0,
							imageWidth: 120,
							imageHeight: 90,
							imageFill : 'clip',
							displayImage : true,
							displayTitle : true,
							titleFontSize: 20,
							titleFontColor: '#333',
							titleFontFamily : 'Microsoft Yahei',
							titleFontWeight: 'bold',
							titlePaddingTop : 0,
							titlePaddingRight : 0,
							titlePaddingBottom : 10,
							titlePaddingLeft : 0,
							displayDesc : true,
							descFontSize: 14,
							descFontColor: '#6b6b6b',
							descFontFamily : 'Microsoft Yahei',
							paddingTop : 0,
							paddingRight : 0,
							paddingBottom : 0,
							paddingLeft : 0,
							backgroundColor: '#fff',
							hoverColor: '#ca0c16'
						}
					})
				</script>

			
				<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/lutao614/article/details/22056837" target="_blank" strategy="BlogCommendFromBaidu_2">
				H264和<em>X264</em>究竟有什么区别?			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/lutao614/article/details/22056837" target="_blank" >
				转载自：http://blog.sina.com.cn/s/blog_7995e07901014tyd.html
先<em>简单</em>说一下，mkv和avi的格式只是封装容器，里面封装的是视频流+音频流。容器不会影...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/lutao614" title="lutao614" target="_blank">
					<img src="https://avatar.csdn.net/9/1/9/3_lutao614.jpg" alt="lutao614" class="avatar-pic">
					<span class="name">lutao614</span>
				</a>
			</p>
			<p>
				<span class="date">2014-03-25 13:48:19</span>
			</p>
			<p>
				<span class="read-num">阅读数：7657</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/chenchong_219/article/details/37996385" target="_blank" strategy="BlogCommendFromBaidu_3">
				<em>X264</em>编码			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/chenchong_219/article/details/37996385" target="_blank" >
				前面讲到了关于NAL打包成RTP后进行发送，那么这些NAL应该怎么得到呢？当然如果有现成的H264数据就可以直接用了，但是一般我们的摄像头采集的数据都不是H264格式的，那就需要编码。而且在我们这个项...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/chenchong_219" title="chenchong_219" target="_blank">
					<img src="https://avatar.csdn.net/0/E/3/3_chenchong_219.jpg" alt="chenchong_219" class="avatar-pic">
					<span class="name">chenchong_219</span>
				</a>
			</p>
			<p>
				<span class="date">2014-07-20 20:45:38</span>
			</p>
			<p>
				<span class="read-num">阅读数：9806</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/wupengqiangqinli/article/details/50813314" target="_blank" strategy="BlogCommendFromBaidu_4">
				vs2013编译 <em>x264</em>			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/wupengqiangqinli/article/details/50813314" target="_blank" >
				1.下载yasm，地址  http://yasm.tortall.net/Download.html ，下载Win64
 VS2010 .zip
2.解压Win64
 VS2010 .zip， 把vs...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/wupengqiangqinli" title="wupengqiangqinli" target="_blank">
					<img src="https://avatar.csdn.net/9/0/7/3_wupengqiangqinli.jpg" alt="wupengqiangqinli" class="avatar-pic">
					<span class="name">wupengqiangqinli</span>
				</a>
			</p>
			<p>
				<span class="date">2016-03-06 14:55:38</span>
			</p>
			<p>
				<span class="read-num">阅读数：1539</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/leixiaohua1020/article/details/45583217" target="_blank" strategy="BlogCommendFromBaidu_5">
				<em>x264</em><em>源代码</em><em>简单</em><em>分析</em>：<em>x264</em>命令行工具（<em>x264</em>.exe）			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/leixiaohua1020/article/details/45583217" target="_blank" >
				本文<em>简单</em><em>分析</em><em>x264</em>项目中的命令行工具（<em>x264</em>.exe）的<em>源代码</em>。该命令行工具可以调用lib<em>x264</em>将YUV格式像素数据编码为H.264码流。...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/leixiaohua1020" title="leixiaohua1020" target="_blank">
					<img src="https://avatar.csdn.net/A/7/6/3_leixiaohua1020.jpg" alt="leixiaohua1020" class="avatar-pic">
					<span class="name">leixiaohua1020</span>
				</a>
			</p>
			<p>
				<span class="date">2015-05-08 18:30:23</span>
			</p>
			<p>
				<span class="read-num">阅读数：11944</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box recommend-ad-box" id="a_d_feed_0"></div>
			<script>
				var width = $("div.recommend-box").outerWidth() - 48;
				NEWS_FEED({
					w: width,
					h: 90,
					showid: 'Afihld',
					placeholderId: 'a_d_feed_0',
					inject: 'define',
					define: {
						imagePosition: 'right',
						imageBorderRadius: 0,
						imageWidth: 120,
						imageHeight: 90,
						imageFill: 'clip',
						displayImage: true,
						displayTitle: true,
						titleFontSize: 20,
						titleFontColor: '#333',
						titleFontFamily: 'Microsoft Yahei',
						titleFontWeight: 'bold',
						titlePaddingTop: 0,
						titlePaddingRight: 0,
						titlePaddingBottom: 10,
						titlePaddingLeft: 0,
						displayDesc: true,
						descFontSize: 14,
						descFontColor: '#6b6b6b',
						descFontFamily: 'Microsoft Yahei',
						paddingTop: 0,
						paddingRight: 0,
						paddingBottom: 0,
						paddingLeft: 0,
						backgroundColor: '#fff',
						hoverColor: '#ca0c16'
					}
				})
			</script>
			<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/DeliaPu/article/details/80462864" target="_blank" strategy="BlogCommendFromBaidu_6">
				编译带<em>x264</em>的FFMPEG			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/DeliaPu/article/details/80462864" target="_blank" >
				业务需要，需要在Linux系统下编译带<em>x264</em>编码的ffmpeg工程，略踩小坑，过程记录如下。首先下载源码，ffmpeg： http://www.ffmpeg.org/download.htmlx26...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/DeliaPu" title="DeliaPu" target="_blank">
					<img src="https://avatar.csdn.net/6/C/F/3_deliapu.jpg" alt="DeliaPu" class="avatar-pic">
					<span class="name">DeliaPu</span>
				</a>
			</p>
			<p>
				<span class="date">2018-05-26 17:52:14</span>
			</p>
			<p>
				<span class="read-num">阅读数：53</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/wishfly/article/details/54584944" target="_blank" strategy="BlogCommendFromBaidu_7">
				<em>X264</em>编码流程详解			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/wishfly/article/details/54584944" target="_blank" >
				对H.264编码标准一直停留在理解原理的基础上，对于一个实际投入使用的<em>编码器</em>是如何构建起来一直感觉很神秘，于是决定在理解理论的基础上潜心于<em>编码器</em>实现框架。关于开源的H264<em>编码器</em>有很多，JMVC，T2...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/wishfly" title="wishfly" target="_blank">
					<img src="https://avatar.csdn.net/4/E/7/3_wishfly.jpg" alt="wishfly" class="avatar-pic">
					<span class="name">wishfly</span>
				</a>
			</p>
			<p>
				<span class="date">2017-01-17 17:10:49</span>
			</p>
			<p>
				<span class="read-num">阅读数：922</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/liuchen1206/article/details/79351137" target="_blank" strategy="BlogCommendFromBaidu_8">
				<em>X264</em>性能优化			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/liuchen1206/article/details/79351137" target="_blank" >
				一、<em>X264</em>性能<em>分析</em>测试环境测试环境：Intel Pentium4 3.00GHz  (双核cpu),开启超线程内存:    DDR 1.00G操作系统: Windows sever 2003 Ent...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/liuchen1206" title="liuchen1206" target="_blank">
					<img src="https://avatar.csdn.net/6/8/6/3_liuchen1206.jpg" alt="liuchen1206" class="avatar-pic">
					<span class="name">liuchen1206</span>
				</a>
			</p>
			<p>
				<span class="date">2018-02-23 10:04:36</span>
			</p>
			<p>
				<span class="read-num">阅读数：153</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/HEVC_CJL/article/details/8316653" target="_blank" strategy="BlogCommendFromBaidu_9">
				<em>x264</em>函数说明			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/HEVC_CJL/article/details/8316653" target="_blank" >
				原文地址：http://wmnmtm.blog.163.com/blog/static/38245714201163025957590/





函数名称
所在位置
完成功能

...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/HEVC_CJL" title="HEVC_CJL" target="_blank">
					<img src="https://avatar.csdn.net/1/D/5/3_hevc_cjl.jpg" alt="HEVC_CJL" class="avatar-pic">
					<span class="name">HEVC_CJL</span>
				</a>
			</p>
			<p>
				<span class="date">2012-12-18 22:45:08</span>
			</p>
			<p>
				<span class="read-num">阅读数：2600</span>
			</p>
		</div>
	</div>
			            <!-- 第四范式SDK -->
<script src="https://nbrecsys.4paradigm.com/resource/js/sdk-csdn-smallflow@js" async defer></script>
            <div class="recommend-loading-box">
                <img src='https://csdnimg.cn/release/phoenix/images/feedLoading.gif'>
            </div>
            <div class="recommend-end-box">
                <p class="text-center">没有更多推荐了，<a href="https://blog.csdn.net/" class="c-blue c-blue-hover c-blue-focus">返回首页</a></p>
            </div>
        </div>
    <div style="border-bottom: dashed 1px #666;"><span style="font-size: 0.8em; font-weight: bold;">此PDF由<a style="color:#0000ff" href="http://www.github.com/spygg">spygg</a>生成,请尊重原作者版权!!!<br/>我的邮箱:liushidc@163.com</span></div> </main>
    <aside style="display: none;">
		    <div id="asideProfile" class="aside-box">
    <h3 class="aside-title">个人资料</h3>
    <div class="profile-intro d-flex">
        <div class="avatar-box d-flex justify-content-center flex-column">
            <a href="https://blog.csdn.net/leixiaohua1020">
                <img src="https://avatar.csdn.net/A/7/6/3_leixiaohua1020.jpg" class="avatar_pic">
            </a>
        </div>
        <div class="user-info d-flex justify-content-center flex-column">
            <p class="name csdn-tracking-statistics tracking-click" data-mod="popu_379">
                <a href="https://blog.csdn.net/leixiaohua1020" target="_blank" class="text-truncate" id="uid">leixiaohua1020</a>
            </p>
                    </div>
                <div class="opt-box d-flex justify-content-center flex-column">
            <span  class="csdn-tracking-statistics tracking-click" data-mod="popu_379">
                                <a class="btn btn-sm btn-red-hollow" href="https://passport.csdn.net/account/login?from=https://blog.csdn.net/leixiaohua1020/article/details/45644367" target="_self">关注</a>
                            </span>
                    </div>
            </div>
    <div class="data-info d-flex item-tiling">
                <dl class="text-center" title="373">
                        <dt><a href="https://blog.csdn.net/leixiaohua1020?t=1">原创</a></dt>
            <dd><a href="https://blog.csdn.net/leixiaohua1020?t=1"><span class="count">373</span></a></dd>
                    </dl>
        <dl class="text-center" title="14088">
            <dt>粉丝</dt>
            <dd><span class="count" id="fan">1万+</span></dd>
        </dl>
        <dl class="text-center" title="460">
            <dt>喜欢</dt>
            <dd><span class="count">460</span></dd>
        </dl>
        <dl class="text-center" title="7317">
            <dt>评论</dt>
            <dd><span class="count">7317</span></dd>
        </dl>
    </div>
    <div class="grade-box clearfix">
        <dl>
            <dt>等级：</dt>
            <dd>
                <a href="https://blog.csdn.net/home/help.html#level" title="9级,点击查看等级说明" target="_blank">
                    <svg class="icon icon-level" aria-hidden="true">
                        <use xlink:href="#csdnc-bloglevel-9"></use>
                    </svg>
                </a>
            </dd>
        </dl>
        <dl>
            <dt>访问：</dt>
            <dd title="10421172">
                1042万+            </dd>
        </dl>
        <dl>
            <dt>积分：</dt>
            <dd title="62878">
                6万+            </dd>
        </dl>
        <dl title="49">
            <dt>排名：</dt>
            <dd>49</dd>
        </dl>
    </div>
        <div class="badge-box d-flex">
        <span>勋章：</span>
                <a class="icon-badge" title="专栏达人">
            <svg class="icon" aria-hidden="true">
                <use xlink:href="#csdnc-m-columns"></use>
            </svg>
            <div class="icon-arrow"></div>
            <div class="grade-detail-box item1">
                <div class="pos-box">
                    <div class="left-box d-flex justify-content-center align-items-center flex-column">
                        <svg class="icon" aria-hidden="true">
                            <use xlink:href="#csdnc-m-columns"></use>
                        </svg>
                        <p>专栏达人</p>
                    </div>
                    <div class="right-box d-flex justify-content-center align-items-center">
                        授予成功创建个人博客专栏的用户。专栏中添加五篇以上博文即可点亮！撰写博客专栏浓缩技术精华，专栏达人就是你！
                    </div>
                </div>
            </div> 
        </a>  
                        <a class="icon-badge" title="持之以恒">
            <svg class="icon" aria-hidden="true">
                <use xlink:href="#csdnc-m-lasting"></use>
            </svg>
            <div class="icon-arrow"></div>
            <div class="grade-detail-box item2">
                <div class="pos-box">
                    <div class="left-box d-flex justify-content-center align-items-center flex-column">
                        <svg class="icon" aria-hidden="true">
                            <use xlink:href="#csdnc-m-lasting"></use>
                        </svg>
                        <p>持之以恒</p>
                    </div>
                    <div class="right-box d-flex justify-content-center align-items-center">
                        授予每个自然月内发布4篇或4篇以上原创或翻译IT博文的用户。不积跬步无以至千里，不积小流无以成江海，程序人生的精彩需要坚持不懈地积累！
                    </div>
                </div>
            </div>
        </a>
                                <a class="icon-badge" title="博客之星">
            <svg class="icon" aria-hidden="true">
                <use xlink:href="#csdnc-m-blogstar-l"></use>
            </svg>
            <div class="icon-arrow"></div>
            <div class="grade-detail-box item4">
                <div class="pos-box">
                    <div class="left-box d-flex justify-content-center align-items-center flex-column">
                        <svg class="icon" aria-hidden="true">
                            <use xlink:href="#csdnc-m-blogstar-l"></use>
                        </svg>
                        <p>博客之星</p>
                    </div>
                    <div class="right-box d-flex justify-content-center align-items-center">
                        授予通过"CSDN博客之星评选"中脱颖而出的十大博客之星称号的用户。
                    </div>
                </div>
            </div>
        </a>   
            </div>
    </div>		    <div class="csdn-tracking-statistics mb8 box-shadow" data-pid="blog" data-mod="popu_4" style="height:250px;">
    <div class="aside-content text-center" id="cpro_u2734133">
        <!-- 投放代码 -->
        <script type="text/javascript" src="//cee1.iteye.com/lgyyovfyh@js"></script>
    </div>
</div>
		    <!--自定义模块-->
<div id="asideCustom26787557" class="aside-box custom-box">
    <h3 class="aside-title">关于我</h3>
    <div class="aside-content clearfix">
        姓名：雷霄骅<br>
网名：leixiaohua1020<br>
本科：<br>
中国传媒大学-广播电视工程<br>
硕士：<br>
中国传媒大学-数字电视技术<br>
博士：<br>
中国传媒大学-数字视频技术<br>
Email：<br>
leixiaohua1020@126.com<br>
QQ：<br>
494085803<br>
<br>
[注1：QQ消息较多，难以一一回复，见谅]<br>
[注2：CSDN私信功能使用很少，有问题可以直接在博客评论处留言]<br>
<br>
奖项：<br>
<a href="http://vote.blog.csdn.net/Blogstar2014/List">2014年度 - CSDN博客之星</a><br>
<a href="https://mvp.microsoft.com/en-us/mvp/Xiaohua%20Lei-5001392">2015年度 - 微软MVP</a><br>
<a href="http://bss.csdn.net/m/topic/community_star/index">2015年度 - CSDN博客之星</a><br>
简介：<br>
主要从事与广播电视有关的视音频技术的研究。包括视音频质量评价，视音频编解码，流媒体，媒资检索等。
<br>    </div>
</div>
		    <div id="asideNewArticle" class="aside-box">
    <h3 class="aside-title">最新文章</h3>
    <div class="aside-content">
        <ul class="inf_list clearfix csdn-tracking-statistics tracking-click" data-mod="popu_382">
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/51187668" target="_blank">[投稿] Speex回声消除原理深度解析</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50789619" target="_blank">[投稿]房间声学原理与Schroeder混响算法实现</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50789503" target="_blank">[投稿]一个频域语音降噪算法实现及改进方法</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50618190" target="_blank">最简单的基于FFmpeg的AVfilter的例子-纯净版</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50535230" target="_blank">视音频数据处理入门：UDP-RTP协议解析</a>
            </li>
                    </ul>
    </div>
</div>
		    <div id="asideColumn" class="aside-box">
    <h3 class="aside-title">博主专栏</h3>
    <div class="aside-content">
        <ul class="column-box csdn-tracking-statistics tracking-click" data-mod="popu_520" >
                            <li class="clearfix">
                    <div class="img-box float-left">
                        <a class="d-flex align-items-center" href="https://blog.csdn.net/column/details/videoquality.html">
                            <img src="https://img-blog.csdn.net/20151123175555036?imageView2/5/w/120/h/120" alt="">
                        </a>
                    </div>
                    <div class="info">
                        <p class="title"><a href="https://blog.csdn.net/column/details/videoquality.html">视频质量评价</a></p>
                        <div class="data">阅读量：<span>434203</span><span class="count">41 篇</span></div>
                    </div>
                </li>
                            <li class="clearfix">
                    <div class="img-box float-left">
                        <a class="d-flex align-items-center" href="https://blog.csdn.net/column/details/osmedia.html">
                            <img src="https://img-blog.csdn.net/20151123175559974?imageView2/5/w/120/h/120" alt="">
                        </a>
                    </div>
                    <div class="info">
                        <p class="title"><a href="https://blog.csdn.net/column/details/osmedia.html">开源多媒体项目源代码分析</a></p>
                        <div class="data">阅读量：<span>1158961</span><span class="count">91 篇</span></div>
                    </div>
                </li>
                            <li class="clearfix">
                    <div class="img-box float-left">
                        <a class="d-flex align-items-center" href="https://blog.csdn.net/column/details/ffmpeg-devel.html">
                            <img src="https://img-blog.csdn.net/20151123175857395?imageView2/5/w/120/h/120" alt="">
                        </a>
                    </div>
                    <div class="info">
                        <p class="title"><a href="https://blog.csdn.net/column/details/ffmpeg-devel.html">FFmpeg</a></p>
                        <div class="data">阅读量：<span>4852475</span><span class="count">135 篇</span></div>
                    </div>
                </li>
                    </ul>
    </div>
    </div>
		    <div id="asideArchive" class="aside-box flexible-box">
    <h3 class="aside-title">归档</h3>
    <div class="aside-content">
        <ul class="archive-list">
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/04">
                    2016年4月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/03">
                    2016年3月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/02">
                    2016年2月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/01">
                    2016年1月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/12">
                    2015年12月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/11">
                    2015年11月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/08">
                    2015年8月                    <span class="count float-right">4篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/07">
                    2015年7月                    <span class="count float-right">17篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/06">
                    2015年6月                    <span class="count float-right">6篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/05">
                    2015年5月                    <span class="count float-right">12篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/04">
                    2015年4月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/03">
                    2015年3月                    <span class="count float-right">25篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/02">
                    2015年2月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/01">
                    2015年1月                    <span class="count float-right">11篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/12">
                    2014年12月                    <span class="count float-right">10篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/11">
                    2014年11月                    <span class="count float-right">9篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/10">
                    2014年10月                    <span class="count float-right">20篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/09">
                    2014年9月                    <span class="count float-right">5篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/08">
                    2014年8月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/07">
                    2014年7月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/06">
                    2014年6月                    <span class="count float-right">8篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/05">
                    2014年5月                    <span class="count float-right">10篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/04">
                    2014年4月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/02">
                    2014年2月                    <span class="count float-right">5篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/01">
                    2014年1月                    <span class="count float-right">14篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/12">
                    2013年12月                    <span class="count float-right">21篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/11">
                    2013年11月                    <span class="count float-right">71篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/10">
                    2013年10月                    <span class="count float-right">161篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/09">
                    2013年9月                    <span class="count float-right">101篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/08">
                    2013年8月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/06">
                    2013年6月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/03">
                    2013年3月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                    </ul>
    </div>
        <p class="text-center">
        <a class="btn btn-link-blue flexible-btn" data-fbox="aside-archive">展开</a>
    </p>
    </div>
		    <div id="asideNewComments" class="aside-box">
    <h3 class="aside-title">最新评论</h3>
    <div class="aside-content">
        <ul class="newcomment-list">
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/15811977#comments">[总结]FFMPEG视音频编解码零...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/tanhuifang520" class="user-name" target="_blank">tanhuifang520</a>：含着敬畏的心情又看了遍这个文章                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/42105049#comments">最简单的基于librtmp的示例：...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/qq_32245927" class="user-name" target="_blank">qq_32245927</a>：[reply]hjl19901012[/reply]
你们的是哪里有问题呢                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/46754977#comments">视频编码器评测系统：VideoCo...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/tqs_1220" class="user-name" target="_blank">tqs_1220</a>：天妒英才                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/38284961#comments">FFmpeg获取DirectSho...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/a137748099" class="user-name" target="_blank">a137748099</a>：[reply]liangqingzhi[/reply]
大佬，有的电脑使用regsvr32注册不成...                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/15811977#comments">[总结]FFMPEG视音频编解码零...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/qq_17276615" class="user-name" target="_blank">qq_17276615</a>：每次视频编解码都会搜到你的文章，感谢您给我们这些菜鸡一些指引。谢谢！                </p>
            </li>
                    </ul>
    </div>
</div>
		<div id="asideFooter">
			
		<div class="aside-box">
						<script type="text/javascript" src="//cee1.iteye.com/avneunkwb@js"></script>
					</div>
				<div class="aside-box">
			<div class="persion_article">
			</div>
		</div>
	</div>
</aside>
<script src="https://csdnimg.cn/pubfooter/js/publib_footer-1.0.3@js" data-isfootertrack="false" type="text/javascript"></script>
<script>
	$("a.flexible-btn").click(function(){
		$(this).parents('div.aside-box').removeClass('flexible-box');
		$(this).remove();
	})
</script>
</div>
<div class="mask-dark"></div>
<div class="pulllog-box" style="display: none;">
	<div class="pulllog clearfix">
		<span class="text float-left">加入CSDN，享受更精准的内容推荐，与500万程序员共同成长！</span>
		<div class="pulllog-btn float-right clearfix">
            <button class="pulllog-login float-left csdn-tracking-statistics tracking-click" data-mod="popu_557">
                登录
            </button>
            <div class="pulllog-sigin float-left csdn-tracking-statistics tracking-click" data-mod="popu_558">
                <a href="https://passport.csdn.net/account/mobileregister" target="_blank">注册</a>
            </div>
            <button class="btn-close">
                <svg class="icon" aria-hidden="true">
                    <use xlink:href="#csdnc-times"></use>
                </svg>
            </button>
		</div>
	</div>
</div>
<div id="loginWrap" style="display:none"></div>
<div class="tool-box">
	<ul class="meau-list">
		<li>
			<button class="btn-like " title="点赞">
				<svg class="icon active" aria-hidden="true">
					<use xlink:href="#csdnc-thumbsup-ok"></use>
				</svg><svg class="icon no-active" aria-hidden="true">
					<use xlink:href="#csdnc-thumbsup"></use>
				</svg>
				<p>8</p>
			</button>
		</li>
		<li class="toc-container-box" id="liTocBox">
			<button class="btn-toc" title="目录">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-contents"></use>
				</svg><br>目录
			</button>
			<div class="toc-container">
				<div class="pos-box">
					<div class="icon-arrow"></div>
					<div class="scroll-box">
						<div class="toc-box"></div>
					</div>
				</div>
				<div class="opt-box">
					<button class="btn-opt prev nomore" title="向上">
						<svg class="icon" aria-hidden="true">
							<use xlink:href="#csdnc-chevronup"></use>
						</svg>
					</button>
					<button class="btn-opt next">
						<svg class="icon" aria-hidden="true">
							<use xlink:href="#csdnc-chevrondown"></use>
						</svg>
					</button>
				</div>
			</div>
		</li>
		<li>
			<button class="btn-bookmark" title="收藏">
				<svg class="icon active" aria-hidden="true">
					<use xlink:href="#csdnc-bookmark-ok"></use>
				</svg><svg class="icon no-active" aria-hidden="true">
					<use xlink:href="#csdnc-bookmark"></use>
				</svg><br>收藏
			</button>
		</li>
		<li>
			<a class="btn-comments" title="评论" href="#commentBox">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-comments"></use>
				</svg><br>评论
			</a>
		</li>
				<li class="bdsharebuttonbox">
			<a class="btn-comments bds_weixin" data-cmd="weixin" title="微信分享">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-wechat"></use>
				</svg><br>微信
			</a>
		</li>
		<li class="bdsharebuttonbox">
			<a class="btn-comments bds_tsina" data-cmd="tsina" title="微博分享">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-weibo"></use>
				</svg><br>微博
			</a>
		</li>
		<li class="bdsharebuttonbox">
			<a class="btn-comments bds_qzone" data-cmd="qzone" title="QQ分享">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-qq"></use>
				</svg><br>QQ
			</a>
		</li>
	</ul>
</div>
<script>window._bd_share_config = { "common": { "bdSnsKey": {}, "bdText": "", "bdMini": "1", "bdMiniList": false, "bdPic": "", "bdStyle": "0", "bdSize": "16" }, "share": {} }; with (document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'https://csdnimg.cn/static/api/js/share@js?v=89860594'];</script>
<script>
    var recommendCount = 10;
    recommendCount = recommendCount > 1 ? (recommendCount + (recommendCount>6 ? 2 : 1)) : recommendCount;
    var articleTit = "x264源代码简单分析：编码器主干部分-1";
    var ChannelId = 16;
    var articleId = "45644367";
    var commentscount = 13;
    var islock = false;
    var curentUrl = "https://blog.csdn.net/leixiaohua1020/article/details/45644367";
    var myUrl = "https://my.csdn.net/";
    //1禁止评论，2正常
    var commentAuth = 2;
    //百度搜索
    var baiduKey = "i_num_reorder_frames";
    var needInsertBaidu = false;
</script>
<script src="https://csdnimg.cn/public/sandalstrap/1.3/js/sandalstrap.min@js"></script>
<script src="https://csdnimg.cn/release/phoenix/vendor/pagination/paging@js"></script>

<script>
    GoTop({
        right: 8,
        hasReport: true,
        reportFun: function() {
            showReport(false,"x264源代码简单分析：编码器主干部分-1");
        }
    })
</script>
<script src="https://csdnimg.cn/release/phoenix/template/js/common-bd54b21308.min@js"></script>
<script src="https://csdnimg.cn/release/phoenix/template/js/detail-effe72036e.min@js"></script>
<script src="https://csdnimg.cn/release/phoenix/themes/skin3-template/skin3-template-46c7bd3d86.min@js"></script>
<script src="https://csdnimg.cn/search/baidu_search-1.1.2@js?v=201802071056&autorun=true&install=true&keyword=i_num_reorder_frames"  type="text/javascript"></script>
</body>
<div class="box-box-default" style="display:none;">
    <a class="btn-remove">
        关闭
    </a>
    <script type="text/javascript" src="//cee1.iteye.com/mhzzjepzz@js"></script>
</div>
<div class="box-box-large" style="display:none;">
    <a class="btn-remove">
        关闭
    </a>
    <script type="text/javascript" src="//cee1.iteye.com/idvveasfs@js"></script>
</div>
</html>