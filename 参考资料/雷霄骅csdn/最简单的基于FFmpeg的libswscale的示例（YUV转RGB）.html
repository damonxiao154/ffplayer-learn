<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <link rel="canonical" href="https://blog.csdn.net/leixiaohua1020/article/details/42134965"/> 
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="referrer" content="always">
    <meta name="description" content="本文记录一个基于FFmpeg的libswscale的示例。Libswscale里面实现了各种图像像素格式的转换，例如YUV与RGB之间的转换；以及图像大小缩放（例如640x360拉伸为1280x720）功能。而且libswscale还做了相应指令集的优化，因此它的转换效率比自己写的C语言的转换效率高很多。" />
    <meta name="keywords" content="libswscale,拉伸" />
    <meta http-equiv="Cache-Control" content="no-siteapp" /><link rel="alternate" media="handheld" href="#" />
    <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848">
    <script src="https://csdnimg.cn/release/phoenix/vendor/tingyun/tingyun-rum-blog@js"></script>

    <link href="https://csdnimg.cn/public/favicon.ico" rel="SHORTCUT ICON">
    <title>最简单的基于FFmpeg的libswscale的示例（YUV转RGB） - CSDN博客</title>
    
            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/detail-60a2c245da.min.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/themes/skin3-template/skin3-template-88717cedf2.min.css">

    <script type="text/javascript">
        var username = "leixiaohua1020";
        var blog_address = "https://blog.csdn.net/leixiaohua1020";
        var static_host = "https://csdnimg.cn/release/phoenix/";
        var currentUserName = ""; 
        var isShowAds = true;
        var isOwner = false;
        var loginUrl = "https://passport.csdn.net/account/login?from=https://blog.csdn.net/leixiaohua1020/article/details/42134965"
        var blogUrl = "https://blog.csdn.net/";
        var curSkin = "skin3-template";
    </script>
    <script type="text/javascript">
        // Traffic Stats of the entire Web site By baidu
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm@js?6bcd52f51e9b3dce32bec4a3997715ac";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
        // Traffic Stats of the entire Web site By baidu end
    </script>
    <script src="https://csdnimg.cn/public/common/libs/jquery/jquery-1.9.1.min@js" type="text/javascript"></script>
    <script src="https://csdnimg.cn/rabbit/exposure-click/main-1.0.6@js"></script>
    <!-- 新版上报 -->
    <script src="//g.csdnimg.cn/track/1.0.0/track@js" type="text/javascript"></script>
    <!-- 新版上报end -->
            <link rel="stylesheet" href="https://csdnimg.cn/public/sandalstrap/1.3/css/sandalstrap.min.css"> 
    <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>
</head>
<body>    
    <link rel="stylesheet" href="https://csdnimg.cn/public/common/toolbar/content_toolbar_css/content_toolbar.css">
    
    <script src="https://csdnimg.cn/public/sandalstrap/1.3/fonts/csdnc/csdnc@js"></script><link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/blog_code-c3a0c33d5c.css">
<link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/vendor/pagination/paging.css">
<script type="text/javascript" src="//static.mediav.com/js/mvf_news_feed@js"></script>

<header style="display: none;">
	<div class="container d-flex clearfix">
		<div class="title-box">
			<h2 class="title-blog">
				<a href="https://blog.csdn.net/leixiaohua1020">雷霄骅(leixiaohua1020)的专栏</a>
			</h2>
			<p class="description">一个广院工科生的视音频技术笔记</p>
		</div>
		<div class="opt-box d-flex justify-content-end">
			<a class="btn btn-sm" href="https://blog.csdn.net/leixiaohua1020/rss/list">
					<svg class="icon" aria-hidden="true">
						<use xlink:href="#csdnc-rss"></use>
					</svg>RSS订阅</a>
					</div>
	</div>
</header><script src="https://dup.baidustatic.com/js/ds@js"></script>
<div class="container clearfix pt0" id="mainBox">
    <main style="width: 100%;">
        <div class="blog-content-box">
	<div class="article-title-box">
			<span class="article-type type-1 float-left">原</span>		<h1 class="title-article">最简单的基于FFmpeg的libswscale的示例（YUV转RGB）</h1>
	</div>
	<div class="article-info-box">
		<div class="article-bar-top d-flex">
												<span class="time">2014年12月28日 00:46:53</span>
			<div class="float-right">
				<span class="read-count" style="display:none;">阅读数：38124</span>
											</div>
		</div>
	</div>
	<article>
		<div id="article_content" class="article_content_dummy clearfix csdn-tracking-statistics" data-pid="blog"  data-mod=popu_307  data-dsm = "post" >
                    <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/htmledit_views-0a60691e80.css" />
            <div class="htmledit_views">
                <p>=====================================================<br /></p><p>最简单的基于FFmpeg的libswscale的示例系列文章列表：</p><p><a href="http://blog.csdn.net/leixiaohua1020/article/details/42134965">最简单的基于FFmpeg的libswscale的示例（YUV转RGB）</a><br /></p><p><a href="http://blog.csdn.net/leixiaohua1020/article/details/42135539">最简单的基于FFmpeg的libswscale的示例附件：测试图片生成工具</a><br /></p><p>=====================================================</p><p>本文记录一个基于FFmpeg的libswscale的示例。Libswscale里面实现了各种图像像素格式的转换，例如YUV与RGB之间的转换；以及图像大小缩放（例如640x360拉伸为1280x720）功能。而且libswscale还做了相应指令集的优化，因此它的转换效率比自己写的C语言的转换效率高很多。</p><p>本文记录的程序将像素格式为YUV420P，分辨率为480x272的视频转换为像素格式为RGB24，分辨率为1280x720的视频。</p><p><br /></p><h2>流程</h2><h3>简单的初始化方法</h3>Libswscale使用起来很方便，最主要的函数只有3个：<br />（1）       sws_getContext()：使用参数初始化SwsContext结构体。<br />（2）       sws_scale()：转换一帧图像。<br />（3）       sws_freeContext()：释放SwsContext结构体。<br />其中sws_getContext()也可以用另一个接口函数sws_getCachedContext()取代。<br /> <br /><h3>复杂但是更灵活的初始化方法</h3>初始化SwsContext除了调用sws_getContext()之外还有另一种方法，更加灵活，可以配置更多的参数。该方法调用的函数如下所示。<br />（1）       sws_alloc_context()：为SwsContext结构体分配内存。<br />（2）       av_opt_set_XXX()：通过av_opt_set_int()，av_opt_set()…等等一系列方法设置SwsContext结构体的值。在这里需要注意，SwsContext结构体的定义看不到，所以不能对其中的成员变量直接进行赋值，必须通过av_opt_set()这类的API才能对其进行赋值。<br />（3）       sws_init_context()：初始化SwsContext结构体。<br />这种复杂的方法可以配置一些sws_getContext()配置不了的参数。比如说设置图像的YUV像素的取值范围是JPEG标准（Y、U、V取值范围都是0-255）还是MPEG标准（Y取值范围是16-235，U、V的取值范围是16-240）。<br /> <br /><h2>几个知识点</h2><p>下文记录几个图像像素数据处理过程中的几个知识点：像素格式，图像拉伸，YUV像素取值范围，色域。</p><h3>像素格式</h3>像素格式的知识此前已经记录过，不再重复。在这里记录一下FFmpeg支持的像素格式。有几点注意事项：<br />（1）       所有的像素格式的名称都是以“AV_PIX_FMT_”开头<br /><p>（2）       像素格式名称后面有“P”的，代表是planar格式，否则就是packed格式。Planar格式不同的分量分别存储在不同的数组中，例如AV_PIX_FMT_YUV420P存储方式如下：</p>data[0]: Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8……<br />data[1]: U1, U2, U3, U4……<br /><p>data[2]: V1, V2, V3, V4……</p><p>Packed格式的数据都存储在同一个数组中，例如AV_PIX_FMT_RGB24存储方式如下：</p>data[0]: R1, G1, B1, R2, G2, B2, R3, G3, B3, R4, G4, B4……<br /> <br />（3）       像素格式名称后面有“BE”的，代表是Big Endian格式；名称后面有“LE”的，代表是Little Endian格式。<br /> <br />FFmpeg支持的像素格式的定义位于libavutil\pixfmt.h，是一个名称为AVPixelFormat的枚举类型，如下所示。<br /><pre class="cpp">/**
 * Pixel format.
 *
 * @note
 * AV_PIX_FMT_RGB32 is handled in an endian-specific manner. An RGBA
 * color is put together as:
 *  (A &lt;&lt; 24) | (R &lt;&lt; 16) | (G &lt;&lt; 8) | B
 * This is stored as BGRA on little-endian CPU architectures and ARGB on
 * big-endian CPUs.
 *
 * @par
 * When the pixel format is palettized RGB (AV_PIX_FMT_PAL8), the palettized
 * image data is stored in AVFrame.data[0]. The palette is transported in
 * AVFrame.data[1], is 1024 bytes long (256 4-byte entries) and is
 * formatted the same as in AV_PIX_FMT_RGB32 described above (i.e., it is
 * also endian-specific). Note also that the individual RGB palette
 * components stored in AVFrame.data[1] should be in the range 0..255.
 * This is important as many custom PAL8 video codecs that were designed
 * to run on the IBM VGA graphics adapter use 6-bit palette components.
 *
 * @par
 * For all the 8bit per pixel formats, an RGB32 palette is in data[1] like
 * for pal8. This palette is filled in automatically by the function
 * allocating the picture.
 *
 * @note
 * Make sure that all newly added big-endian formats have (pix_fmt &amp; 1) == 1
 * and that all newly added little-endian formats have (pix_fmt &amp; 1) == 0.
 * This allows simpler detection of big vs little-endian.
 */
enum AVPixelFormat {
    AV_PIX_FMT_NONE = -1,
    AV_PIX_FMT_YUV420P,   ///&lt; planar YUV 4:2:0, 12bpp, (1 Cr &amp; Cb sample per 2x2 Y samples)
    AV_PIX_FMT_YUYV422,   ///&lt; packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr
    AV_PIX_FMT_RGB24,     ///&lt; packed RGB 8:8:8, 24bpp, RGBRGB...
    AV_PIX_FMT_BGR24,     ///&lt; packed RGB 8:8:8, 24bpp, BGRBGR...
    AV_PIX_FMT_YUV422P,   ///&lt; planar YUV 4:2:2, 16bpp, (1 Cr &amp; Cb sample per 2x1 Y samples)
    AV_PIX_FMT_YUV444P,   ///&lt; planar YUV 4:4:4, 24bpp, (1 Cr &amp; Cb sample per 1x1 Y samples)
    AV_PIX_FMT_YUV410P,   ///&lt; planar YUV 4:1:0,  9bpp, (1 Cr &amp; Cb sample per 4x4 Y samples)
    AV_PIX_FMT_YUV411P,   ///&lt; planar YUV 4:1:1, 12bpp, (1 Cr &amp; Cb sample per 4x1 Y samples)
    AV_PIX_FMT_GRAY8,     ///&lt;        Y        ,  8bpp
    AV_PIX_FMT_MONOWHITE, ///&lt;        Y        ,  1bpp, 0 is white, 1 is black, in each byte pixels are ordered from the msb to the lsb
    AV_PIX_FMT_MONOBLACK, ///&lt;        Y        ,  1bpp, 0 is black, 1 is white, in each byte pixels are ordered from the msb to the lsb
    AV_PIX_FMT_PAL8,      ///&lt; 8 bit with PIX_FMT_RGB32 palette
    AV_PIX_FMT_YUVJ420P,  ///&lt; planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV420P and setting color_range
    AV_PIX_FMT_YUVJ422P,  ///&lt; planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV422P and setting color_range
    AV_PIX_FMT_YUVJ444P,  ///&lt; planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated in favor of PIX_FMT_YUV444P and setting color_range
#if FF_API_XVMC
    AV_PIX_FMT_XVMC_MPEG2_MC,///&lt; XVideo Motion Acceleration via common packet passing
    AV_PIX_FMT_XVMC_MPEG2_IDCT,
#define AV_PIX_FMT_XVMC AV_PIX_FMT_XVMC_MPEG2_IDCT
#endif /* FF_API_XVMC */
    AV_PIX_FMT_UYVY422,   ///&lt; packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1
    AV_PIX_FMT_UYYVYY411, ///&lt; packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3
    AV_PIX_FMT_BGR8,      ///&lt; packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb)
    AV_PIX_FMT_BGR4,      ///&lt; packed RGB 1:2:1 bitstream,  4bpp, (msb)1B 2G 1R(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits
    AV_PIX_FMT_BGR4_BYTE, ///&lt; packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb)
    AV_PIX_FMT_RGB8,      ///&lt; packed RGB 3:3:2,  8bpp, (msb)2R 3G 3B(lsb)
    AV_PIX_FMT_RGB4,      ///&lt; packed RGB 1:2:1 bitstream,  4bpp, (msb)1R 2G 1B(lsb), a byte contains two pixels, the first pixel in the byte is the one composed by the 4 msb bits
    AV_PIX_FMT_RGB4_BYTE, ///&lt; packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)
    AV_PIX_FMT_NV12,      ///&lt; planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)
    AV_PIX_FMT_NV21,      ///&lt; as above, but U and V bytes are swapped
 
    AV_PIX_FMT_ARGB,      ///&lt; packed ARGB 8:8:8:8, 32bpp, ARGBARGB...
    AV_PIX_FMT_RGBA,      ///&lt; packed RGBA 8:8:8:8, 32bpp, RGBARGBA...
    AV_PIX_FMT_ABGR,      ///&lt; packed ABGR 8:8:8:8, 32bpp, ABGRABGR...
    AV_PIX_FMT_BGRA,      ///&lt; packed BGRA 8:8:8:8, 32bpp, BGRABGRA...
 
    AV_PIX_FMT_GRAY16BE,  ///&lt;        Y        , 16bpp, big-endian
    AV_PIX_FMT_GRAY16LE,  ///&lt;        Y        , 16bpp, little-endian
    AV_PIX_FMT_YUV440P,   ///&lt; planar YUV 4:4:0 (1 Cr &amp; Cb sample per 1x2 Y samples)
    AV_PIX_FMT_YUVJ440P,  ///&lt; planar YUV 4:4:0 full scale (JPEG), deprecated in favor of PIX_FMT_YUV440P and setting color_range
    AV_PIX_FMT_YUVA420P,  ///&lt; planar YUV 4:2:0, 20bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples)
#if FF_API_VDPAU
    AV_PIX_FMT_VDPAU_H264,///&lt; H.264 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
    AV_PIX_FMT_VDPAU_MPEG1,///&lt; MPEG-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
    AV_PIX_FMT_VDPAU_MPEG2,///&lt; MPEG-2 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
    AV_PIX_FMT_VDPAU_WMV3,///&lt; WMV3 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
    AV_PIX_FMT_VDPAU_VC1, ///&lt; VC-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
#endif
    AV_PIX_FMT_RGB48BE,   ///&lt; packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as big-endian
    AV_PIX_FMT_RGB48LE,   ///&lt; packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte value for each R/G/B component is stored as little-endian
 
    AV_PIX_FMT_RGB565BE,  ///&lt; packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), big-endian
    AV_PIX_FMT_RGB565LE,  ///&lt; packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), little-endian
    AV_PIX_FMT_RGB555BE,  ///&lt; packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), big-endian, most significant bit to 0
    AV_PIX_FMT_RGB555LE,  ///&lt; packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), little-endian, most significant bit to 0
 
    AV_PIX_FMT_BGR565BE,  ///&lt; packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), big-endian
    AV_PIX_FMT_BGR565LE,  ///&lt; packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), little-endian
    AV_PIX_FMT_BGR555BE,  ///&lt; packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), big-endian, most significant bit to 1
    AV_PIX_FMT_BGR555LE,  ///&lt; packed BGR 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), little-endian, most significant bit to 1
 
    AV_PIX_FMT_VAAPI_MOCO, ///&lt; HW acceleration through VA API at motion compensation entry-point, Picture.data[3] contains a vaapi_render_state struct which contains macroblocks as well as various fields extracted from headers
    AV_PIX_FMT_VAAPI_IDCT, ///&lt; HW acceleration through VA API at IDCT entry-point, Picture.data[3] contains a vaapi_render_state struct which contains fields extracted from headers
    AV_PIX_FMT_VAAPI_VLD,  ///&lt; HW decoding through VA API, Picture.data[3] contains a vaapi_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
 
    AV_PIX_FMT_YUV420P16LE,  ///&lt; planar YUV 4:2:0, 24bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
    AV_PIX_FMT_YUV420P16BE,  ///&lt; planar YUV 4:2:0, 24bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
    AV_PIX_FMT_YUV422P16LE,  ///&lt; planar YUV 4:2:2, 32bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
    AV_PIX_FMT_YUV422P16BE,  ///&lt; planar YUV 4:2:2, 32bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
    AV_PIX_FMT_YUV444P16LE,  ///&lt; planar YUV 4:4:4, 48bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
    AV_PIX_FMT_YUV444P16BE,  ///&lt; planar YUV 4:4:4, 48bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
#if FF_API_VDPAU
    AV_PIX_FMT_VDPAU_MPEG4,  ///&lt; MPEG4 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
#endif
    AV_PIX_FMT_DXVA2_VLD,    ///&lt; HW decoding through DXVA2, Picture.data[3] contains a LPDIRECT3DSURFACE9 pointer
 
    AV_PIX_FMT_RGB444LE,  ///&lt; packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), little-endian, most significant bits to 0
    AV_PIX_FMT_RGB444BE,  ///&lt; packed RGB 4:4:4, 16bpp, (msb)4A 4R 4G 4B(lsb), big-endian, most significant bits to 0
    AV_PIX_FMT_BGR444LE,  ///&lt; packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), little-endian, most significant bits to 1
    AV_PIX_FMT_BGR444BE,  ///&lt; packed BGR 4:4:4, 16bpp, (msb)4A 4B 4G 4R(lsb), big-endian, most significant bits to 1
    AV_PIX_FMT_GRAY8A,    ///&lt; 8bit gray, 8bit alpha
    AV_PIX_FMT_BGR48BE,   ///&lt; packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as big-endian
    AV_PIX_FMT_BGR48LE,   ///&lt; packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte value for each R/G/B component is stored as little-endian
 
    /**
     * The following 12 formats have the disadvantage of needing 1 format for each bit depth.
     * Notice that each 9/10 bits sample is stored in 16 bits with extra padding.
     * If you want to support multiple bit depths, then using AV_PIX_FMT_YUV420P16* with the bpp stored separately is better.
     */
    AV_PIX_FMT_YUV420P9BE, ///&lt; planar YUV 4:2:0, 13.5bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
    AV_PIX_FMT_YUV420P9LE, ///&lt; planar YUV 4:2:0, 13.5bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
    AV_PIX_FMT_YUV420P10BE,///&lt; planar YUV 4:2:0, 15bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
    AV_PIX_FMT_YUV420P10LE,///&lt; planar YUV 4:2:0, 15bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
    AV_PIX_FMT_YUV422P10BE,///&lt; planar YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
    AV_PIX_FMT_YUV422P10LE,///&lt; planar YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
    AV_PIX_FMT_YUV444P9BE, ///&lt; planar YUV 4:4:4, 27bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
    AV_PIX_FMT_YUV444P9LE, ///&lt; planar YUV 4:4:4, 27bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
    AV_PIX_FMT_YUV444P10BE,///&lt; planar YUV 4:4:4, 30bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
    AV_PIX_FMT_YUV444P10LE,///&lt; planar YUV 4:4:4, 30bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
    AV_PIX_FMT_YUV422P9BE, ///&lt; planar YUV 4:2:2, 18bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
    AV_PIX_FMT_YUV422P9LE, ///&lt; planar YUV 4:2:2, 18bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
    AV_PIX_FMT_VDA_VLD,    ///&lt; hardware decoding through VDA
 
#ifdef AV_PIX_FMT_ABI_GIT_MASTER
    AV_PIX_FMT_RGBA64BE,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
    AV_PIX_FMT_RGBA64LE,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
    AV_PIX_FMT_BGRA64BE,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
    AV_PIX_FMT_BGRA64LE,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
#endif
    AV_PIX_FMT_GBRP,      ///&lt; planar GBR 4:4:4 24bpp
    AV_PIX_FMT_GBRP9BE,   ///&lt; planar GBR 4:4:4 27bpp, big-endian
    AV_PIX_FMT_GBRP9LE,   ///&lt; planar GBR 4:4:4 27bpp, little-endian
    AV_PIX_FMT_GBRP10BE,  ///&lt; planar GBR 4:4:4 30bpp, big-endian
    AV_PIX_FMT_GBRP10LE,  ///&lt; planar GBR 4:4:4 30bpp, little-endian
    AV_PIX_FMT_GBRP16BE,  ///&lt; planar GBR 4:4:4 48bpp, big-endian
    AV_PIX_FMT_GBRP16LE,  ///&lt; planar GBR 4:4:4 48bpp, little-endian
 
    /**
     * duplicated pixel formats for compatibility with libav.
     * FFmpeg supports these formats since May 8 2012 and Jan 28 2012 (commits f9ca1ac7 and 143a5c55)
     * Libav added them Oct 12 2012 with incompatible values (commit 6d5600e85)
     */
    AV_PIX_FMT_YUVA422P_LIBAV,  ///&lt; planar YUV 4:2:2 24bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples)
    AV_PIX_FMT_YUVA444P_LIBAV,  ///&lt; planar YUV 4:4:4 32bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples)
 
    AV_PIX_FMT_YUVA420P9BE,  ///&lt; planar YUV 4:2:0 22.5bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples), big-endian
    AV_PIX_FMT_YUVA420P9LE,  ///&lt; planar YUV 4:2:0 22.5bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples), little-endian
    AV_PIX_FMT_YUVA422P9BE,  ///&lt; planar YUV 4:2:2 27bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples), big-endian
    AV_PIX_FMT_YUVA422P9LE,  ///&lt; planar YUV 4:2:2 27bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples), little-endian
    AV_PIX_FMT_YUVA444P9BE,  ///&lt; planar YUV 4:4:4 36bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples), big-endian
    AV_PIX_FMT_YUVA444P9LE,  ///&lt; planar YUV 4:4:4 36bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples), little-endian
    AV_PIX_FMT_YUVA420P10BE, ///&lt; planar YUV 4:2:0 25bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, big-endian)
    AV_PIX_FMT_YUVA420P10LE, ///&lt; planar YUV 4:2:0 25bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, little-endian)
    AV_PIX_FMT_YUVA422P10BE, ///&lt; planar YUV 4:2:2 30bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, big-endian)
    AV_PIX_FMT_YUVA422P10LE, ///&lt; planar YUV 4:2:2 30bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, little-endian)
    AV_PIX_FMT_YUVA444P10BE, ///&lt; planar YUV 4:4:4 40bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, big-endian)
    AV_PIX_FMT_YUVA444P10LE, ///&lt; planar YUV 4:4:4 40bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, little-endian)
    AV_PIX_FMT_YUVA420P16BE, ///&lt; planar YUV 4:2:0 40bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, big-endian)
    AV_PIX_FMT_YUVA420P16LE, ///&lt; planar YUV 4:2:0 40bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples, little-endian)
    AV_PIX_FMT_YUVA422P16BE, ///&lt; planar YUV 4:2:2 48bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, big-endian)
    AV_PIX_FMT_YUVA422P16LE, ///&lt; planar YUV 4:2:2 48bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples, little-endian)
    AV_PIX_FMT_YUVA444P16BE, ///&lt; planar YUV 4:4:4 64bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, big-endian)
    AV_PIX_FMT_YUVA444P16LE, ///&lt; planar YUV 4:4:4 64bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples, little-endian)
 
    AV_PIX_FMT_VDPAU,     ///&lt; HW acceleration through VDPAU, Picture.data[3] contains a VdpVideoSurface
 
    AV_PIX_FMT_XYZ12LE,      ///&lt; packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as little-endian, the 4 lower bits are set to 0
    AV_PIX_FMT_XYZ12BE,      ///&lt; packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the 2-byte value for each X/Y/Z is stored as big-endian, the 4 lower bits are set to 0
    AV_PIX_FMT_NV16,         ///&lt; interleaved chroma YUV 4:2:2, 16bpp, (1 Cr &amp; Cb sample per 2x1 Y samples)
    AV_PIX_FMT_NV20LE,       ///&lt; interleaved chroma YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
    AV_PIX_FMT_NV20BE,       ///&lt; interleaved chroma YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
 
    /**
     * duplicated pixel formats for compatibility with libav.
     * FFmpeg supports these formats since Sat Sep 24 06:01:45 2011 +0200 (commits 9569a3c9f41387a8c7d1ce97d8693520477a66c3)
     * also see Fri Nov 25 01:38:21 2011 +0100 92afb431621c79155fcb7171d26f137eb1bee028
     * Libav added them Sun Mar 16 23:05:47 2014 +0100 with incompatible values (commit 1481d24c3a0abf81e1d7a514547bd5305232be30)
     */
    AV_PIX_FMT_RGBA64BE_LIBAV,     ///&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
    AV_PIX_FMT_RGBA64LE_LIBAV,     ///&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
    AV_PIX_FMT_BGRA64BE_LIBAV,     ///&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
    AV_PIX_FMT_BGRA64LE_LIBAV,     ///&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
 
    AV_PIX_FMT_YVYU422,   ///&lt; packed YUV 4:2:2, 16bpp, Y0 Cr Y1 Cb
 
#ifndef AV_PIX_FMT_ABI_GIT_MASTER
    AV_PIX_FMT_RGBA64BE=0x123,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
    AV_PIX_FMT_RGBA64LE,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
    AV_PIX_FMT_BGRA64BE,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as big-endian
    AV_PIX_FMT_BGRA64LE,  ///&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the 2-byte value for each R/G/B/A component is stored as little-endian
#endif
    AV_PIX_FMT_0RGB=0x123+4,      ///&lt; packed RGB 8:8:8, 32bpp, 0RGB0RGB...
    AV_PIX_FMT_RGB0,      ///&lt; packed RGB 8:8:8, 32bpp, RGB0RGB0...
    AV_PIX_FMT_0BGR,      ///&lt; packed BGR 8:8:8, 32bpp, 0BGR0BGR...
    AV_PIX_FMT_BGR0,      ///&lt; packed BGR 8:8:8, 32bpp, BGR0BGR0...
    AV_PIX_FMT_YUVA444P,  ///&lt; planar YUV 4:4:4 32bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A samples)
    AV_PIX_FMT_YUVA422P,  ///&lt; planar YUV 4:2:2 24bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A samples)
 
    AV_PIX_FMT_YUV420P12BE, ///&lt; planar YUV 4:2:0,18bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
    AV_PIX_FMT_YUV420P12LE, ///&lt; planar YUV 4:2:0,18bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
    AV_PIX_FMT_YUV420P14BE, ///&lt; planar YUV 4:2:0,21bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), big-endian
    AV_PIX_FMT_YUV420P14LE, ///&lt; planar YUV 4:2:0,21bpp, (1 Cr &amp; Cb sample per 2x2 Y samples), little-endian
    AV_PIX_FMT_YUV422P12BE, ///&lt; planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
    AV_PIX_FMT_YUV422P12LE, ///&lt; planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
    AV_PIX_FMT_YUV422P14BE, ///&lt; planar YUV 4:2:2,28bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), big-endian
    AV_PIX_FMT_YUV422P14LE, ///&lt; planar YUV 4:2:2,28bpp, (1 Cr &amp; Cb sample per 2x1 Y samples), little-endian
    AV_PIX_FMT_YUV444P12BE, ///&lt; planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
    AV_PIX_FMT_YUV444P12LE, ///&lt; planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
    AV_PIX_FMT_YUV444P14BE, ///&lt; planar YUV 4:4:4,42bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), big-endian
    AV_PIX_FMT_YUV444P14LE, ///&lt; planar YUV 4:4:4,42bpp, (1 Cr &amp; Cb sample per 1x1 Y samples), little-endian
    AV_PIX_FMT_GBRP12BE,    ///&lt; planar GBR 4:4:4 36bpp, big-endian
    AV_PIX_FMT_GBRP12LE,    ///&lt; planar GBR 4:4:4 36bpp, little-endian
    AV_PIX_FMT_GBRP14BE,    ///&lt; planar GBR 4:4:4 42bpp, big-endian
    AV_PIX_FMT_GBRP14LE,    ///&lt; planar GBR 4:4:4 42bpp, little-endian
    AV_PIX_FMT_GBRAP,       ///&lt; planar GBRA 4:4:4:4 32bpp
    AV_PIX_FMT_GBRAP16BE,   ///&lt; planar GBRA 4:4:4:4 64bpp, big-endian
    AV_PIX_FMT_GBRAP16LE,   ///&lt; planar GBRA 4:4:4:4 64bpp, little-endian
    AV_PIX_FMT_YUVJ411P,    ///&lt; planar YUV 4:1:1, 12bpp, (1 Cr &amp; Cb sample per 4x1 Y samples) full scale (JPEG), deprecated in favor of PIX_FMT_YUV411P and setting color_range
 
    AV_PIX_FMT_BAYER_BGGR8,    ///&lt; bayer, BGBG..(odd line), GRGR..(even line), 8-bit samples */
    AV_PIX_FMT_BAYER_RGGB8,    ///&lt; bayer, RGRG..(odd line), GBGB..(even line), 8-bit samples */
    AV_PIX_FMT_BAYER_GBRG8,    ///&lt; bayer, GBGB..(odd line), RGRG..(even line), 8-bit samples */
    AV_PIX_FMT_BAYER_GRBG8,    ///&lt; bayer, GRGR..(odd line), BGBG..(even line), 8-bit samples */
    AV_PIX_FMT_BAYER_BGGR16LE, ///&lt; bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, little-endian */
    AV_PIX_FMT_BAYER_BGGR16BE, ///&lt; bayer, BGBG..(odd line), GRGR..(even line), 16-bit samples, big-endian */
    AV_PIX_FMT_BAYER_RGGB16LE, ///&lt; bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, little-endian */
    AV_PIX_FMT_BAYER_RGGB16BE, ///&lt; bayer, RGRG..(odd line), GBGB..(even line), 16-bit samples, big-endian */
    AV_PIX_FMT_BAYER_GBRG16LE, ///&lt; bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, little-endian */
    AV_PIX_FMT_BAYER_GBRG16BE, ///&lt; bayer, GBGB..(odd line), RGRG..(even line), 16-bit samples, big-endian */
    AV_PIX_FMT_BAYER_GRBG16LE, ///&lt; bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, little-endian */
    AV_PIX_FMT_BAYER_GRBG16BE, ///&lt; bayer, GRGR..(odd line), BGBG..(even line), 16-bit samples, big-endian */
#if !FF_API_XVMC
    AV_PIX_FMT_XVMC,///&lt; XVideo Motion Acceleration via common packet passing
#endif /* !FF_API_XVMC */
 
    AV_PIX_FMT_NB,        ///&lt; number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions
 
#if FF_API_PIX_FMT
#include "old_pix_fmts.h"
#endif
};</pre><br />FFmpeg有一个专门用于描述像素格式的结构体AVPixFmtDescriptor。该结构体的定义位于libavutil\pixdesc.h，如下所示。<br /><pre class="cpp">/**
 * Descriptor that unambiguously describes how the bits of a pixel are
 * stored in the up to 4 data planes of an image. It also stores the
 * subsampling factors and number of components.
 *
 * @note This is separate of the colorspace (RGB, YCbCr, YPbPr, JPEG-style YUV
 *       and all the YUV variants) AVPixFmtDescriptor just stores how values
 *       are stored not what these values represent.
 */
typedef struct AVPixFmtDescriptor{
    const char *name;
    uint8_t nb_components;      ///&lt; The number of components each pixel has, (1-4)
 
    /**
     * Amount to shift the luma width right to find the chroma width.
     * For YV12 this is 1 for example.
     * chroma_width = -((-luma_width) &gt;&gt; log2_chroma_w)
     * The note above is needed to ensure rounding up.
     * This value only refers to the chroma components.
     */
    uint8_t log2_chroma_w;      ///&lt; chroma_width = -((-luma_width )&gt;&gt;log2_chroma_w)
 
    /**
     * Amount to shift the luma height right to find the chroma height.
     * For YV12 this is 1 for example.
     * chroma_height= -((-luma_height) &gt;&gt; log2_chroma_h)
     * The note above is needed to ensure rounding up.
     * This value only refers to the chroma components.
     */
    uint8_t log2_chroma_h;
    uint8_t flags;
 
    /**
     * Parameters that describe how pixels are packed.
     * If the format has 2 or 4 components, then alpha is last.
     * If the format has 1 or 2 components, then luma is 0.
     * If the format has 3 or 4 components,
     * if the RGB flag is set then 0 is red, 1 is green and 2 is blue;
     * otherwise 0 is luma, 1 is chroma-U and 2 is chroma-V.
     */
    AVComponentDescriptor comp[4];
}AVPixFmtDescriptor;</pre><br />关于AVPixFmtDescriptor这个结构体不再做过多解释。它的定义比较简单，看注释就可以理解。通过av_pix_fmt_desc_get()可以获得指定像素格式的AVPixFmtDescriptor结构体。<br /><pre class="cpp">/**
 * @return a pixel format descriptor for provided pixel format or NULL if
 * this pixel format is unknown.
 */
const AVPixFmtDescriptor *av_pix_fmt_desc_get(enum AVPixelFormat pix_fmt);</pre> <br />通过AVPixFmtDescriptor结构体可以获得不同像素格式的一些信息。例如下文中用到了av_get_bits_per_pixel()，通过该函数可以获得指定像素格式每个像素占用的比特数（Bit Per Pixel）。<br /><pre class="cpp">/**
 * Return the number of bits per pixel used by the pixel format
 * described by pixdesc. Note that this is not the same as the number
 * of bits per sample.
 *
 * The returned number of bits refers to the number of bits actually
 * used for storing the pixel information, that is padding bits are
 * not counted.
 */
int av_get_bits_per_pixel(const AVPixFmtDescriptor *pixdesc);</pre><br />其他的API在这里不做过多记录。<br /> <br /><h3>图像拉伸</h3>FFmpeg支持多种像素拉伸的方式。这些方式的定义位于libswscale\swscale.h中，如下所示。<br /><pre class="cpp">#define SWS_FAST_BILINEAR     1
#define SWS_BILINEAR          2
#define SWS_BICUBIC           4
#define SWS_X                 8
#define SWS_POINT          0x10
#define SWS_AREA           0x20
#define SWS_BICUBLIN       0x40
#define SWS_GAUSS          0x80
#define SWS_SINC          0x100
#define SWS_LANCZOS       0x200
#define SWS_SPLINE        0x400</pre><br />其中SWS_BICUBIC性能比较好；SWS_FAST_BILINEAR在性能和速度之间有一个比好好的平衡，<br />而SWS_POINT的效果比较差。<br /><p>有关这些方法的评测可以参考文章：</p><p><a href="http://blog.csdn.net/leixiaohua1020/article/details/12029505">《ffmpeg中的sws_scale算法性能测试》</a></p>简单解释一下SWS_BICUBIC、SWS_BILINEAR和SWS_POINT的原理。<br /><h4>SWS_POINT（Nearest-neighbor interpolation， 邻域插值）</h4>领域插值可以简单说成“1个点确定插值的点”。例如当图像放大后，新的样点根据距离它最近的样点的值取得自己的值。换句话说就是简单拷贝附近距离它最近的样点的值。领域插值是一种最基础的插值方法，速度最快，插值效果最不好，一般情况下不推荐使用。一般情况下使用邻域插值之后，画面会产生很多的“锯齿”。下图显示了4x4=16个彩色样点经过邻域插值后形成的图形。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012015923?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><h4>SWS_BILINEAR（Bilinear interpolation， 双线性插值）</h4>双线性插值可以简单说成“4个点确定插值的点”。它的计算过程可以简单用下图表示。图中绿色的P点是需要插值的点。首先通过Q11，Q21求得R1；Q12，Q22求得R2。然后根据R1，R2求得P。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012036234?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><br />其中求值的过程是一个简单的加权计算的过程。<br />设定Q11 = (x1, y1)，Q12 = (x1, y2)，Q21 = (x2, y1)，Q22 = (x2, y2)则各点的计算公式如下。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012103347?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012107059?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012110226?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><br />可以看出距离插值的点近一些的样点权值会大一些，远一些的样点权值要小一些。<br />下面看一个维基百科上的双线性插值的实例。该例子根据坐标为(20, 14)， (20, 15)， (21, 14)，(21, 15)的4个样点计算坐标为（20.2, 14.5）的插值点的值。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012135734?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><div style="text-align:center;"><img src="https://img-blog.csdn.net/20160116235115248" alt="" /><br /></div><div style="text-align:center;"><br /></div><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012201862?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><br /><h4>SWS_BICUBIC（Bicubic interpolation， 双三次插值）</h4><p>双三次插值可以简单说成“16个点确定插值的点”。该插值算法比前两种算法复杂很多，插值后图像的质量也是最好的。有关它的插值方式比较复杂不再做过多记录。它的差值方法可以简单表述为下述公式。</p><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012235324?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><br />其中aij的过程依赖于插值数据的特性。<br /> <br />维基百科上使用同样的样点进行邻域插值，双线性插值，双三次插值对比如下图所示。<br /><p style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012308053?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></p><div style="text-align:center;">Nearest-neighbor interpolation，邻域插值</div><p style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012326453?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></p><p style="text-align:center;">Bilinear interpolation，双线性插值</p><p style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012341953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></p><div style="text-align:center;">Bicubic interpolation，双三次插值</div> <br /><h3>YUV像素取值范围</h3><p>FFmpeg中可以通过使用av_opt_set()设置“src_range”和“dst_range”来设置输入和输出的YUV的取值范围。如果“dst_range”字段设置为“1”的话，则代表输出的YUV的取值范围遵循“jpeg”标准；如果“dst_range”字段设置为“0”的话，则代表输出的YUV的取值范围遵循“mpeg”标准。下面记录一下YUV的取值范围的概念。</p><p>与RGB每个像素点的每个分量取值范围为0-255不同（每个分量占8bit），YUV取值范围有两种：</p><blockquote style="margin:0 0 0 40px;border:none;padding:0px;">（1）       以Rec.601为代表（还包括BT.709 / BT.2020）的广播电视标准中，Y的取值范围是16-235，U、V的取值范围是16-240。FFmpeg中称之为“mpeg”范围。<p>（2）       以JPEG为代表的标准中，Y、U、V的取值范围都是0-255。FFmpeg中称之为“jpeg” 范围。</p></blockquote><p>实际中最常见的是第1种取值范围的YUV（可以自己观察一下YUV的数据，会发现其中亮度分量没有取值为0、255这样的数值）。很多人在这个地方会有疑惑，为什么会去掉“两边”的取值呢？</p>在广播电视系统中不传输很低和很高的数值，实际上是为了防止信号变动造成过载，因而把这“两边”的数值作为“保护带”。下面这张图是数字电视中亮度信号量化后的电平分配图。从图中可以看出，对于8bit量化来说，信号的白电平为235，对应模拟电平为700mV；黑电平为16，对应模拟电平为0mV。信号上方的“保护带”取值范围是236至254，而信号下方的“保护带”取值范围是1-15。最边缘的0和255两个电平是保护电平，是不允许出现在数据流中的。与之类似，10bit量化的时候，白电平是235*4=940，黑电平是16*4=64。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012423433?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div>下面两张图是数字电视中色度信号量化后的电平分配图。可以看出，色度最大正电平为240，对应模拟电平为+350mV；色度最大负电平为16，对应模拟电平为-350mV。需要注意的是，色度信号数字电平128对应的模拟电平是0mV。<br /><p style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012442231?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></p><p style="text-align:center;"><br /></p><p style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012449407?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></p> <br /><h3>色域</h3>Libswscale支持色域的转换。有关色域的转换我目前还没有做太多的研究，仅记录一下目前最常见的三个标准中的色域：BT.601，BT.709，BT.2020。这三个标准中的色域逐渐增大。<br />在这里先简单解释一下CIE 1931颜色空间。这个空间围绕的区域像一个“舌头”，其中包含了自然界所有的颜色。CIE 1931颜色空间中的横坐标是x，纵坐标是y，x、y、z满足如下关系：<br /><div style="text-align:center;">x + y + z = 1</div>“舌头”的边缘叫做“舌形曲线”，代表着饱和度为100%的光谱色。“舌头”的中心点（1/3，1/3）对应着白色，饱和度为0。<br />受显示器件性能的限制，电视屏幕是无法重现所有的颜色的，尤其是位于“舌形曲线”上的100% 饱和度的光谱色一般情况下是无法显示出来的。因此电视屏幕只能根据其具体的荧光粉的配方，有选择性的显示一部分的颜色，这部分可以显示的颜色称为色域。下文分别比较标清电视、高清电视和超高清电视标准中规定的色域。可以看出随着技术的进步，色域的范围正变得越来越大。<br /><strong>标清电视（SDTV）色域的规定源自于BT.601。高清电视（HDTV）色域的规定源自于BT.709。</strong>他们两个标准中的色域在CIE 1931颜色空间中的对比如下图所示。从图中可以看出，BT.709和BT.601色域差别不大，BT.709的色域要略微大于BT.601。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012556144?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><br /><strong>超高清电视（UHDTV）色域的规定源自于BT.2020。</strong>BT.2020和BT.709的色域在CIE 1931 颜色空间中的对比如下图所示。从图中可以看出，BT.2020的色域要远远大于BT.709。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012610371?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><p>从上面的对比也可以看出，对超高清电视（UHDTV）的显示器件的性能的要求更高了。这样超高清电视可以还原出一个更“真实”的世界。</p><p>下面这张图则使用实际的例子反映出色域范围大的重要性。图中的两个黑色三角形分别标识出了BT.709（小三角形）和BT.2020（大三角形）标准中的色域。从图中可以看出，如果使用色域较小的显示设备显示图片的话，将会损失掉很多的颜色。</p><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012652366?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div><h2>源代码</h2>本示例程序包含一个输入和一个输出，实现了从输入图像格式（YUV420P）到输出图像格式（RGB24）之间的转换；同时将输入视频的分辨率从480x272拉伸为1280x720。<br /> <pre class="cpp">/**
 * 最简单的基于FFmpeg的Swscale示例
 * Simplest FFmpeg Swscale
 *
 * 雷霄骅 Lei Xiaohua
 * leixiaohua1020@126.com
 * 中国传媒大学/数字电视技术
 * Communication University of China / Digital TV Technology
 * http://blog.csdn.net/leixiaohua1020
 *
 * 本程序使用libswscale对像素数据进行缩放转换等处理。
 * 它中实现了YUV420P格式转换为RGB24格式，
 * 同时将分辨率从480x272拉伸为1280x720
 * 它是最简单的libswscale的教程。
 *
 * This software uses libswscale to scale / convert pixels.
 * It convert YUV420P format to RGB24 format,
 * and changes resolution from 480x272 to 1280x720.
 * It's the simplest tutorial about libswscale.
 */

#include &lt;stdio.h&gt;

#define __STDC_CONSTANT_MACROS

#ifdef _WIN32
//Windows
extern "C"
{
#include "libswscale/swscale.h"
#include "libavutil/opt.h"
#include "libavutil/imgutils.h"
};
#else
//Linux...
#ifdef __cplusplus
extern "C"
{
#endif
#include &lt;libswscale/swscale.h&gt;
#include &lt;libavutil/opt.h&gt;
#include &lt;libavutil/imgutils.h&gt;
#ifdef __cplusplus
};
#endif
#endif


int main(int argc, char* argv[])
{
	//Parameters	
	FILE *src_file =fopen("sintel_480x272_yuv420p.yuv", "rb");
	const int src_w=480,src_h=272;
	AVPixelFormat src_pixfmt=AV_PIX_FMT_YUV420P;

	int src_bpp=av_get_bits_per_pixel(av_pix_fmt_desc_get(src_pixfmt));

	FILE *dst_file = fopen("sintel_1280x720_rgb24.rgb", "wb");
	const int dst_w=1280,dst_h=720;
	AVPixelFormat dst_pixfmt=AV_PIX_FMT_RGB24;
	int dst_bpp=av_get_bits_per_pixel(av_pix_fmt_desc_get(dst_pixfmt));

	//Structures
	uint8_t *src_data[4];
	int src_linesize[4];

	uint8_t *dst_data[4];
	int dst_linesize[4];

	int rescale_method=SWS_BICUBIC;
	struct SwsContext *img_convert_ctx;
	uint8_t *temp_buffer=(uint8_t *)malloc(src_w*src_h*src_bpp/8);
	
	int frame_idx=0;
	int ret=0;
	ret= av_image_alloc(src_data, src_linesize,src_w, src_h, src_pixfmt, 1);
	if (ret&lt; 0) {
		printf( "Could not allocate source image\n");
		return -1;
	}
	ret = av_image_alloc(dst_data, dst_linesize,dst_w, dst_h, dst_pixfmt, 1);
	if (ret&lt; 0) {
		printf( "Could not allocate destination image\n");
		return -1;
	}
	//-----------------------------	
	//Init Method 1
	img_convert_ctx =sws_alloc_context();
	//Show AVOption
	av_opt_show2(img_convert_ctx,stdout,AV_OPT_FLAG_VIDEO_PARAM,0);
	//Set Value
	av_opt_set_int(img_convert_ctx,"sws_flags",SWS_BICUBIC|SWS_PRINT_INFO,0);
	av_opt_set_int(img_convert_ctx,"srcw",src_w,0);
	av_opt_set_int(img_convert_ctx,"srch",src_h,0);
	av_opt_set_int(img_convert_ctx,"src_format",src_pixfmt,0);
	//'0' for MPEG (Y:0-235);'1' for JPEG (Y:0-255)
	av_opt_set_int(img_convert_ctx,"src_range",1,0);
	av_opt_set_int(img_convert_ctx,"dstw",dst_w,0);
	av_opt_set_int(img_convert_ctx,"dsth",dst_h,0);
	av_opt_set_int(img_convert_ctx,"dst_format",dst_pixfmt,0);
	av_opt_set_int(img_convert_ctx,"dst_range",1,0);
	sws_init_context(img_convert_ctx,NULL,NULL);

	//Init Method 2
	//img_convert_ctx = sws_getContext(src_w, src_h,src_pixfmt, dst_w, dst_h, dst_pixfmt, 
	//	rescale_method, NULL, NULL, NULL); 
	//-----------------------------
	/*
	//Colorspace
	ret=sws_setColorspaceDetails(img_convert_ctx,sws_getCoefficients(SWS_CS_ITU601),0,
		sws_getCoefficients(SWS_CS_ITU709),0,
		 0, 1 &lt;&lt; 16, 1 &lt;&lt; 16);
	if (ret==-1) {
		printf( "Colorspace not support.\n");
		return -1;
	}
	*/
	while(1)
	{
		if (fread(temp_buffer, 1, src_w*src_h*src_bpp/8, src_file) != src_w*src_h*src_bpp/8){
			break;
		}
		
		switch(src_pixfmt){
		case AV_PIX_FMT_GRAY8:{
			memcpy(src_data[0],temp_buffer,src_w*src_h);
			break;
							  }
		case AV_PIX_FMT_YUV420P:{
			memcpy(src_data[0],temp_buffer,src_w*src_h);                    //Y
			memcpy(src_data[1],temp_buffer+src_w*src_h,src_w*src_h/4);      //U
			memcpy(src_data[2],temp_buffer+src_w*src_h*5/4,src_w*src_h/4);  //V
			break;
								}
		case AV_PIX_FMT_YUV422P:{
			memcpy(src_data[0],temp_buffer,src_w*src_h);                    //Y
			memcpy(src_data[1],temp_buffer+src_w*src_h,src_w*src_h/2);      //U
			memcpy(src_data[2],temp_buffer+src_w*src_h*3/2,src_w*src_h/2);  //V
			break;
								}
		case AV_PIX_FMT_YUV444P:{
			memcpy(src_data[0],temp_buffer,src_w*src_h);                    //Y
			memcpy(src_data[1],temp_buffer+src_w*src_h,src_w*src_h);        //U
			memcpy(src_data[2],temp_buffer+src_w*src_h*2,src_w*src_h);      //V
			break;
								}
		case AV_PIX_FMT_YUYV422:{
			memcpy(src_data[0],temp_buffer,src_w*src_h*2);                  //Packed
			break;
								}
		case AV_PIX_FMT_RGB24:{
			memcpy(src_data[0],temp_buffer,src_w*src_h*3);                  //Packed
			break;
								}
		default:{
			printf("Not Support Input Pixel Format.\n");
			break;
							  }
		}
		
		sws_scale(img_convert_ctx, src_data, src_linesize, 0, src_h, dst_data, dst_linesize);
		printf("Finish process frame %5d\n",frame_idx);
		frame_idx++;

		switch(dst_pixfmt){
		case AV_PIX_FMT_GRAY8:{
			fwrite(dst_data[0],1,dst_w*dst_h,dst_file);	
			break;
							  }
		case AV_PIX_FMT_YUV420P:{
			fwrite(dst_data[0],1,dst_w*dst_h,dst_file);                 //Y
			fwrite(dst_data[1],1,dst_w*dst_h/4,dst_file);               //U
			fwrite(dst_data[2],1,dst_w*dst_h/4,dst_file);               //V
			break;
								}
		case AV_PIX_FMT_YUV422P:{
			fwrite(dst_data[0],1,dst_w*dst_h,dst_file);					//Y
			fwrite(dst_data[1],1,dst_w*dst_h/2,dst_file);				//U
			fwrite(dst_data[2],1,dst_w*dst_h/2,dst_file);				//V
			break;
								}
		case AV_PIX_FMT_YUV444P:{
			fwrite(dst_data[0],1,dst_w*dst_h,dst_file);                 //Y
			fwrite(dst_data[1],1,dst_w*dst_h,dst_file);                 //U
			fwrite(dst_data[2],1,dst_w*dst_h,dst_file);                 //V
			break;
								}
		case AV_PIX_FMT_YUYV422:{
			fwrite(dst_data[0],1,dst_w*dst_h*2,dst_file);               //Packed
			break;
								}
		case AV_PIX_FMT_RGB24:{
			fwrite(dst_data[0],1,dst_w*dst_h*3,dst_file);               //Packed
			break;
							  }
		default:{
			printf("Not Support Output Pixel Format.\n");
			break;
							}
		}
	}

	sws_freeContext(img_convert_ctx);

	free(temp_buffer);
	fclose(dst_file);
	av_freep(&amp;src_data[0]);
	av_freep(&amp;dst_data[0]);

	return 0;
}
</pre><br /><br /> <br /><h2>运行结果</h2><br />程序的输入为一个名称为“sintel_480x272_yuv420p.yuv”的视频。该视频像素格式是YUV420P，分辨率为480x272。<br /><br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012709984?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /></div> <br />程序的输出为一个名称为“sintel_1280x720_rgb24.rgb”的视频。该视频像素格式是RGB24，分辨率为1280x720。<br /><div style="text-align:center;"><img src="https://img-blog.csdn.net/20141225012725812?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" /><br /></div><br /><h2>下载</h2><br /><strong>Simplest FFmpeg Swscale</strong><br /> <br /><p></p><p><strong>项目主页</strong></p><p>SourceForge：<a href="https://sourceforge.net/projects/simplestffmpegswscale/">https://sourceforge.net/projects/simplestffmpegswscale/</a></p><p>Github：<a href="https://github.com/leixiaohua1020/simplest_ffmpeg_swscale">https://github.com/leixiaohua1020/simplest_ffmpeg_swscale</a></p><p>开源中国：<a href="http://git.oschina.net/leixiaohua1020/simplest_ffmpeg_swscale">http://git.oschina.net/leixiaohua1020/simplest_ffmpeg_swscale</a></p><p><br /></p><p>CDSN下载地址：<a href="http://download.csdn.net/detail/leixiaohua1020/8292175">http://download.csdn.net/detail/leixiaohua1020/8292175</a></p> <br />本教程是最简单的基于FFmpeg的libswscale进行像素处理的教程。它包含了两个工程：<br /><span style="color:rgb(255,0,0);">simplest_ffmpeg_swscale: 最简单的libswscale的教程。</span><br /><p>simplest_pic_gen: 生成各种测试图片的工具。</p><p><br /></p><p><strong> 更新-1.1 (2015.2.13)=========================================</strong></p><p>这次考虑到了跨平台的要求，调整了源代码。经过这次调整之后，源代码可以在以下平台编译通过：</p><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><em>VC++：打开sln文件即可编译，无需配置。</em></p></blockquote><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><p><em>cl.exe：打开compile_cl.bat即可命令行下使用cl.exe进行编译，注意可能需要按照VC的安装路径调整脚本里面的参数。编译命令如下。</em></p></blockquote><pre class="plain">::VS2010 Environment
call "D:\Program Files\Microsoft Visual Studio 10.0\VC\vcvarsall.bat"
::include
@set INCLUDE=include;%INCLUDE%
::lib
@set LIB=lib;%LIB%
::compile and link
cl simplest_ffmpeg_swscale.cpp /link swscale.lib avutil.lib /OPT:NOREF</pre><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><em>MinGW：MinGW命令行下运行compile_mingw.sh即可使用MinGW的g++进行编译。编译命令如下。</em></blockquote><pre class="plain">g++ simplest_ffmpeg_swscale.cpp -g -o simplest_ffmpeg_swscale.exe \
-I /usr/local/include -L /usr/local/lib -lswscale -lavutil</pre><blockquote style="margin:0 0 0 40px;border:none;padding:0px;"><em>GCC：Linux或者MacOS命令行下运行compile_gcc.sh即可使用GCC进行编译。编译命令如下。</em></blockquote><pre class="plain">gcc simplest_ffmpeg_swscale.cpp -g -o simplest_ffmpeg_swscale.out  -I /usr/local/include -L /usr/local/lib \
-lswscale -lavutil</pre><br />PS：相关的编译命令已经保存到了工程文件夹中<br /><br /><p>CSDN下载地址：<a href="http://download.csdn.net/detail/leixiaohua1020/8445671">http://download.csdn.net/detail/leixiaohua1020/8445671</a></p><p>SourceForge上已经更新。</p>             </div>
                </div>
				<div style="display:none;" class="hide-article-box text-center csdn-tracking-statistics tracking-click" data-mod="popu_376">
			<a class="btn btn-red-hollow" id="btn-readmore">阅读更多</a>
		</div>
        	</article>
	
		<div class="article-bar-bottom">
				<div class="article-copyright">
			版权声明：本文为博主原创文章，未经博主允许不得转载。			https://blog.csdn.net/leixiaohua1020/article/details/42134965		</div>
						<div class="tags-box artic-tag-box">
			<span class="label">文章标签：</span>
						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=libswscale&t=blog" target="_blank">libswscale						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=拉伸&t=blog" target="_blank">拉伸						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=yuv&t=blog" target="_blank">yuv						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=ffmpeg&t=blog" target="_blank">ffmpeg						<a class="tag-link" href="http://so.csdn.net/so/search/s.do?q=色域&t=blog" target="_blank">色域						</a>
		</div>
						<div class="tags-box">
			<span class="label">个人分类：</span>
						<a class="tag-link" href="https://blog.csdn.net/leixiaohua1020/article/category/1360795"  target="_blank">FFMPEG						<a class="tag-link" href="https://blog.csdn.net/leixiaohua1020/article/category/1843731"  target="_blank">我的开源项目						</a>
		</div>
						<div class="tags-box">
			<span class="label">所属专栏：</span>
						<a class="tag-link" href="https://blog.csdn.net/column/details/ffmpeg-devel.html" target="_blank">FFmpeg</a>
						</a>
		</div>
			</div>
	
	<!-- !empty($pre_next_article[0]) -->
		</div>
<script>
    $(".MathJax").remove();
</script>

<script type="text/javascript" src="https://static-blog.csdn.net/mdeditor/public/res/bower-libs/MathJax/MathJax@js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
			"HTML-CSS": {
					linebreaks: { automatic: true, width: "94%container" },
					imageFont: null
			},
			tex2jax: {
				preview: "none"
			},
			mml2jax: {
				preview: 'none'
			}
	});
</script>
<script>
	(function(){
		var btnReadmore = $("#btn-readmore");
		if(btnReadmore.length>0){
			var winH = $(window).height();
			var articleBox = $("div.article_content");
			var artH = articleBox.height();
			if(artH > winH*2){
				articleBox.css({
					'height':winH*2+'px',
					'overflow':'hidden'
				})
				btnReadmore.click(function(){
					articleBox.removeAttr("style");
					$(this).parent().remove();
				})
			}else{
				btnReadmore.parent().remove();
			}
		}
	})()
</script>        <div class="edu-promotion"></div>
<script type="text/javascript">
	var edu_ad_is_big_data = 0;
	var edu_ad_id_mapping = {"0":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"1":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"8":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"2":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1"],"3":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"6":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"12":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"14":["https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcweb","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"15":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcjg","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1"],"16":["https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1"],"28":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcai","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"29":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1"],"30":["https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1"],"32":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcaq"],"33":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gccxrs","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1"],"35":["https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"37":["https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1"],"7":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=web1","https:\/\/edu.csdn.net\/sp\/blog.php?type=618"],"17":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1"],"34":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcbt"],"36":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=ai1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"31":["https:\/\/edu.csdn.net\/sp\/blog.php?type=python1","https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"19":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"],"20":["https:\/\/edu.csdn.net\/sp\/blog.php?type=bigdata1","https:\/\/edu.csdn.net\/sp\/blog.php?type=gcit"]};
</script>        <a id="commentBox"></a>
<div class="comment-box" style="display:none;">
	  	<div class="unlogin-box text-center">
		想对作者说点什么？
		<!-- $curl 当前地址 -->
		<a href="https://passport.csdn.net/account/login?from=https://blog.csdn.net/leixiaohua1020/article/details/42134965#commentBox" class="btn btn-sm btn-red">我来说一句</a>
	</div>
			<div class="comment-list-container">
		<a id="comments"></a>
		<div class="comment-list-box">
		</div>
		<div id="commentPage" class="pagination-box d-none"></div>
		<div class="opt-box text-center">
			<button class="btn btn-sm btn-link-blue" id="btnMoreComment"></button>
		</div>
	</div>
</div>        <div class="recommend-box" style="display:none;">
            		<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/leixiaohua1020/article/details/14215391" target="_blank" strategy="BlogCommendFromBaidu_0">
				<em>FFMPEG</em> 实现 <em>YUV</em>，<em>RGB</em>各种图像原始数据之间的转换（swscale）			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/leixiaohua1020/article/details/14215391" target="_blank" >
				<em>FFMPEG</em>中的swscale提供了视频原始数据（<em>YUV</em>420，<em>YUV</em>422，<em>YUV</em>444，<em>RGB</em>24...）之间的转换，分辨率变换等操作，使用起来十分方便，在这里记录一下它的用法。

swscale...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/leixiaohua1020" title="leixiaohua1020" target="_blank">
					<img src="https://avatar.csdn.net/A/7/6/3_leixiaohua1020.jpg" alt="leixiaohua1020" class="avatar-pic">
					<span class="name">leixiaohua1020</span>
				</a>
			</p>
			<p>
				<span class="date">2013-11-06 15:37:09</span>
			</p>
			<p>
				<span class="read-num">阅读数：87806</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/STN_LCD/article/details/73649332" target="_blank" strategy="BlogCommendFromBaidu_1">
				颜色格式转换： 最<em>简单</em>的<em>基于</em><em>FFmpeg</em>的<em>libswscale</em>的<em>示例</em>（<em>YUV</em>转<em>RGB</em>）			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/STN_LCD/article/details/73649332" target="_blank" >
				http://blog.csdn.net/leixiaohua1020/article/details/42134965






版权声明：本文为博主原创文章，未经博主允许不得转载。...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/STN_LCD" title="STN_LCD" target="_blank">
					<img src="https://avatar.csdn.net/5/E/7/3_stn_lcd.jpg" alt="STN_LCD" class="avatar-pic">
					<span class="name">STN_LCD</span>
				</a>
			</p>
			<p>
				<span class="date">2017-06-23 16:10:35</span>
			</p>
			<p>
				<span class="read-num">阅读数：628</span>
			</p>
		</div>
	</div>
								<div class="recommend-item-box recommend-ad-box" id="ad1"></div>
				<script>
				  var width = $("div.recommend-box").outerWidth() - 48;
					NEWS_FEED({
						w: width,
						h : 90,
						showid : 'GNKXx7',
						placeholderId: "ad1",
						inject : 'define',
						define : {
							imagePosition : 'right',
							imageBorderRadius : 0,
							imageWidth: 120,
							imageHeight: 90,
							imageFill : 'clip',
							displayImage : true,
							displayTitle : true,
							titleFontSize: 20,
							titleFontColor: '#333',
							titleFontFamily : 'Microsoft Yahei',
							titleFontWeight: 'bold',
							titlePaddingTop : 0,
							titlePaddingRight : 0,
							titlePaddingBottom : 10,
							titlePaddingLeft : 0,
							displayDesc : true,
							descFontSize: 14,
							descFontColor: '#6b6b6b',
							descFontFamily : 'Microsoft Yahei',
							paddingTop : 0,
							paddingRight : 0,
							paddingBottom : 0,
							paddingLeft : 0,
							backgroundColor: '#fff',
							hoverColor: '#ca0c16'
						}
					})
				</script>

			
				<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/jscese/article/details/52946979" target="_blank" strategy="BlogCommendFromBaidu_2">
				<em>FFMPEG</em>-初探认识-<em>YUV</em>转<em>RGB</em>用例			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/jscese/article/details/52946979" target="_blank" >
				前段时间因为项目需要，尝试通过<em>FFMPEG</em>将图像帧进行格式转换，评估测试了一下，记录一下<em>FFMPEG</em>的一些基本信息资料概念:来自百科： 
<em>FFmpeg</em>是一套可以用来记录、转换数字音频、视频，并能将其转...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/jscese" title="jscese" target="_blank">
					<img src="https://avatar.csdn.net/E/4/2/3_jscese.jpg" alt="jscese" class="avatar-pic">
					<span class="name">jscese</span>
				</a>
			</p>
			<p>
				<span class="date">2016-10-27 16:52:35</span>
			</p>
			<p>
				<span class="read-num">阅读数：2864</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/qq214517703/article/details/52709442" target="_blank" strategy="BlogCommendFromBaidu_3">
				从零开始学习音视频编程技术（十五） <em>YUV</em>420P转<em>RGB</em>32			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/qq214517703/article/details/52709442" target="_blank" >
				原文地址：http://blog.yundiantech.com/?log=blog&amp;id=19

上一节讲解了<em>YUV</em>420P格式的内容。

我说过，我们不是为了做研究。 平白无故讲了<em>YUV</em>420P的...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/qq214517703" title="qq214517703" target="_blank">
					<img src="https://avatar.csdn.net/E/A/2/3_qq214517703.jpg" alt="qq214517703" class="avatar-pic">
					<span class="name">qq214517703</span>
				</a>
			</p>
			<p>
				<span class="date">2016-09-30 10:20:09</span>
			</p>
			<p>
				<span class="read-num">阅读数：3030</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/chen_0306/article/details/43714107" target="_blank" strategy="BlogCommendFromBaidu_5">
				<em>ffmpeg</em>进行<em>YUV</em>420P和<em>RGB</em>24转换			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/chen_0306/article/details/43714107" target="_blank" >
				有两种方式可以进行图像像素之间的转换》
①   avpicture_fill(&amp;pic, buffer, PIX_FMT_<em>RGB</em>24, width, height)
       sws_getc...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/chen_0306" title="chen_0306" target="_blank">
					<img src="https://avatar.csdn.net/0/B/0/3_chen_0306.jpg" alt="chen_0306" class="avatar-pic">
					<span class="name">chen_0306</span>
				</a>
			</p>
			<p>
				<span class="date">2015-02-10 23:25:06</span>
			</p>
			<p>
				<span class="read-num">阅读数：2048</span>
			</p>
		</div>
	</div>
						<div class="recommend-item-box recommend-download-box csdn-tracking-statistics clearfix" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
			<div class="content float-left">
				<h4 class="text-truncate">
					<a href="https://download.csdn.net/download/codemanship/7617363" target="_blank" strategy="BlogCommendFromBaidu_6">
						使用<em>FFmpeg</em>将<em>RGB</em>格式图片或视频转换为<em>YUV</em>格式					</a>
				</h4>
				<p>
					<span class="data">2014年07月10日 </span>
					<span class="size">1012KB</span>
					<span class="type">下载</span>
				</p>
			</div>
			<div class="img-box float-right">
				<a href="https://download.csdn.net/download/codemanship/7617363" target="_blank" strategy="BlogCommendFromBaidu_6">
					<img src="http://csdnimg.cn/release/download/old_static/images/minetype/rar.svg" alt="">
				</a>
			</div>
		</div>
					<div class="recommend-item-box recommend-ad-box" id="a_d_feed_0"></div>
			<script>
				var width = $("div.recommend-box").outerWidth() - 48;
				NEWS_FEED({
					w: width,
					h: 90,
					showid: 'Afihld',
					placeholderId: 'a_d_feed_0',
					inject: 'define',
					define: {
						imagePosition: 'right',
						imageBorderRadius: 0,
						imageWidth: 120,
						imageHeight: 90,
						imageFill: 'clip',
						displayImage: true,
						displayTitle: true,
						titleFontSize: 20,
						titleFontColor: '#333',
						titleFontFamily: 'Microsoft Yahei',
						titleFontWeight: 'bold',
						titlePaddingTop: 0,
						titlePaddingRight: 0,
						titlePaddingBottom: 10,
						titlePaddingLeft: 0,
						displayDesc: true,
						descFontSize: 14,
						descFontColor: '#6b6b6b',
						descFontFamily: 'Microsoft Yahei',
						paddingTop: 0,
						paddingRight: 0,
						paddingBottom: 0,
						paddingLeft: 0,
						backgroundColor: '#fff',
						hoverColor: '#ca0c16'
					}
				})
			</script>
			<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/chuyouyinghe/article/details/78556609" target="_blank" strategy="BlogCommendFromBaidu_7">
				<em>ffmpeg</em>系列：使用<em>ffmpeg</em>转换为<em>RGB</em>数据并缩放视频			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/chuyouyinghe/article/details/78556609" target="_blank" >
				main.cpp文件代码如下：
#include &quot;myplayer.h&quot;
#include 
#pragma comment(lib,&quot;avformat.lib&quot;)
#pragma comment...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/chuyouyinghe" title="chuyouyinghe" target="_blank">
					<img src="https://avatar.csdn.net/3/4/9/3_chuyouyinghe.jpg" alt="chuyouyinghe" class="avatar-pic">
					<span class="name">chuyouyinghe</span>
				</a>
			</p>
			<p>
				<span class="date">2017-11-16 23:32:33</span>
			</p>
			<p>
				<span class="read-num">阅读数：236</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/lou__001/article/details/78552956" target="_blank" strategy="BlogCommendFromBaidu_8">
				<em>ffmpeg</em> <em>rgb</em>转<em>yuv</em> 生成H264文件			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/lou__001/article/details/78552956" target="_blank" >
				BITMAPFILEHEADER * test = NULL;
FILE * file[5];
char * szTxt[5];
int nWidth = 0;
int nHeight = 0...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/lou__001" title="lou__001" target="_blank">
					<img src="https://avatar.csdn.net/0/5/A/3_lou__001.jpg" alt="lou__001" class="avatar-pic">
					<span class="name">lou__001</span>
				</a>
			</p>
			<p>
				<span class="date">2017-11-16 16:57:13</span>
			</p>
			<p>
				<span class="read-num">阅读数：470</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/huang546213693/article/details/50054243" target="_blank" strategy="BlogCommendFromBaidu_9">
				<em>YUV</em>与<em>RGB</em>格式转换			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/huang546213693/article/details/50054243" target="_blank" >
				原文：http://www.cnblogs.com/dwdxdy/p/3713990.html


<em>YUV</em>格式具有亮度信息和色彩信息分离的特点，但大多数图像处理操作都是<em>基于</em><em>RGB</em>格式。
因此当...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/huang546213693" title="huang546213693" target="_blank">
					<img src="https://avatar.csdn.net/8/7/C/3_huang546213693.jpg" alt="huang546213693" class="avatar-pic">
					<span class="name">huang546213693</span>
				</a>
			</p>
			<p>
				<span class="date">2015-11-26 12:24:43</span>
			</p>
			<p>
				<span class="read-num">阅读数：14578</span>
			</p>
		</div>
	</div>
					<div class="recommend-item-box csdn-tracking-statistics" data-mod="popu_387" data-poputype="feed"  data-feed-show="false"  data-dsm="post">
		<h4 class="text-truncate">
			<a href="https://blog.csdn.net/mandagod/article/details/73692387" target="_blank" strategy="BlogCommendFromBaidu_10">
				如何做<em>YUV</em>的分辨率转换 - <em>FFMPEG</em> 实现 <em>YUV</em>，<em>RGB</em>各种图像原始数据之间的转换（swscale）			</a>
		</h4>
		<p class="content">
			<a href="https://blog.csdn.net/mandagod/article/details/73692387" target="_blank" >
				<em>FFMPEG</em>中的swscale提供了视频原始数据（<em>YUV</em>420，<em>YUV</em>422，<em>YUV</em>444，<em>RGB</em>24...）之间的转换，分辨率变换等操作，使用起来十分方便，在这里记录一下它的用法。
swscale...			</a>
		</p>
		<div class="info-box d-flex align-content-center">
			<p>
				<a class="avatar" src="https://blog.csdn.net/mandagod" title="mandagod" target="_blank">
					<img src="https://avatar.csdn.net/1/0/3/3_mandagod.jpg" alt="mandagod" class="avatar-pic">
					<span class="name">mandagod</span>
				</a>
			</p>
			<p>
				<span class="date">2017-06-24 16:03:12</span>
			</p>
			<p>
				<span class="read-num">阅读数：1267</span>
			</p>
		</div>
	</div>
			            <!-- 第四范式SDK -->
<script src="https://nbrecsys.4paradigm.com/resource/js/sdk-csdn-smallflow@js" async defer></script>
            <div class="recommend-loading-box">
                <img src='https://csdnimg.cn/release/phoenix/images/feedLoading.gif'>
            </div>
            <div class="recommend-end-box">
                <p class="text-center">没有更多推荐了，<a href="https://blog.csdn.net/" class="c-blue c-blue-hover c-blue-focus">返回首页</a></p>
            </div>
        </div>
    <div style="border-bottom: dashed 1px #666;"><span style="font-size: 0.8em; font-weight: bold;">此PDF由<a style="color:#0000ff" href="http://www.github.com/spygg">spygg</a>生成,请尊重原作者版权!!!<br/>我的邮箱:liushidc@163.com</span></div> </main>
    <aside style="display: none;">
		    <div id="asideProfile" class="aside-box">
    <h3 class="aside-title">个人资料</h3>
    <div class="profile-intro d-flex">
        <div class="avatar-box d-flex justify-content-center flex-column">
            <a href="https://blog.csdn.net/leixiaohua1020">
                <img src="https://avatar.csdn.net/A/7/6/3_leixiaohua1020.jpg" class="avatar_pic">
            </a>
        </div>
        <div class="user-info d-flex justify-content-center flex-column">
            <p class="name csdn-tracking-statistics tracking-click" data-mod="popu_379">
                <a href="https://blog.csdn.net/leixiaohua1020" target="_blank" class="text-truncate" id="uid">leixiaohua1020</a>
            </p>
                    </div>
                <div class="opt-box d-flex justify-content-center flex-column">
            <span  class="csdn-tracking-statistics tracking-click" data-mod="popu_379">
                                <a class="btn btn-sm btn-red-hollow" href="https://passport.csdn.net/account/login?from=https://blog.csdn.net/leixiaohua1020/article/details/42134965" target="_self">关注</a>
                            </span>
                    </div>
            </div>
    <div class="data-info d-flex item-tiling">
                <dl class="text-center" title="373">
                        <dt><a href="https://blog.csdn.net/leixiaohua1020?t=1">原创</a></dt>
            <dd><a href="https://blog.csdn.net/leixiaohua1020?t=1"><span class="count">373</span></a></dd>
                    </dl>
        <dl class="text-center" title="14088">
            <dt>粉丝</dt>
            <dd><span class="count" id="fan">1万+</span></dd>
        </dl>
        <dl class="text-center" title="460">
            <dt>喜欢</dt>
            <dd><span class="count">460</span></dd>
        </dl>
        <dl class="text-center" title="7317">
            <dt>评论</dt>
            <dd><span class="count">7317</span></dd>
        </dl>
    </div>
    <div class="grade-box clearfix">
        <dl>
            <dt>等级：</dt>
            <dd>
                <a href="https://blog.csdn.net/home/help.html#level" title="9级,点击查看等级说明" target="_blank">
                    <svg class="icon icon-level" aria-hidden="true">
                        <use xlink:href="#csdnc-bloglevel-9"></use>
                    </svg>
                </a>
            </dd>
        </dl>
        <dl>
            <dt>访问：</dt>
            <dd title="10421225">
                1042万+            </dd>
        </dl>
        <dl>
            <dt>积分：</dt>
            <dd title="62878">
                6万+            </dd>
        </dl>
        <dl title="49">
            <dt>排名：</dt>
            <dd>49</dd>
        </dl>
    </div>
        <div class="badge-box d-flex">
        <span>勋章：</span>
                <a class="icon-badge" title="专栏达人">
            <svg class="icon" aria-hidden="true">
                <use xlink:href="#csdnc-m-columns"></use>
            </svg>
            <div class="icon-arrow"></div>
            <div class="grade-detail-box item1">
                <div class="pos-box">
                    <div class="left-box d-flex justify-content-center align-items-center flex-column">
                        <svg class="icon" aria-hidden="true">
                            <use xlink:href="#csdnc-m-columns"></use>
                        </svg>
                        <p>专栏达人</p>
                    </div>
                    <div class="right-box d-flex justify-content-center align-items-center">
                        授予成功创建个人博客专栏的用户。专栏中添加五篇以上博文即可点亮！撰写博客专栏浓缩技术精华，专栏达人就是你！
                    </div>
                </div>
            </div> 
        </a>  
                        <a class="icon-badge" title="持之以恒">
            <svg class="icon" aria-hidden="true">
                <use xlink:href="#csdnc-m-lasting"></use>
            </svg>
            <div class="icon-arrow"></div>
            <div class="grade-detail-box item2">
                <div class="pos-box">
                    <div class="left-box d-flex justify-content-center align-items-center flex-column">
                        <svg class="icon" aria-hidden="true">
                            <use xlink:href="#csdnc-m-lasting"></use>
                        </svg>
                        <p>持之以恒</p>
                    </div>
                    <div class="right-box d-flex justify-content-center align-items-center">
                        授予每个自然月内发布4篇或4篇以上原创或翻译IT博文的用户。不积跬步无以至千里，不积小流无以成江海，程序人生的精彩需要坚持不懈地积累！
                    </div>
                </div>
            </div>
        </a>
                                <a class="icon-badge" title="博客之星">
            <svg class="icon" aria-hidden="true">
                <use xlink:href="#csdnc-m-blogstar-l"></use>
            </svg>
            <div class="icon-arrow"></div>
            <div class="grade-detail-box item4">
                <div class="pos-box">
                    <div class="left-box d-flex justify-content-center align-items-center flex-column">
                        <svg class="icon" aria-hidden="true">
                            <use xlink:href="#csdnc-m-blogstar-l"></use>
                        </svg>
                        <p>博客之星</p>
                    </div>
                    <div class="right-box d-flex justify-content-center align-items-center">
                        授予通过"CSDN博客之星评选"中脱颖而出的十大博客之星称号的用户。
                    </div>
                </div>
            </div>
        </a>   
            </div>
    </div>		    <div class="csdn-tracking-statistics mb8 box-shadow" data-pid="blog" data-mod="popu_4" style="height:250px;">
    <div class="aside-content text-center" id="cpro_u2734133">
        <!-- 投放代码 -->
        <script type="text/javascript" src="//cee1.iteye.com/lgyyovfyh@js"></script>
    </div>
</div>
		    <!--自定义模块-->
<div id="asideCustom26787557" class="aside-box custom-box">
    <h3 class="aside-title">关于我</h3>
    <div class="aside-content clearfix">
        姓名：雷霄骅<br>
网名：leixiaohua1020<br>
本科：<br>
中国传媒大学-广播电视工程<br>
硕士：<br>
中国传媒大学-数字电视技术<br>
博士：<br>
中国传媒大学-数字视频技术<br>
Email：<br>
leixiaohua1020@126.com<br>
QQ：<br>
494085803<br>
<br>
[注1：QQ消息较多，难以一一回复，见谅]<br>
[注2：CSDN私信功能使用很少，有问题可以直接在博客评论处留言]<br>
<br>
奖项：<br>
<a href="http://vote.blog.csdn.net/Blogstar2014/List">2014年度 - CSDN博客之星</a><br>
<a href="https://mvp.microsoft.com/en-us/mvp/Xiaohua%20Lei-5001392">2015年度 - 微软MVP</a><br>
<a href="http://bss.csdn.net/m/topic/community_star/index">2015年度 - CSDN博客之星</a><br>
简介：<br>
主要从事与广播电视有关的视音频技术的研究。包括视音频质量评价，视音频编解码，流媒体，媒资检索等。
<br>    </div>
</div>
		    <div id="asideNewArticle" class="aside-box">
    <h3 class="aside-title">最新文章</h3>
    <div class="aside-content">
        <ul class="inf_list clearfix csdn-tracking-statistics tracking-click" data-mod="popu_382">
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/51187668" target="_blank">[投稿] Speex回声消除原理深度解析</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50789619" target="_blank">[投稿]房间声学原理与Schroeder混响算法实现</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50789503" target="_blank">[投稿]一个频域语音降噪算法实现及改进方法</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50618190" target="_blank">最简单的基于FFmpeg的AVfilter的例子-纯净版</a>
            </li>
                        <li class="clearfix">
                <a href="https://blog.csdn.net/leixiaohua1020/article/details/50535230" target="_blank">视音频数据处理入门：UDP-RTP协议解析</a>
            </li>
                    </ul>
    </div>
</div>
		    <div id="asideColumn" class="aside-box">
    <h3 class="aside-title">博主专栏</h3>
    <div class="aside-content">
        <ul class="column-box csdn-tracking-statistics tracking-click" data-mod="popu_520" >
                            <li class="clearfix">
                    <div class="img-box float-left">
                        <a class="d-flex align-items-center" href="https://blog.csdn.net/column/details/videoquality.html">
                            <img src="https://img-blog.csdn.net/20151123175555036?imageView2/5/w/120/h/120" alt="">
                        </a>
                    </div>
                    <div class="info">
                        <p class="title"><a href="https://blog.csdn.net/column/details/videoquality.html">视频质量评价</a></p>
                        <div class="data">阅读量：<span>434203</span><span class="count">41 篇</span></div>
                    </div>
                </li>
                            <li class="clearfix">
                    <div class="img-box float-left">
                        <a class="d-flex align-items-center" href="https://blog.csdn.net/column/details/osmedia.html">
                            <img src="https://img-blog.csdn.net/20151123175559974?imageView2/5/w/120/h/120" alt="">
                        </a>
                    </div>
                    <div class="info">
                        <p class="title"><a href="https://blog.csdn.net/column/details/osmedia.html">开源多媒体项目源代码分析</a></p>
                        <div class="data">阅读量：<span>1158961</span><span class="count">91 篇</span></div>
                    </div>
                </li>
                            <li class="clearfix">
                    <div class="img-box float-left">
                        <a class="d-flex align-items-center" href="https://blog.csdn.net/column/details/ffmpeg-devel.html">
                            <img src="https://img-blog.csdn.net/20151123175857395?imageView2/5/w/120/h/120" alt="">
                        </a>
                    </div>
                    <div class="info">
                        <p class="title"><a href="https://blog.csdn.net/column/details/ffmpeg-devel.html">FFmpeg</a></p>
                        <div class="data">阅读量：<span>4852475</span><span class="count">135 篇</span></div>
                    </div>
                </li>
                    </ul>
    </div>
    </div>
		    <div id="asideArchive" class="aside-box flexible-box">
    <h3 class="aside-title">归档</h3>
    <div class="aside-content">
        <ul class="archive-list">
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/04">
                    2016年4月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/03">
                    2016年3月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/02">
                    2016年2月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2016/01">
                    2016年1月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/12">
                    2015年12月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/11">
                    2015年11月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/08">
                    2015年8月                    <span class="count float-right">4篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/07">
                    2015年7月                    <span class="count float-right">17篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/06">
                    2015年6月                    <span class="count float-right">6篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/05">
                    2015年5月                    <span class="count float-right">12篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/04">
                    2015年4月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/03">
                    2015年3月                    <span class="count float-right">25篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/02">
                    2015年2月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2015/01">
                    2015年1月                    <span class="count float-right">11篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/12">
                    2014年12月                    <span class="count float-right">10篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/11">
                    2014年11月                    <span class="count float-right">9篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/10">
                    2014年10月                    <span class="count float-right">20篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/09">
                    2014年9月                    <span class="count float-right">5篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/08">
                    2014年8月                    <span class="count float-right">7篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/07">
                    2014年7月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/06">
                    2014年6月                    <span class="count float-right">8篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/05">
                    2014年5月                    <span class="count float-right">10篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/04">
                    2014年4月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/02">
                    2014年2月                    <span class="count float-right">5篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2014/01">
                    2014年1月                    <span class="count float-right">14篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/12">
                    2013年12月                    <span class="count float-right">21篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/11">
                    2013年11月                    <span class="count float-right">71篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/10">
                    2013年10月                    <span class="count float-right">161篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/09">
                    2013年9月                    <span class="count float-right">101篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/08">
                    2013年8月                    <span class="count float-right">1篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/06">
                    2013年6月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                        <!--归档统计-->
            <li>
                <a href="https://blog.csdn.net/leixiaohua1020/article/month/2013/03">
                    2013年3月                    <span class="count float-right">2篇</span>
                </a>
            </li>
                    </ul>
    </div>
        <p class="text-center">
        <a class="btn btn-link-blue flexible-btn" data-fbox="aside-archive">展开</a>
    </p>
    </div>
		    <div id="asideNewComments" class="aside-box">
    <h3 class="aside-title">最新评论</h3>
    <div class="aside-content">
        <ul class="newcomment-list">
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/15811977#comments">[总结]FFMPEG视音频编解码零...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/tanhuifang520" class="user-name" target="_blank">tanhuifang520</a>：含着敬畏的心情又看了遍这个文章                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/42105049#comments">最简单的基于librtmp的示例：...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/qq_32245927" class="user-name" target="_blank">qq_32245927</a>：[reply]hjl19901012[/reply]
你们的是哪里有问题呢                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/46754977#comments">视频编码器评测系统：VideoCo...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/tqs_1220" class="user-name" target="_blank">tqs_1220</a>：天妒英才                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/38284961#comments">FFmpeg获取DirectSho...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/a137748099" class="user-name" target="_blank">a137748099</a>：[reply]liangqingzhi[/reply]
大佬，有的电脑使用regsvr32注册不成...                </p>
            </li>
                        <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/leixiaohua1020/article/details/15811977#comments">[总结]FFMPEG视音频编解码零...</a>
                <p class="comment">
                    <a href="https://my.csdn.net/qq_17276615" class="user-name" target="_blank">qq_17276615</a>：每次视频编解码都会搜到你的文章，感谢您给我们这些菜鸡一些指引。谢谢！                </p>
            </li>
                    </ul>
    </div>
</div>
		<div id="asideFooter">
			
		<div class="aside-box">
						<script type="text/javascript" src="//cee1.iteye.com/avneunkwb@js"></script>
					</div>
				<div class="aside-box">
			<div class="persion_article">
			</div>
		</div>
	</div>
</aside>
<script src="https://csdnimg.cn/pubfooter/js/publib_footer-1.0.3@js" data-isfootertrack="false" type="text/javascript"></script>
<script>
	$("a.flexible-btn").click(function(){
		$(this).parents('div.aside-box').removeClass('flexible-box');
		$(this).remove();
	})
</script>
</div>
<div class="mask-dark"></div>
<div class="pulllog-box" style="display: none;">
	<div class="pulllog clearfix">
		<span class="text float-left">加入CSDN，享受更精准的内容推荐，与500万程序员共同成长！</span>
		<div class="pulllog-btn float-right clearfix">
            <button class="pulllog-login float-left csdn-tracking-statistics tracking-click" data-mod="popu_557">
                登录
            </button>
            <div class="pulllog-sigin float-left csdn-tracking-statistics tracking-click" data-mod="popu_558">
                <a href="https://passport.csdn.net/account/mobileregister" target="_blank">注册</a>
            </div>
            <button class="btn-close">
                <svg class="icon" aria-hidden="true">
                    <use xlink:href="#csdnc-times"></use>
                </svg>
            </button>
		</div>
	</div>
</div>
<div id="loginWrap" style="display:none"></div>
<div class="tool-box">
	<ul class="meau-list">
		<li>
			<button class="btn-like " title="点赞">
				<svg class="icon active" aria-hidden="true">
					<use xlink:href="#csdnc-thumbsup-ok"></use>
				</svg><svg class="icon no-active" aria-hidden="true">
					<use xlink:href="#csdnc-thumbsup"></use>
				</svg>
				<p>8</p>
			</button>
		</li>
		<li class="toc-container-box" id="liTocBox">
			<button class="btn-toc" title="目录">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-contents"></use>
				</svg><br>目录
			</button>
			<div class="toc-container">
				<div class="pos-box">
					<div class="icon-arrow"></div>
					<div class="scroll-box">
						<div class="toc-box"></div>
					</div>
				</div>
				<div class="opt-box">
					<button class="btn-opt prev nomore" title="向上">
						<svg class="icon" aria-hidden="true">
							<use xlink:href="#csdnc-chevronup"></use>
						</svg>
					</button>
					<button class="btn-opt next">
						<svg class="icon" aria-hidden="true">
							<use xlink:href="#csdnc-chevrondown"></use>
						</svg>
					</button>
				</div>
			</div>
		</li>
		<li>
			<button class="btn-bookmark" title="收藏">
				<svg class="icon active" aria-hidden="true">
					<use xlink:href="#csdnc-bookmark-ok"></use>
				</svg><svg class="icon no-active" aria-hidden="true">
					<use xlink:href="#csdnc-bookmark"></use>
				</svg><br>收藏
			</button>
		</li>
		<li>
			<a class="btn-comments" title="评论" href="#commentBox">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-comments"></use>
				</svg><br>评论
			</a>
		</li>
				<li class="bdsharebuttonbox">
			<a class="btn-comments bds_weixin" data-cmd="weixin" title="微信分享">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-wechat"></use>
				</svg><br>微信
			</a>
		</li>
		<li class="bdsharebuttonbox">
			<a class="btn-comments bds_tsina" data-cmd="tsina" title="微博分享">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-weibo"></use>
				</svg><br>微博
			</a>
		</li>
		<li class="bdsharebuttonbox">
			<a class="btn-comments bds_qzone" data-cmd="qzone" title="QQ分享">
				<svg class="icon" aria-hidden="true">
					<use xlink:href="#csdnc-qq"></use>
				</svg><br>QQ
			</a>
		</li>
	</ul>
</div>
<script>window._bd_share_config = { "common": { "bdSnsKey": {}, "bdText": "", "bdMini": "1", "bdMiniList": false, "bdPic": "", "bdStyle": "0", "bdSize": "16" }, "share": {} }; with (document) 0[(getElementsByTagName('head')[0] || body).appendChild(createElement('script')).src = 'https://csdnimg.cn/static/api/js/share@js?v=89860594'];</script>
<script>
    var recommendCount = 10;
    recommendCount = recommendCount > 1 ? (recommendCount + (recommendCount>6 ? 2 : 1)) : recommendCount;
    var articleTit = "最简单的基于FFmpeg的libswscale的示例（YUV转RGB）";
    var ChannelId = 16;
    var articleId = "42134965";
    var commentscount = 24;
    var islock = false;
    var curentUrl = "https://blog.csdn.net/leixiaohua1020/article/details/42134965";
    var myUrl = "https://my.csdn.net/";
    //1禁止评论，2正常
    var commentAuth = 2;
    //百度搜索
    var baiduKey = "ffmpeg+sws_scale+yuv+rgb";
    var needInsertBaidu = true;
</script>
<script src="https://csdnimg.cn/public/sandalstrap/1.3/js/sandalstrap.min@js"></script>
<script src="https://csdnimg.cn/release/phoenix/vendor/pagination/paging@js"></script>

<script>
    GoTop({
        right: 8,
        hasReport: true,
        reportFun: function() {
            showReport(false,"最简单的基于FFmpeg的libswscale的示例（YUV转RGB）");
        }
    })
</script>
<script src="https://csdnimg.cn/release/phoenix/template/js/common-bd54b21308.min@js"></script>
<script src="https://csdnimg.cn/release/phoenix/template/js/detail-effe72036e.min@js"></script>
<script src="https://csdnimg.cn/release/phoenix/themes/skin3-template/skin3-template-46c7bd3d86.min@js"></script>
<script src="https://csdnimg.cn/search/baidu_search-1.1.2@js?v=201802071056&autorun=true&install=true&keyword=ffmpeg+sws_scale+yuv+rgb"  type="text/javascript"></script>
</body>
<div class="box-box-default" style="display:none;">
    <a class="btn-remove">
        关闭
    </a>
    <script type="text/javascript" src="//cee1.iteye.com/mhzzjepzz@js"></script>
</div>
<div class="box-box-large" style="display:none;">
    <a class="btn-remove">
        关闭
    </a>
    <script type="text/javascript" src="//cee1.iteye.com/idvveasfs@js"></script>
</div>
</html>